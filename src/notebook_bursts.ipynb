{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib qt\n",
    "mpl.rcParams['lines.linewidth'] = 0.91\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/marcellosicbaldi/Gitlab/acc_hr_corr_sleep/\"\n",
    "\n",
    "df_ll = pd.read_csv(path + 'bursts_ll.csv')[['start', 'end']]\n",
    "df_lw = pd.read_csv(path + 'bursts_lw.csv')[['start', 'end']]\n",
    "df_rl = pd.read_csv(path + 'bursts_rl.csv')[['start', 'end']]\n",
    "df_rw = pd.read_csv(path + 'bursts_rw.csv')[['start', 'end']]\n",
    "df_trunk = pd.read_csv(path + 'bursts_trunk.csv')[['start', 'end']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1297"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lw.shape[0] + df_rl.shape[0] + df_rw.shape[0] + df_trunk.shape[0] + df_ll.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('2024-03-20 23:17:40.274266243', '2024-03-20 23:17:46.034266233', 'LL'),\n",
       " ('2024-03-20 23:18:34.394266367', '2024-03-20 23:18:36.414266348', 'LL'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals[0], intervals[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Limbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-20 23:17:40.274266243</td>\n",
       "      <td>2024-03-20 23:17:46.034266233</td>\n",
       "      <td>LL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-20 23:18:34.352916241</td>\n",
       "      <td>2024-03-20 23:18:36.815256357</td>\n",
       "      <td>RL+LL+LW+T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-20 23:20:42.682284117</td>\n",
       "      <td>2024-03-20 23:20:45.294266224</td>\n",
       "      <td>LW+RL+LL+T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-20 23:22:28.934266329</td>\n",
       "      <td>2024-03-20 23:22:43.062916517</td>\n",
       "      <td>LL+LW+T+RL+RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-20 23:24:13.829737425</td>\n",
       "      <td>2024-03-20 23:24:24.655256510</td>\n",
       "      <td>RW+LL+LW+T+RL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2024-03-21 07:11:42.364266157</td>\n",
       "      <td>2024-03-21 07:11:48.634266376</td>\n",
       "      <td>LL+RL+LW+T+RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2024-03-21 07:11:58.762916088</td>\n",
       "      <td>2024-03-21 07:12:09.049737692</td>\n",
       "      <td>RL+LW+LL+T+RW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>2024-03-21 07:12:29.125256299</td>\n",
       "      <td>2024-03-21 07:12:34.594266176</td>\n",
       "      <td>T+RL+RW+LL+LW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>2024-03-21 07:12:47.612916231</td>\n",
       "      <td>2024-03-21 07:12:50.812283754</td>\n",
       "      <td>RL+LL+LW+T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>2024-03-21 07:13:44.612916231</td>\n",
       "      <td>2024-03-21 07:13:46.564266205</td>\n",
       "      <td>RL+LL+LW+T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Start                            End  \\\n",
       "0    2024-03-20 23:17:40.274266243  2024-03-20 23:17:46.034266233   \n",
       "1    2024-03-20 23:18:34.352916241  2024-03-20 23:18:36.815256357   \n",
       "2    2024-03-20 23:20:42.682284117  2024-03-20 23:20:45.294266224   \n",
       "3    2024-03-20 23:22:28.934266329  2024-03-20 23:22:43.062916517   \n",
       "4    2024-03-20 23:24:13.829737425  2024-03-20 23:24:24.655256510   \n",
       "..                             ...                            ...   \n",
       "335  2024-03-21 07:11:42.364266157  2024-03-21 07:11:48.634266376   \n",
       "336  2024-03-21 07:11:58.762916088  2024-03-21 07:12:09.049737692   \n",
       "337  2024-03-21 07:12:29.125256299  2024-03-21 07:12:34.594266176   \n",
       "338  2024-03-21 07:12:47.612916231  2024-03-21 07:12:50.812283754   \n",
       "339  2024-03-21 07:13:44.612916231  2024-03-21 07:13:46.564266205   \n",
       "\n",
       "             Limbs  \n",
       "0               LL  \n",
       "1       RL+LL+LW+T  \n",
       "2       LW+RL+LL+T  \n",
       "3    LL+LW+T+RL+RW  \n",
       "4    RW+LL+LW+T+RL  \n",
       "..             ...  \n",
       "335  LL+RL+LW+T+RW  \n",
       "336  RL+LW+LL+T+RW  \n",
       "337  T+RL+RW+LL+LW  \n",
       "338     RL+LL+LW+T  \n",
       "339     RL+LL+LW+T  \n",
       "\n",
       "[340 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Combine all intervals into a list along with limb identifiers\n",
    "intervals = []\n",
    "intervals.extend((row['start'], row['end'], 'LL') for index, row in df_ll.iterrows())\n",
    "intervals.extend((row['start'], row['end'], 'LW') for index, row in df_lw.iterrows())\n",
    "intervals.extend((row['start'], row['end'], 'RL') for index, row in df_rl.iterrows())\n",
    "intervals.extend((row['start'], row['end'], 'RW') for index, row in df_rw.iterrows())\n",
    "intervals.extend((row['start'], row['end'], 'T') for index, row in df_trunk.iterrows())\n",
    "\n",
    "# Sort intervals by start time\n",
    "intervals.sort(key=lambda x: x[0])\n",
    "\n",
    "# Merge overlapping intervals and label them\n",
    "merged_intervals = []\n",
    "current_start, current_end, current_limb = intervals[0]\n",
    "\n",
    "for start, end, limb in intervals[1:]:\n",
    "    if start <= current_end:  # There is an overlap\n",
    "        current_end = max(current_end, end)\n",
    "        if limb not in current_limb:\n",
    "            current_limb += '+' + limb\n",
    "    else:\n",
    "        merged_intervals.append((current_start, current_end, current_limb))\n",
    "        current_start, current_end, current_limb = start, end, limb\n",
    "\n",
    "# Append the last interval\n",
    "merged_intervals.append((current_start, current_end, current_limb))\n",
    "\n",
    "# Create a DataFrame for a cleaner view of the merged intervals\n",
    "df_merged_intervals = pd.DataFrame(merged_intervals, columns=['Start', 'End', 'Limbs'])\n",
    "df_merged_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Limbs\n",
       "LW               25\n",
       "LL               19\n",
       "RL               18\n",
       "RL+LL+LW+T+RW    12\n",
       "LW+RW            11\n",
       "                 ..\n",
       "RL+LW             1\n",
       "RL+LL+RW+T        1\n",
       "RL+LL+RW+LW+T     1\n",
       "LW+T+LL+RL        1\n",
       "T+RW+RL+LL+LW     1\n",
       "Name: count, Length: 122, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_intervals.value_counts('Limbs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### Functions to detect bursts in acceleration signal ####\n",
    "\n",
    "def hl_envelopes_idx(s, dmin=1, dmax=1, split=False):\n",
    "    \"\"\"\n",
    "    Compute high and low envelopes of a signal s\n",
    "    Parameters\n",
    "    ----------\n",
    "    s: 1d-array, data signal from which to extract high and low envelopes\n",
    "    dmin, dmax: int, optional, size of chunks, use this if the size of the input signal is too big\n",
    "    split: bool, optional, if True, split the signal in half along its mean, might help to generate the envelope in some cases\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lmin,lmax : high/low envelope idx of input signal s\n",
    "    \"\"\"\n",
    "\n",
    "    # locals min      \n",
    "    lmin = (np.diff(np.sign(np.diff(s))) > 0).nonzero()[0] + 1 \n",
    "    # locals max\n",
    "    lmax = (np.diff(np.sign(np.diff(s))) < 0).nonzero()[0] + 1 \n",
    "    \n",
    "    if split:\n",
    "        # s_mid is zero if s centered around x-axis or more generally mean of signal\n",
    "        s_mid = np.mean(s) \n",
    "        # pre-sorting of locals min based on relative position with respect to s_mid \n",
    "        lmin = lmin[s[lmin]<s_mid]\n",
    "        # pre-sorting of local max based on relative position with respect to s_mid \n",
    "        lmax = lmax[s[lmax]>s_mid]\n",
    "\n",
    "    # global min of dmin-chunks of locals min \n",
    "    lmin = lmin[[i+np.argmin(s[lmin[i:i+dmin]]) for i in range(0,len(lmin),dmin)]]\n",
    "    # global max of dmax-chunks of locals max \n",
    "    lmax = lmax[[i+np.argmax(s[lmax[i:i+dmax]]) for i in range(0,len(lmax),dmax)]]\n",
    "    \n",
    "    return lmin,lmax\n",
    "\n",
    "def detect_bursts(acc, envelope = True, plot = False, alfa = 15):\n",
    "    \"\"\"\n",
    "    Detect bursts in acceleration signal\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    std_acc : pd.Series\n",
    "        Standard deviation of acceleration signal with a 1 s resolution\n",
    "    envelope : bool, optional\n",
    "        If True, detect bursts based on the envelope of the signal\n",
    "        If False, detect bursts based on the std of the signal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bursts : pd.Series\n",
    "        pd.DataFrame with burst start times, end times, and duration\n",
    "    \"\"\"\n",
    "\n",
    "    if envelope:\n",
    "        lmin, lmax = hl_envelopes_idx(acc.values, dmin=9, dmax=9)\n",
    "        # adjust shapes\n",
    "        if len(lmin) > len(lmax):\n",
    "            lmin = lmin[:-1]\n",
    "        if len(lmax) > len(lmin):\n",
    "            lmax = lmax[1:]\n",
    "        th = np.percentile(acc.values[lmax] - acc.values[lmin], 10) * alfa\n",
    "        std_acc = pd.Series(acc.values[lmax] - acc.values[lmin], index = acc.index[lmax])\n",
    "    else:\n",
    "        std_acc = acc.resample(\"1 s\").std()\n",
    "        std_acc.index.round(\"1 s\")\n",
    "        th = np.percentile(std_acc, 10) * alfa\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(std_acc, color = 'b')\n",
    "        plt.axhline(th, color = 'r')\n",
    "\n",
    "    bursts1 = (std_acc > th).astype(int)\n",
    "    start_burst = bursts1.where(bursts1.diff()==1).dropna()\n",
    "    end_burst = bursts1.where(bursts1.diff()==-1).dropna()\n",
    "    if bursts1.iloc[0] == 1:\n",
    "            start_burst = pd.concat([pd.Series(0, index = [bursts1.index[0]]), start_burst])\n",
    "    if bursts1.iloc[-1] == 1:\n",
    "        end_burst = pd.concat([end_burst, pd.Series(0, index = [bursts1.index[-1]])])\n",
    "    bursts_df = pd.DataFrame({\"duration\": end_burst.index - start_burst.index}, index = start_burst.index)\n",
    "\n",
    "    start = bursts_df.index\n",
    "    end = pd.to_datetime((bursts_df.index + bursts_df[\"duration\"]).values)\n",
    "\n",
    "    end = end.to_series().reset_index(drop = True)\n",
    "    start = start.to_series().reset_index(drop = True)\n",
    "\n",
    "    duration_between_bursts = (start.iloc[1:].values - end.iloc[:-1].values)\n",
    "\n",
    "    for i in range(len(start)-1):\n",
    "        if duration_between_bursts[i] < pd.Timedelta(\"5 s\"):\n",
    "            end[i] = np.nan\n",
    "            start[i+1] = np.nan\n",
    "    end.dropna(inplace = True)\n",
    "    start.dropna(inplace = True)\n",
    "\n",
    "    # extract amplitude of the bursts\n",
    "    bursts = pd.DataFrame({\"start\": start.reset_index(drop = True), \"end\": end.reset_index(drop = True)})\n",
    "    burst_amplitude1 = []\n",
    "    burst_amplitude2 = []\n",
    "    for i in range(len(bursts)):\n",
    "        # peak-to-peak amplitude of bp acceleration\n",
    "        burst_amplitude1.append(acc.loc[bursts[\"start\"].iloc[i]:bursts[\"end\"].iloc[i]].max() - acc.loc[bursts[\"start\"].iloc[i]:bursts[\"end\"].iloc[i]].min())\n",
    "        # AUC of std_acc\n",
    "        burst_amplitude2.append(np.trapz(std_acc.loc[bursts[\"start\"].iloc[i]:bursts[\"end\"].iloc[i]]))\n",
    "    bursts[\"duration\"] = bursts[\"end\"] - bursts[\"start\"]\n",
    "    bursts[\"peak-to-peak\"] = burst_amplitude1\n",
    "    bursts[\"AUC\"] = burst_amplitude2\n",
    "    return bursts\n",
    "\n",
    "#### Functions to filter bursts that are too close to each other ####\n",
    "\n",
    "def filter_bursts(data):\n",
    "    \"\"\"\n",
    "    Filter bursts that are neither preceded nor followed by another movement for at least 30 seconds.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): DataFrame containing 'start', 'end', and 'duration' columns.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the time difference between movements\n",
    "    data['next_start_diff'] = data['start'].shift(-1) - data['end']\n",
    "    data['prev_end_diff'] = data['start'] - data['end'].shift(1)\n",
    "    \n",
    "    # Convert differences to total seconds for comparison\n",
    "    data['next_start_diff_seconds'] = data['next_start_diff'].dt.total_seconds()\n",
    "    data['prev_end_diff_seconds'] = data['prev_end_diff'].dt.total_seconds()\n",
    "    \n",
    "    # Filter movements with at least 30 seconds separation from both previous and next movements\n",
    "    filtered_data = data[(data['next_start_diff_seconds'] > 30) & (data['prev_end_diff_seconds'] > 30)]\n",
    "\n",
    "    data.drop(columns=['next_start_diff', 'prev_end_diff', 'next_start_diff_seconds', 'prev_end_diff_seconds'], inplace=True)\n",
    "    \n",
    "    # Return the filtered data, dropping the temporary columns used for filtering\n",
    "    return filtered_data.drop(columns=['next_start_diff', 'prev_end_diff', 'next_start_diff_seconds', 'prev_end_diff_seconds'])\n",
    "\n",
    "#### Functions to find combination of bursts happening at different limbs ####\n",
    "\n",
    "# For now, implemented for \n",
    "# - all 5 limbs together\n",
    "# - every combination?\n",
    "\n",
    "\n",
    "def is_isolated(start, end, df):\n",
    "    # Check if the start or end of an interval falls within any interval in the dataframe\n",
    "    overlap = df[(df['start'] <= end) & (df['end'] >= start)]\n",
    "    return overlap.empty\n",
    "\n",
    "def merge_excluding(current_df):\n",
    "    df_list = [bursts_ll, bursts_rl, bursts_lw, bursts_rw, bursts_trunk]  # TODO: make this a function argument...\n",
    "    combined_df = pd.concat([df for df in df_list if not df.equals(current_df)], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def find_isolated_combination(dfs_to_combine, dfs_to_isolate):\n",
    "    # Merge dataframes that should be combined\n",
    "    combined_df = pd.concat(dfs_to_combine, ignore_index=True).sort_values(by='start')\n",
    "    # Merge dataframes from which isolation is required\n",
    "    isolate_df = pd.concat(dfs_to_isolate, ignore_index=True).sort_values(by='start')\n",
    "\n",
    "    # Finding overlaps within combined_df\n",
    "    overlaps = []\n",
    "    for i, row in combined_df.iterrows():\n",
    "        overlapping_rows = combined_df[\n",
    "            (combined_df['start'] <= row['end']) &\n",
    "            (combined_df['end'] >= row['start']) &\n",
    "            (combined_df.index != i)\n",
    "        ]\n",
    "        if not overlapping_rows.empty:\n",
    "            # Check isolation from other dataframes\n",
    "            if is_isolated(row['start'], row['end'], isolate_df):\n",
    "                overlaps.append(row)\n",
    "\n",
    "    return pd.DataFrame(overlaps)\n",
    "\n",
    "def find_combined_movements_all_limbs(dfs):\n",
    "    # Merging all limb dataframes\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "    # Sorting by start time\n",
    "    merged_df.sort_values(by='start', inplace=True)\n",
    "    \n",
    "    # Finding overlapping intervals for all limbs\n",
    "    overlaps = []\n",
    "    current_overlap = None\n",
    "    for index, row in merged_df.iterrows():\n",
    "        if current_overlap is None:\n",
    "            current_overlap = {\n",
    "                'start': row['start'],\n",
    "                'end': row['end'],\n",
    "                'limbs_involved': {row['limb']}\n",
    "            }\n",
    "        else:\n",
    "            # Check if the current row overlaps with the current overlapping period\n",
    "            if row['start'] <= current_overlap['end']:\n",
    "                current_overlap['limbs_involved'].add(row['limb'])\n",
    "                # Update the end time to the latest end time\n",
    "                if row['end'] > current_overlap['end']:\n",
    "                    current_overlap['end'] = row['end']\n",
    "            else:\n",
    "                # Check if the previous overlap involved all limbs\n",
    "                if current_overlap['limbs_involved'] == {'lw', 'rw', 'll', 'rl', 'trunk'}:\n",
    "                    overlaps.append(current_overlap)\n",
    "                # Start a new overlap\n",
    "                current_overlap = {\n",
    "                    'start': row['start'],\n",
    "                    'end': row['end'],\n",
    "                    'limbs_involved': {row['limb']}\n",
    "                }\n",
    "    \n",
    "    # Final check at the end of the loop\n",
    "    if current_overlap and current_overlap['limbs_involved'] == {'lw', 'rw', 'll', 'rl', 'trunk'}:\n",
    "        overlaps.append(current_overlap)\n",
    "    \n",
    "    return pd.DataFrame(overlaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "Loaded ax_data!\n"
     ]
    }
   ],
   "source": [
    "# Description: This script detects bursts in the accelerometer data of the trunk and limbs of the subjects, and save the results in a pickle file. \n",
    "# The bursts are detected using the Hilbert envelope method, and the isolated movements are extracted for each limb. \n",
    "# The script also computes the area under the curve of the Hilbert envelope for each burst, and detects posture changes from the trunk accelerometer data. \n",
    "# The results are saved in a dictionary with keys for each combination of limbs.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neurokit2 as nk\n",
    "import pickle\n",
    "\n",
    "from functions.acc_utils import compute_acc_norm\n",
    "from functions.posture import compute_spherical_coordinates, detect_posture_changes\n",
    "\n",
    "\n",
    "diary_SPT = {    \n",
    "    \"158\": [pd.Timestamp('2024-02-28 23:00:00'), pd.Timestamp('2024-02-29 07:15:00')], # 158 OK\n",
    "    \"633\": [pd.Timestamp('2024-03-07 00:05:00'), pd.Timestamp('2024-03-07 06:36:00')], # 633 OK\n",
    "    \"906\": [pd.Timestamp('2024-03-07 00:30:00'), pd.Timestamp('2024-03-07 07:30:00')], # 906 OK\n",
    "    \"958\": [pd.Timestamp('2024-03-13 22:00:00'), pd.Timestamp('2024-03-14 06:00:00')], # 958 OK\n",
    "    \"127\": [pd.Timestamp('2024-03-13 23:15:00'), pd.Timestamp('2024-03-14 06:50:00')], # 127 OK\n",
    "    \"098\": [pd.Timestamp('2024-03-16 02:01:00'), pd.Timestamp('2024-03-16 09:50:00')], # 098 OK\n",
    "    \"547\": [pd.Timestamp('2024-03-16 01:04:00'), pd.Timestamp('2024-03-16 07:40:00')], # 547 OK\n",
    "    \"815\": [pd.Timestamp('2024-03-20 23:00:00'), pd.Timestamp('2024-03-21 07:30:00')], # 815 OK\n",
    "    \"914\": [pd.Timestamp('2024-03-20 21:50:00'), pd.Timestamp('2024-03-21 05:50:00')], # 914 OK\n",
    "    \"971\": [pd.Timestamp('2024-03-20 23:50:00'), pd.Timestamp('2024-03-21 07:50:00')], # 971 OK\n",
    "    \"279\": [pd.Timestamp('2024-03-28 00:10:00'), pd.Timestamp('2024-03-28 07:27:00')], # 279 OK\n",
    "    \"965\": [pd.Timestamp('2024-03-28 01:25:00'), pd.Timestamp('2024-03-28 09:20:00')], # 965 OK\n",
    "}\n",
    "\n",
    "diary_TIB = {\n",
    "    \"158\": [pd.Timestamp('2024-02-28 22:15:00'), pd.Timestamp('2024-02-29 07:45:00')], # 158 OK\n",
    "    \"633\": [pd.Timestamp('2024-03-06 23:39:00'), pd.Timestamp('2024-03-07 08:00:00')], # 633 OK \n",
    "    \"906\": [pd.Timestamp('2024-03-07 00:15:00'), pd.Timestamp('2024-03-07 07:35:00')], # 906 OK\n",
    "    \"958\": [pd.Timestamp('2024-03-13 21:30:00'), pd.Timestamp('2024-03-14 06:30:00')], # 958 OK\n",
    "    \"127\": [pd.Timestamp('2024-03-13 22:00:00'), pd.Timestamp('2024-03-14 07:10:00')], # 127 OK \n",
    "    \"098\": [pd.Timestamp('2024-03-16 01:49:00'), pd.Timestamp('2024-03-16 09:52:00')], # 098 OK \n",
    "    \"547\": [pd.Timestamp('2024-03-16 00:26:00'), pd.Timestamp('2024-03-16 08:20:00')], # 547 OK \n",
    "    \"815\": [pd.Timestamp('2024-03-20 22:00:00'), pd.Timestamp('2024-03-21 07:30:00')], # 815 OK \n",
    "    \"914\": [pd.Timestamp('2024-03-20 21:30:00'), pd.Timestamp('2024-03-21 06:20:00')], # 914 OK \n",
    "    \"971\": [pd.Timestamp('2024-03-20 23:30:00'), pd.Timestamp('2024-03-21 08:08:00')], # 971 OK \n",
    "    \"279\": [pd.Timestamp('2024-03-28 00:04:00'), pd.Timestamp('2024-03-28 07:41:00')], # 279 OK\n",
    "    \"965\": [pd.Timestamp('2024-03-28 01:22:00'), pd.Timestamp('2024-03-28 09:22:00')], # 965 OK\n",
    "}\n",
    "\n",
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\"]\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "\n",
    "    print(sub)\n",
    "\n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/ax_data.pkl', 'rb') as f:\n",
    "        ax_data = pickle.load(f)\n",
    "\n",
    "    print(\"Loaded ax_data!\")\n",
    "\n",
    "    trunk_df = pd.Series(compute_acc_norm(ax_data[\"trunk\"][[\"x\", \"y\", \"z\"]].values), index = pd.to_datetime(ax_data[\"trunk\"][\"time\"], unit = \"s\") + pd.Timedelta(hours = 1))\n",
    "    ll_df = pd.Series(compute_acc_norm(ax_data[\"la\"][[\"x\", \"y\", \"z\"]].values), index = pd.to_datetime(ax_data[\"la\"][\"time\"], unit = \"s\") + pd.Timedelta(hours = 1))\n",
    "    rl_df = pd.Series(compute_acc_norm(ax_data[\"ra\"][[\"x\", \"y\", \"z\"]].values), index = pd.to_datetime(ax_data[\"ra\"][\"time\"], unit = \"s\") + pd.Timedelta(hours = 1))\n",
    "    lw_df = pd.Series(compute_acc_norm(ax_data[\"lw\"][[\"x\", \"y\", \"z\"]].values), index = pd.to_datetime(ax_data[\"lw\"][\"time\"], unit = \"s\") + pd.Timedelta(hours = 1))\n",
    "    rw_df = pd.Series(compute_acc_norm(ax_data[\"rw\"][[\"x\", \"y\", \"z\"]].values), index = pd.to_datetime(ax_data[\"rw\"][\"time\"], unit = \"s\") + pd.Timedelta(hours = 1))\n",
    "\n",
    "    start_sleep, end_sleep = diary_SPT[sub]\n",
    "\n",
    "    trunk_df = trunk_df.loc[start_sleep:end_sleep]\n",
    "    ll_df = ll_df.loc[start_sleep:end_sleep]\n",
    "    rl_df = rl_df.loc[start_sleep:end_sleep]\n",
    "    lw_df = lw_df.loc[start_sleep:end_sleep]\n",
    "    rw_df = rw_df.loc[start_sleep:end_sleep]\n",
    "\n",
    "    # TODO: Modify sampling rate to 100 Hz\n",
    "\n",
    "    lw_df_bp = pd.Series(nk.signal_filter(lw_df.values, sampling_rate = 50, lowcut=0.1, highcut=5, method='butterworth', order=8), index = lw_df.index)\n",
    "    rw_df_bp = pd.Series(nk.signal_filter(rw_df.values, sampling_rate = 50, lowcut=0.1, highcut=5, method='butterworth', order=8), index = rw_df.index)\n",
    "    ll_df_bp = pd.Series(nk.signal_filter(ll_df.values, sampling_rate = 50, lowcut=0.1, highcut=5, method='butterworth', order=8), index = ll_df.index)\n",
    "    rl_df_bp = pd.Series(nk.signal_filter(rl_df.values, sampling_rate = 50, lowcut=0.1, highcut=5, method='butterworth', order=8), index = rl_df.index)\n",
    "    trunk_df_bp = pd.Series(nk.signal_filter(trunk_df.values, sampling_rate = 50, lowcut=0.1, highcut=5, method='butterworth', order=8), index = trunk_df.index)\n",
    "    bursts_lw = detect_bursts(lw_df_bp, plot = False, alfa = 7)\n",
    "    bursts_rw = detect_bursts(rw_df_bp, plot = False, alfa = 7)\n",
    "    bursts_ll = detect_bursts(ll_df_bp, plot = False, alfa = 6)\n",
    "    bursts_rl = detect_bursts(rl_df_bp, plot = False, alfa = 6)\n",
    "    bursts_trunk = detect_bursts(trunk_df_bp, plot = False, alfa = 5)\n",
    "\n",
    "    break\n",
    "\n",
    "    # Isolation checks\n",
    "    bursts_ll['isolated'] = bursts_ll.apply(lambda x: is_isolated(x['start'], x['end'], merge_excluding(bursts_ll)), axis=1)\n",
    "    bursts_rl['isolated'] = bursts_rl.apply(lambda x: is_isolated(x['start'], x['end'], merge_excluding(bursts_rl)), axis=1)\n",
    "    bursts_lw['isolated'] = bursts_lw.apply(lambda x: is_isolated(x['start'], x['end'], merge_excluding(bursts_lw)), axis=1)\n",
    "    bursts_rw['isolated'] = bursts_rw.apply(lambda x: is_isolated(x['start'], x['end'], merge_excluding(bursts_rw)), axis=1)\n",
    "    bursts_trunk['isolated'] = bursts_trunk.apply(lambda x: is_isolated(x['start'], x['end'], merge_excluding(bursts_trunk)), axis=1)\n",
    "\n",
    "    # Extract isolated movements for each limb\n",
    "    bursts_ll_isolated = bursts_ll[bursts_ll['isolated']]\n",
    "    bursts_rl_isolated = bursts_rl[bursts_rl['isolated']]\n",
    "    bursts_lw_isolated = bursts_lw[bursts_lw['isolated']]\n",
    "    bursts_rw_isolated = bursts_rw[bursts_rw['isolated']]\n",
    "    bursts_trunk_isolated = bursts_trunk[bursts_trunk['isolated']]\n",
    "\n",
    "    bursts_wrists_isolated = pd.concat([bursts_lw_isolated, bursts_rw_isolated], ignore_index=True)\n",
    "    bursts_legs_isolated = pd.concat([bursts_ll_isolated, bursts_rl_isolated], ignore_index=True)\n",
    "\n",
    "    bursts_both_wrists = find_isolated_combination([bursts_lw, bursts_rw], [bursts_ll, bursts_rl, bursts_trunk]).iloc[::2].reset_index(drop=True)\n",
    "\n",
    "    # Finding isolated movements for both legs alone (no wrists or trunk)\n",
    "    bursts_both_legs = find_isolated_combination([bursts_ll, bursts_rl], [bursts_lw, bursts_rw, bursts_trunk]).iloc[::2].reset_index(drop=True)\n",
    "\n",
    "    bursts_lw[\"limb\"] = \"lw\"\n",
    "    bursts_rw[\"limb\"] = \"rw\"\n",
    "    bursts_ll[\"limb\"] = \"ll\"\n",
    "    bursts_rl[\"limb\"] = \"rl\"\n",
    "    bursts_trunk[\"limb\"] = \"trunk\"\n",
    "    bursts_all_limbs_combined = find_combined_movements_all_limbs([bursts_lw, bursts_rw, bursts_ll, bursts_rl, bursts_trunk])\n",
    "\n",
    "    bursts_all_limbs_combined[\"AUC\"] = np.nan\n",
    "\n",
    "    lmin, lmax = hl_envelopes_idx(lw_df_bp.values, dmin=9, dmax=9)\n",
    "    if len(lmin) > len(lmax):\n",
    "        lmin = lmin[:-1]\n",
    "    if len(lmax) > len(lmin):\n",
    "        lmax = lmax[1:]\n",
    "    env_diff_lw = pd.Series(lw_df_bp.values[lmax] - lw_df_bp.values[lmin], index = lw_df_bp.index[lmax])\n",
    "\n",
    "    lmin, lmax = hl_envelopes_idx(rw_df_bp.values, dmin=9, dmax=9)\n",
    "    if len(lmin) > len(lmax):\n",
    "        lmin = lmin[:-1]\n",
    "    if len(lmax) > len(lmin):\n",
    "        lmax = lmax[1:]\n",
    "    env_diff_rw = pd.Series(rw_df_bp.values[lmax] - rw_df_bp.values[lmin], index = rw_df_bp.index[lmax])\n",
    "\n",
    "    lmin, lmax = hl_envelopes_idx(ll_df_bp.values, dmin=9, dmax=9)\n",
    "    if len(lmin) > len(lmax):\n",
    "        lmin = lmin[:-1]\n",
    "    if len(lmax) > len(lmin):\n",
    "        lmax = lmax[1:]\n",
    "    env_diff_ll = pd.Series(ll_df_bp.values[lmax] - ll_df_bp.values[lmin], index = ll_df_bp.index[lmax])\n",
    "\n",
    "    lmin, lmax = hl_envelopes_idx(rl_df_bp.values, dmin=9, dmax=9)\n",
    "    if len(lmin) > len(lmax):\n",
    "        lmin = lmin[:-1]\n",
    "    if len(lmax) > len(lmin):\n",
    "        lmax = lmax[1:]\n",
    "    env_diff_rl = pd.Series(rl_df_bp.values[lmax] - rl_df_bp.values[lmin], index = rl_df_bp.index[lmax])\n",
    "\n",
    "    lmin, lmax = hl_envelopes_idx(trunk_df_bp.values, dmin=9, dmax=9)\n",
    "    if len(lmin) > len(lmax):\n",
    "        lmin = lmin[:-1]\n",
    "    if len(lmax) > len(lmin):\n",
    "        lmax = lmax[1:]\n",
    "    env_diff_trunk = pd.Series(trunk_df_bp.values[lmax] - trunk_df_bp.values[lmin], index = trunk_df_bp.index[lmax])\n",
    "\n",
    "    for i, b in enumerate(range(len(bursts_all_limbs_combined))):\n",
    "        bursts_all_limbs_combined.loc[i, \"AUC\"] = np.trapz(env_diff_lw.loc[bursts_all_limbs_combined[\"start\"].iloc[i]:bursts_all_limbs_combined[\"end\"].iloc[i]]) \n",
    "        + np.trapz(env_diff_rw.loc[bursts_all_limbs_combined[\"start\"].iloc[i]:bursts_all_limbs_combined[\"end\"].iloc[i]]) \n",
    "        + np.trapz(env_diff_ll.loc[bursts_all_limbs_combined[\"start\"].iloc[i]:bursts_all_limbs_combined[\"end\"].iloc[i]]) \n",
    "        + np.trapz(env_diff_rl.loc[bursts_all_limbs_combined[\"start\"].iloc[i]:bursts_all_limbs_combined[\"end\"].iloc[i]]) \n",
    "        + np.trapz(env_diff_trunk.loc[bursts_all_limbs_combined[\"start\"].iloc[i]:bursts_all_limbs_combined[\"end\"].iloc[i]]) \n",
    "\n",
    "    bursts_both_wrists[\"AUC\"] = np.nan\n",
    "    for i, b in enumerate(range(len(bursts_both_wrists))):\n",
    "        bursts_both_wrists.loc[i, \"AUC\"] = np.trapz(env_diff_lw.loc[bursts_both_wrists[\"start\"].iloc[i]:bursts_both_wrists[\"end\"].iloc[i]]) \n",
    "        + np.trapz(env_diff_rw.loc[bursts_both_wrists[\"start\"].iloc[i]:bursts_both_wrists[\"end\"].iloc[i]])\n",
    "\n",
    "    bursts_both_legs[\"AUC\"] = np.nan\n",
    "    for i, b in enumerate(range(len(bursts_both_legs))):\n",
    "        bursts_both_legs.loc[i, \"AUC\"] = np.trapz(env_diff_ll.loc[bursts_both_legs[\"start\"].iloc[i]:bursts_both_legs[\"end\"].iloc[i]]) \n",
    "        + np.trapz(env_diff_rl.loc[bursts_both_legs[\"start\"].iloc[i]:bursts_both_legs[\"end\"].iloc[i]])\n",
    "\n",
    "    # Trunk - I need xyz\n",
    "    ax_data['trunk'].index = pd.to_datetime(ax_data['trunk']['time'], unit='s') + pd.Timedelta(hours = 1)\n",
    "    ax_data['trunk'].drop(columns=['time'], inplace=True)\n",
    "    trunk_acc_df = ax_data['trunk'].loc[start_sleep:end_sleep]\n",
    "    del ax_data\n",
    "\n",
    "    phi, theta = compute_spherical_coordinates(trunk_acc_df.resample('10s').median())\n",
    "    trunk_acc_sph = pd.DataFrame({\"phi\": phi * 180 / np.pi, \"theta\": theta * 180 / np.pi}, index=trunk_acc_df.resample('10s').median().index)\n",
    "    updated_df = detect_posture_changes(trunk_acc_sph.copy())\n",
    "    time_posture_change30 = updated_df[updated_df['posture_change30']].index\n",
    "    time_posture_change10 = updated_df[updated_df['posture_change10']].index\n",
    "    # join bursts from all limbs and posture changes\n",
    "\n",
    "    bursts_all_limbs_combined[\"posture_change\"] = np.nan\n",
    "\n",
    "    for time in time_posture_change10:\n",
    "        for i in range(len(bursts_all_limbs_combined)):\n",
    "                if time > bursts_all_limbs_combined[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_all_limbs_combined[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                    bursts_all_limbs_combined[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees10\"]\n",
    "    # join bursts and posture changes\n",
    "\n",
    "    bursts_lw[\"posture_change\"] = np.nan\n",
    "    bursts_rw[\"posture_change\"] = np.nan\n",
    "    bursts_ll[\"posture_change\"] = np.nan\n",
    "    bursts_rl[\"posture_change\"] = np.nan\n",
    "    bursts_trunk[\"posture_change\"] = np.nan\n",
    "\n",
    "    for time in time_posture_change30:\n",
    "        for i in range(len(bursts_lw)):\n",
    "            if time > bursts_lw[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_lw[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_lw[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees30\"]\n",
    "        for i in range(len(bursts_rw)):\n",
    "            if time > bursts_rw[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_rw[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_rw[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees30\"]\n",
    "        for i in range(len(bursts_ll)):\n",
    "            if time > bursts_ll[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_ll[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_ll[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees30\"]\n",
    "        for i in range(len(bursts_rl)):\n",
    "            if time > bursts_rl[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_rl[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_rl[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees30\"]\n",
    "        for i in range(len(bursts_trunk)):\n",
    "            if time > bursts_trunk[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_trunk[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_trunk[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees30\"]\n",
    "\n",
    "    for time in time_posture_change10:\n",
    "        for i in range(len(bursts_lw)):\n",
    "            if time > bursts_lw[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_lw[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_lw[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees10\"]\n",
    "        for i in range(len(bursts_rw)):\n",
    "            if time > bursts_rw[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_rw[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_rw[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees10\"]\n",
    "        for i in range(len(bursts_ll)):\n",
    "            if time > bursts_ll[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_ll[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_ll[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees10\"]\n",
    "        for i in range(len(bursts_rl)):\n",
    "            if time > bursts_rl[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_rl[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_rl[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees10\"]\n",
    "        for i in range(len(bursts_trunk)):\n",
    "            if time > bursts_trunk[\"start\"].iloc[i]-pd.Timedelta(seconds = 5) and time < bursts_trunk[\"end\"].iloc[i]+pd.Timedelta(seconds = 5):\n",
    "                bursts_trunk[\"posture_change\"].iloc[i] = updated_df.loc[time, \"posture_change_degrees10\"]\n",
    "\n",
    "    # summarize all the bursts in a dict, with a key for each combination of limbs\n",
    "\n",
    "    bursts = {\n",
    "        \"lw\": bursts_lw,\n",
    "        \"rw\": bursts_rw,\n",
    "        \"ll\": bursts_ll,\n",
    "        \"rl\": bursts_rl,\n",
    "        \"trunk\": bursts_trunk,\n",
    "        \"wrists\": bursts_wrists_isolated,\n",
    "        \"legs\": bursts_legs_isolated,\n",
    "        \"trunk_isolated\": bursts_trunk_isolated,\n",
    "        \"both_wrists\": bursts_both_wrists,\n",
    "        \"both_legs\": bursts_both_legs,\n",
    "        \"all_limbs\": bursts_all_limbs_combined\n",
    "    }\n",
    "\n",
    "    # SAVE\n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/bursts_TIB.pkl', 'wb') as f:\n",
    "        pickle.dump(bursts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb1e4edbca0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(19, 12))\n",
    "plt.subplot(5, 1, 1)\n",
    "plt.plot(lw_df)\n",
    "for i in range(len(bursts_lw)):\n",
    "    plt.axvspan(bursts_lw[\"start\"].iloc[i], bursts_lw[\"end\"].iloc[i], color = 'b', alpha = 0.3)\n",
    "plt.ylabel(\"ACC (g)\", fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.legend([\"LW ACC\", \"Movement\"], loc = \"upper right\", fontsize = 16)\n",
    "\n",
    "plt.subplot(5, 1, 2, sharex = plt.subplot(5, 1, 1), sharey = plt.subplot(5, 1, 1))\n",
    "plt.plot(rw_df)\n",
    "for i in range(len(bursts_rw)):\n",
    "    plt.axvspan(bursts_rw[\"start\"].iloc[i], bursts_rw[\"end\"].iloc[i], color = 'b', alpha = 0.3)\n",
    "plt.ylabel(\"ACC (g)\", fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.legend([\"RW ACC\", \"Movement\"], loc = \"upper right\", fontsize = 16)\n",
    "\n",
    "plt.subplot(5, 1, 3, sharex = plt.subplot(5, 1, 1), sharey = plt.subplot(5, 1, 1))\n",
    "plt.plot(ll_df)\n",
    "for i in range(len(bursts_ll)):\n",
    "    plt.axvspan(bursts_ll[\"start\"].iloc[i], bursts_ll[\"end\"].iloc[i], color = 'b', alpha = 0.3)\n",
    "plt.ylabel(\"ACC (g)\", fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.legend([\"LL ACC\", \"Movement\"], loc = \"upper right\", fontsize = 16)\n",
    "\n",
    "plt.subplot(5, 1, 4, sharex = plt.subplot(5, 1, 1), sharey = plt.subplot(5, 1, 1))\n",
    "plt.plot(rl_df)\n",
    "for i in range(len(bursts_rl)):\n",
    "    plt.axvspan(bursts_rl[\"start\"].iloc[i], bursts_rl[\"end\"].iloc[i], color = 'b', alpha = 0.3)\n",
    "plt.ylabel(\"ACC (g)\", fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.legend([\"RL ACC\", \"Movement\"], loc = \"upper right\", fontsize = 16)\n",
    "\n",
    "plt.subplot(5, 1, 5, sharex = plt.subplot(5, 1, 1), sharey = plt.subplot(5, 1, 1))\n",
    "plt.plot(trunk_df)\n",
    "for i in range(len(bursts_trunk)):\n",
    "    plt.axvspan(bursts_trunk[\"start\"].iloc[i], bursts_trunk[\"end\"].iloc[i], color = 'b', alpha = 0.3)\n",
    "plt.ylabel(\"ACC (g)\", fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.legend([\"Trunk ACC\", \"Movement\"], loc = \"upper right\", fontsize = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all intervals into a list along with limb identifiers\n",
    "intervals = []\n",
    "intervals.extend((row['start'], row['end'], 'LL') for index, row in bursts_ll.iterrows())\n",
    "intervals.extend((row['start'], row['end'], 'LW') for index, row in bursts_lw.iterrows())\n",
    "intervals.extend((row['start'], row['end'], 'RL') for index, row in bursts_rl.iterrows())\n",
    "intervals.extend((row['start'], row['end'], 'RW') for index, row in bursts_rw.iterrows())\n",
    "intervals.extend((row['start'], row['end'], 'T') for index, row in bursts_trunk.iterrows())\n",
    "\n",
    "# Sort intervals by start time\n",
    "intervals.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((Timestamp('2024-02-28 23:00:01.590290070'),\n",
       "  Timestamp('2024-02-28 23:00:02.890290022'),\n",
       "  'LL'),\n",
       " (Timestamp('2024-02-28 23:00:01.781500101'),\n",
       "  Timestamp('2024-02-28 23:00:03.341500044'),\n",
       "  'RL'),\n",
       " (Timestamp('2024-02-28 23:00:01.804869890'),\n",
       "  Timestamp('2024-02-28 23:00:04.064870119'),\n",
       "  'T'),\n",
       " (Timestamp('2024-02-28 23:00:30.990289927'),\n",
       "  Timestamp('2024-02-28 23:00:31.560290098'),\n",
       "  'LL'),\n",
       " (Timestamp('2024-02-28 23:00:43.584870100'),\n",
       "  Timestamp('2024-02-28 23:00:44.704869986'),\n",
       "  'T'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals[0], intervals[1], intervals[2], intervals[3], intervals[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Limbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-28 23:00:01.590290070</td>\n",
       "      <td>2024-02-28 23:00:04.064870119</td>\n",
       "      <td>{T, RL, LL}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-28 23:00:30.990289927</td>\n",
       "      <td>2024-02-28 23:00:31.560290098</td>\n",
       "      <td>{LL}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-28 23:00:43.584870100</td>\n",
       "      <td>2024-02-28 23:00:44.704869986</td>\n",
       "      <td>{T}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-28 23:02:29.704869986</td>\n",
       "      <td>2024-02-28 23:02:31.704869986</td>\n",
       "      <td>{T, LW}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-28 23:03:31.105629921</td>\n",
       "      <td>2024-02-28 23:03:32.335629940</td>\n",
       "      <td>{T, LW}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2024-02-29 06:54:00.270289898</td>\n",
       "      <td>2024-02-29 06:54:01.020289898</td>\n",
       "      <td>{LL}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2024-02-29 07:00:06.070290089</td>\n",
       "      <td>2024-02-29 07:00:28.191499949</td>\n",
       "      <td>{T, LL, RL, RW, LW}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2024-02-29 07:03:13.620290041</td>\n",
       "      <td>2024-02-29 07:03:16.340290070</td>\n",
       "      <td>{LL}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2024-02-29 07:04:31.660290003</td>\n",
       "      <td>2024-02-29 07:04:32.970289946</td>\n",
       "      <td>{LL}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2024-02-29 07:06:48.565629959</td>\n",
       "      <td>2024-02-29 07:07:00.601500034</td>\n",
       "      <td>{T, LL, RL, RW, LW}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Start                           End  \\\n",
       "0   2024-02-28 23:00:01.590290070 2024-02-28 23:00:04.064870119   \n",
       "1   2024-02-28 23:00:30.990289927 2024-02-28 23:00:31.560290098   \n",
       "2   2024-02-28 23:00:43.584870100 2024-02-28 23:00:44.704869986   \n",
       "3   2024-02-28 23:02:29.704869986 2024-02-28 23:02:31.704869986   \n",
       "4   2024-02-28 23:03:31.105629921 2024-02-28 23:03:32.335629940   \n",
       "..                            ...                           ...   \n",
       "143 2024-02-29 06:54:00.270289898 2024-02-29 06:54:01.020289898   \n",
       "144 2024-02-29 07:00:06.070290089 2024-02-29 07:00:28.191499949   \n",
       "145 2024-02-29 07:03:13.620290041 2024-02-29 07:03:16.340290070   \n",
       "146 2024-02-29 07:04:31.660290003 2024-02-29 07:04:32.970289946   \n",
       "147 2024-02-29 07:06:48.565629959 2024-02-29 07:07:00.601500034   \n",
       "\n",
       "                   Limbs  \n",
       "0            {T, RL, LL}  \n",
       "1                   {LL}  \n",
       "2                    {T}  \n",
       "3                {T, LW}  \n",
       "4                {T, LW}  \n",
       "..                   ...  \n",
       "143                 {LL}  \n",
       "144  {T, LL, RL, RW, LW}  \n",
       "145                 {LL}  \n",
       "146                 {LL}  \n",
       "147  {T, LL, RL, RW, LW}  \n",
       "\n",
       "[148 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge overlapping intervals and label them\n",
    "merged_intervals = []\n",
    "current_start, current_end, current_limb = intervals[0]\n",
    "# current_limb = current_limb\n",
    "# print(current_limb)\n",
    "\n",
    "for start, end, limb in intervals[1:]:\n",
    "    if start <= current_end:  # There is an overlap\n",
    "        current_end = max(current_end, end)\n",
    "        if limb not in current_limb:\n",
    "            # print(current_limb)\n",
    "            # current_limb.add(limb)\n",
    "            current_limb += '+' + limb\n",
    "    else:\n",
    "        merged_intervals.append((current_start, current_end, current_limb))\n",
    "        current_start, current_end, current_limb = start, end, limb\n",
    "\n",
    "# Append the last interval\n",
    "merged_intervals.append((current_start, current_end, current_limb))\n",
    "merged_intervals = [(start, end, set(limbs_str.split('+'))) for start, end, limbs_str in merged_intervals]\n",
    "\n",
    "# Create a DataFrame for a cleaner view of the merged intervals\n",
    "df_merged_intervals = pd.DataFrame(merged_intervals, columns=['Start', 'End', 'Limbs'])\n",
    "df_merged_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_lw = {sub: 0 for sub in subjects}\n",
    "bursts_rw = {sub: 0 for sub in subjects}\n",
    "bursts_ll = {sub: 0 for sub in subjects}\n",
    "bursts_rl = {sub: 0 for sub in subjects}\n",
    "bursts_trunk = {sub: 0 for sub in subjects}\n",
    "SIB = {sub: 0 for sub in subjects}\n",
    "limbs_combinations = {sub: 0 for sub in subjects}\n",
    "for i, sub in enumerate(subjects):\n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/bursts.pkl', 'rb') as f:\n",
    "        bursts = pickle.load(f)\n",
    "    bursts_lw[sub] = bursts[\"lw\"]\n",
    "    bursts_rw[sub] = bursts[\"rw\"]\n",
    "    bursts_ll[sub] = bursts[\"ll\"]\n",
    "    bursts_rl[sub] = bursts[\"rl\"]\n",
    "    bursts_trunk[sub] = bursts[\"trunk\"]\n",
    "\n",
    "    # Combine all intervals into a list along with limb identifiers\n",
    "    intervals = []\n",
    "    intervals.extend((row['start'], row['end'], 'LL') for index, row in bursts_ll[sub].iterrows())\n",
    "    intervals.extend((row['start'], row['end'], 'LW') for index, row in bursts_lw[sub].iterrows())\n",
    "    intervals.extend((row['start'], row['end'], 'RL') for index, row in bursts_rl[sub].iterrows())\n",
    "    intervals.extend((row['start'], row['end'], 'RW') for index, row in bursts_rw[sub].iterrows())\n",
    "    intervals.extend((row['start'], row['end'], 'T') for index, row in bursts_trunk[sub].iterrows())\n",
    "\n",
    "    # Sort intervals by start time\n",
    "    intervals.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Merge overlapping intervals and label them\n",
    "    merged_intervals = []\n",
    "    current_start, current_end, current_limb = intervals[0]\n",
    "    # current_limb = current_limb\n",
    "    # print(current_limb)\n",
    "\n",
    "    for start, end, limb in intervals[1:]:\n",
    "        if start <= current_end:  # There is an overlap\n",
    "            current_end = max(current_end, end)\n",
    "            if limb not in current_limb:\n",
    "                current_limb += '+' + limb\n",
    "        else:\n",
    "            merged_intervals.append((current_start, current_end, current_limb))\n",
    "            current_start, current_end, current_limb = start, end, limb\n",
    "\n",
    "    # Append the last interval\n",
    "    merged_intervals.append((current_start, current_end, current_limb))\n",
    "    merged_intervals = [(start, end, set(limbs_str.split('+'))) for start, end, limbs_str in merged_intervals]\n",
    "\n",
    "    # Create a DataFrame for a cleaner view of the merged intervals\n",
    "    df_merged_intervals = pd.DataFrame(merged_intervals, columns=['Start', 'End', 'Limbs'])\n",
    "\n",
    "    limbs_comb = Counter(tuple(sorted(limbs)) for _, _, limbs in merged_intervals)\n",
    "    limbs_combinations_df = pd.DataFrame(limbs_comb.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df[\"sub_ID\"] = sub\n",
    "    limbs_combinations[sub] = limbs_combinations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "limbs_combinations_df_ALL = pd.concat(limbs_combinations.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sub_ID', ylabel='Count'>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limbs_comb_groupby = limbs_combinations_df_ALL.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "\n",
    "# Plot this information\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data = limbs_comb_groupby.reset_index(), x = \"sub_ID\", y = \"Count\", hue = \"Limbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.pie(limbs_combinations_df_ALL.groupby('Limbs').sum().sort_values(by='Count', ascending=False)['Count'], autopct='%1.1f%%');#, labels = limbs_combinations_df_ALL.groupby('Limbs').sum().sort_values(by='Count', ascending=False).index, autopct='%1.1f%%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of possible combinations\n",
    "- 1 limb (size 1): 5 combinations, one for each element.\n",
    "- 2 limbs (size 2): 10 combinations, each pair of elements.\n",
    "- 3 limbs (size 3): 10 combinations, each trio of elements.\n",
    "- 4 limbs (size 4): 5 combinations, each group excluding one element.\n",
    "- 5 limbs (size 5): 1 combination, all elements together.\n",
    "\n",
    "Total of 5+10+10+5+1 = 31 combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
