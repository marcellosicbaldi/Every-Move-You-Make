{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import neurokit2 as nk\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib qt\n",
    "mpl.rcParams['lines.linewidth'] = 0.91\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# sns.set_context(\"talk\")\n",
    "sns.set_palette(\"Set1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "from collections import Counter\n",
    "from functions.bursts import characterize_bursts\n",
    "from sleep_diary import diary_SPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplementary - raw acc SMV baseline change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "subjects = [\"158\", \"098\"]\n",
    "\n",
    "diary_SPT = {    \n",
    "    \"158\": [pd.Timestamp('2024-02-28 23:00:00'), pd.Timestamp('2024-02-29 07:15:00')], # 158 OK\n",
    "    \"098\": [pd.Timestamp('2024-03-16 02:01:00'), pd.Timestamp('2024-03-16 09:50:00')], # 098 OK\n",
    "}\n",
    "\n",
    "TH_WRIST = 20\n",
    "TH_ANKLE = 15\n",
    "TH_TRUNK = 15\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "\n",
    "    print(sub)\n",
    "\n",
    "    start_sleep, end_sleep = diary_SPT[sub]\n",
    "    lw_df = pd.read_pickle(f\"/Volumes/Untitled/rehab/data/{sub}/acc_night/lw.pkl\") * 1000\n",
    "    lw_df_bp = pd.Series(nk.signal_filter(lw_df.values, sampling_rate = 100, lowcut=0.1, highcut=10, method='butterworth', order=8), index = lw_df.index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmin, lmax = hl_envelopes_idx(lw_df.values, dmin=5, dmax=5)\n",
    "upper_envelope = lw_df.values[lmax]\n",
    "lower_envelope = lw_df.values[lmin]\n",
    "env_diff = pd.Series(lw_df.values[lmax] - lw_df.values[lmin], index = lw_df.index[lmax])\n",
    "upper_envelope_res = np.interp(np.arange(len(lw_df)), lmax, upper_envelope)\n",
    "lower_envelope_res = np.interp(np.arange(len(lw_df)), lmin, lower_envelope)\n",
    "env_diff_res = pd.Series(upper_envelope_res - lower_envelope_res, index = lw_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdf3df049d0>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(lw_df, 'k')\n",
    "plt.plot(lw_df.index[lmin], lw_df.values[lmin], color = 'r', linewidth = 1.6)\n",
    "plt.plot(lw_df.index[lmax], lw_df.values[lmax], color = 'g', linewidth = 1.6)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel(\"ACC (mg)\", fontsize = 16)\n",
    "plt.legend([\"Accelerometer SMV\", \"Low envelope\", \"High envelope\"], loc = \"upper left\", frameon = True, fancybox = True, shadow = True, fontsize = 16)\n",
    "plt.subplot(2, 1, 2, sharex = plt.subplot(2, 1, 1))\n",
    "plt.plot(env_diff_res, 'b', linewidth = 1.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods - Envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hl_envelopes_idx(s, dmin=1, dmax=1, split=False, plot = True):\n",
    "    \"\"\"\n",
    "    Compute high and low envelopes of a signal s\n",
    "    Parameters\n",
    "    ----------\n",
    "    s: 1d-array, data signal from which to extract high and low envelopes\n",
    "    dmin, dmax: int, optional, size of chunks, use this if the size of the input signal is too big\n",
    "    split: bool, optional, if True, split the signal in half along its mean, might help to generate the envelope in some cases\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lmin,lmax : high/low envelope idx of input signal s\n",
    "    \"\"\"\n",
    "\n",
    "    # locals min      \n",
    "    lmin = (np.diff(np.sign(np.diff(s))) > 0).nonzero()[0] + 1 \n",
    "    # locals max\n",
    "    lmax = (np.diff(np.sign(np.diff(s))) < 0).nonzero()[0] + 1 \n",
    "    \n",
    "    if split:\n",
    "        # s_mid is zero if s centered around x-axis or more generally mean of signal\n",
    "        s_mid = np.mean(s) \n",
    "        # pre-sorting of locals min based on relative position with respect to s_mid \n",
    "        lmin = lmin[s[lmin]<s_mid]\n",
    "        # pre-sorting of local max based on relative position with respect to s_mid \n",
    "        lmax = lmax[s[lmax]>s_mid]\n",
    "\n",
    "    # global min of dmin-chunks of locals min \n",
    "    lmin = lmin[[i+np.argmin(s[lmin[i:i+dmin]]) for i in range(0,len(lmin),dmin)]]\n",
    "    # global max of dmax-chunks of locals max \n",
    "    lmax = lmax[[i+np.argmax(s[lmax[i:i+dmax]]) for i in range(0,len(lmax),dmax)]]\n",
    "\n",
    "    return lmin, lmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "subjects = [\"158\", \"098\"]\n",
    "\n",
    "diary_SPT = {    \n",
    "    \"158\": [pd.Timestamp('2024-02-28 23:00:00'), pd.Timestamp('2024-02-29 07:15:00')], # 158 OK\n",
    "    \"098\": [pd.Timestamp('2024-03-16 02:01:00'), pd.Timestamp('2024-03-16 09:50:00')], # 098 OK\n",
    "}\n",
    "\n",
    "TH_WRIST = 20\n",
    "TH_ANKLE = 15\n",
    "TH_TRUNK = 15\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "\n",
    "    print(sub)\n",
    "\n",
    "    start_sleep, end_sleep = diary_SPT[sub]\n",
    "    lw_df = pd.read_pickle(f\"/Volumes/Untitled/rehab/data/{sub}/acc_night/lw.pkl\") * 1000\n",
    "    lw_df_bp = pd.Series(nk.signal_filter(lw_df.values, sampling_rate = 100, lowcut=0.1, highcut=10, method='butterworth', order=8), index = lw_df.index)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmin, lmax = hl_envelopes_idx(lw_df_bp.values, dmin=5, dmax=5)\n",
    "upper_envelope = lw_df_bp.values[lmax]\n",
    "lower_envelope = lw_df_bp.values[lmin]\n",
    "env_diff = pd.Series(lw_df_bp.values[lmax] - lw_df_bp.values[lmin], index = lw_df_bp.index[lmax])\n",
    "upper_envelope_res = np.interp(np.arange(len(lw_df_bp)), lmax, upper_envelope)\n",
    "lower_envelope_res = np.interp(np.arange(len(lw_df_bp)), lmin, lower_envelope)\n",
    "env_diff_res = pd.Series(upper_envelope_res - lower_envelope_res, index = lw_df_bp.index)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(lw_df_bp, 'k')\n",
    "plt.plot(lw_df_bp.index[lmin], lw_df_bp.values[lmin], color = 'r', linewidth = 1.6)\n",
    "plt.plot(lw_df_bp.index[lmax], lw_df_bp.values[lmax], color = 'g', linewidth = 1.6)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel(\"ACC (mg)\", fontsize = 16)\n",
    "plt.legend([\"Accelerometer SMV\", \"Low envelope\", \"High envelope\"], loc = \"upper left\", frameon = True, fancybox = True, shadow = True, fontsize = 16)\n",
    "plt.subplot(2, 1, 2, sharex = plt.subplot(2, 1, 1))\n",
    "plt.plot(env_diff_res, 'b', linewidth = 1.9)\n",
    "plt.xlim(pd.Timestamp('2024-02-28 23:45:47.2'), pd.Timestamp('2024-02-28 23:50:50.6'))\n",
    "start_fill = pd.Timestamp('2024-02-28 23:48:47.67')\n",
    "# end_fill = pd.Timestamp('2024-02-28 23:48:50.6')\n",
    "# fill between env_diff above threshold\n",
    "# plt.fill_between(env_diff.index, env_diff, np.percentile(env_diff, 10) * 15, where = env_diff > np.percentile(env_diff, 10) * 15, color = 'r', alpha = 0.3)\n",
    "# plt.fill_between([start_fill, end_fill], env_diff.loc[start_fill:end_fill].min(), env_diff.loc[start_fill:end_fill].max(), color = 'r', alpha = 0.3)\n",
    "plt.axhline(np.percentile(env_diff, 10) * 15, color = 'r', linewidth = 1.2, linestyle = '--')\n",
    "plt.axvline(start_fill, color = 'black', linewidth = 1.6, linestyle = '--')\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.xlabel(\"Time\", fontsize = 19)\n",
    "plt.ylabel(\"Envelopes difference (mg)\", fontsize = 16)\n",
    "plt.legend([\"Envelopes difference\", \"Threshold\", \"Movement onset\"], loc = \"upper left\", frameon = True, fancybox = True, shadow = True, fontsize = 16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Documents/GitHub/Movement-HR-Sleep/figures/paper/acc_envelopes_100hz.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834, 15)\n"
     ]
    }
   ],
   "source": [
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\"]\n",
    "bursts_HR = pd.read_pickle(\"/Volumes/Untitled/rehab/data/bursts_HR_ACC_final.pkl\")\n",
    "bursts_HR[\"ACC_response\"] = bursts_HR[\"ACC_response\"].apply(lambda x: np.array(x))\n",
    "print(bursts_HR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pie during sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_lw = {sub: 0 for sub in subjects}\n",
    "bursts_rw = {sub: 0 for sub in subjects}\n",
    "bursts_ll = {sub: 0 for sub in subjects}\n",
    "bursts_rl = {sub: 0 for sub in subjects}\n",
    "bursts_trunk = {sub: 0 for sub in subjects}\n",
    "SIB = {sub: 0 for sub in subjects}\n",
    "\n",
    "limbs_combinations_tot = {sub: 0 for sub in subjects}\n",
    "limbs_combinations_sleep = {sub: 0 for sub in subjects}\n",
    "limbs_combinations_awake = {sub: 0 for sub in subjects}\n",
    "limbs_combinations1part_sleep = {sub: 0 for sub in subjects}\n",
    "limbs_combinations1part_awake = {sub: 0 for sub in subjects}\n",
    "limbs_combinations2part_sleep = {sub: 0 for sub in subjects}\n",
    "limbs_combinations2part_awake = {sub: 0 for sub in subjects}\n",
    "\n",
    "part2_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms2.out/\"\n",
    "part3_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms3.out/\"\n",
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\", \"127\", \"914\", \"965\"]\n",
    "\n",
    "SIB_GGIR = {sub: pyreadr.read_r(part3_outputFolder + \"LW_\" + sub + \".CWA.RData\")['sib.cla.sum'][[\"sib.onset.time\", \"sib.end.time\"]] for sub in subjects}\n",
    "\n",
    "main_movements_sleep = [{'LL', 'LW', 'RL', 'RW', 'T'},\n",
    "{'LW'},\n",
    "{'RW'},\n",
    "{'RL'},\n",
    "{'LL'},\n",
    "{'RL', 'LL'},\n",
    "{'LL', 'RL', 'T'},\n",
    "]\n",
    "\n",
    "main_movements_wake= [{'LL', 'LW', 'RL', 'RW', 'T'},\n",
    "{'LW'},\n",
    "]\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "\n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/bursts_FINAL_envInterp.pkl', 'rb') as f:\n",
    "        bursts = pickle.load(f)\n",
    "\n",
    "    # df_merged:intervals containts all the bursts \n",
    "    df_merged_intervals = characterize_bursts(bursts)\n",
    "\n",
    "    # Optional: replace any other limb combinations with 'Other'\n",
    "    #df_merged_intervals[\"Limbs\"] = df_merged_intervals[\"Limbs\"].apply(lambda x: x if set(x) in main_movements_sleep else \"X\")\n",
    "\n",
    "    # Add SIB information from GGIR\n",
    "    SIB_GGIR[sub][\"sib.onset.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.onset.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.end.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.end.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.duration\"] = SIB_GGIR[sub][\"sib.end.time\"] - SIB_GGIR[sub][\"sib.onset.time\"]\n",
    "\n",
    "    spt_start = diary_SPT[sub][0] - pd.Timedelta('5 min')\n",
    "    spt_end = diary_SPT[sub][1] + pd.Timedelta('5 min')\n",
    "\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "    \n",
    "    SIB[sub][\"awake.duration\"] = SIB[sub][\"sib.onset.time\"].shift(-1) - SIB[sub][\"sib.end.time\"]\n",
    "\n",
    "    SIB[sub][\"sub_ID\"] = sub\n",
    "\n",
    "    # Find bursts that overlap with SIB\n",
    "    df_merged_intervals[\"SIB\"] = 0\n",
    "    for i, row in SIB[sub].iterrows():\n",
    "        df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= row[\"sib.onset.time\"] + pd.Timedelta(\"5s\")) & (df_merged_intervals[\"End\"] <= row[\"sib.end.time\"] - pd.Timedelta(\"5s\")), \"SIB\"] = 1\n",
    "\n",
    "    #### Count the number of occurrences of each limb combination ####\n",
    "\n",
    "    # Total\n",
    "    limbs_comb_tot = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals[\"Limbs\"])\n",
    "    limbs_combinations_tot_df = pd.DataFrame(limbs_comb_tot.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_tot_df[\"sub_ID\"] = sub\n",
    "    limbs_combinations_tot[sub] = limbs_combinations_tot_df\n",
    "\n",
    "    # Sleep\n",
    "    limbs_combination_sleep = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals[df_merged_intervals[\"SIB\"] == 1][\"Limbs\"])\n",
    "    limbs_combination_sleep_df = pd.DataFrame(limbs_combination_sleep.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combination_sleep_df[\"sub_ID\"] = sub\n",
    "    limbs_combinations_sleep[sub] = limbs_combination_sleep_df\n",
    "\n",
    "    # Awake\n",
    "    limbs_combination_awake = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals[df_merged_intervals[\"SIB\"] == 0][\"Limbs\"])\n",
    "    limbs_combination_awake_df = pd.DataFrame(limbs_combination_awake.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combination_awake_df[\"sub_ID\"] = sub\n",
    "    limbs_combinations_awake[sub] = limbs_combination_awake_df\n",
    "\n",
    "    #### First part VS second part of the night ####\n",
    "    start_sleep, end_sleep = diary_SPT[sub]\n",
    "    sleep_midpoint = start_sleep + (end_sleep - start_sleep) / 2\n",
    "\n",
    "    df_merged_intervals_1 = df_merged_intervals[df_merged_intervals[\"Start\"] < sleep_midpoint]\n",
    "    df_merged_intervals_2 = df_merged_intervals[df_merged_intervals[\"Start\"] >= sleep_midpoint]\n",
    "\n",
    "    limbs_comb_1_sleep = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_1[df_merged_intervals_1[\"SIB\"] == 1][\"Limbs\"])\n",
    "    limbs_comb_1_awake = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_1[df_merged_intervals_1[\"SIB\"] == 0][\"Limbs\"])\n",
    "    limbs_comb_2_sleep = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_2[df_merged_intervals_2[\"SIB\"] == 1][\"Limbs\"])\n",
    "    limbs_comb_2_awake = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_2[df_merged_intervals_2[\"SIB\"] == 0][\"Limbs\"])\n",
    "\n",
    "    limbs_combinations_df_1_sleep = pd.DataFrame(limbs_comb_1_sleep.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_1_sleep[\"sub_ID\"] = sub\n",
    "    limbs_combinations_df_1_awake = pd.DataFrame(limbs_comb_1_awake.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_1_awake[\"sub_ID\"] = sub\n",
    "\n",
    "    limbs_combinations_df_2_sleep = pd.DataFrame(limbs_comb_2_sleep.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_2_sleep[\"sub_ID\"] = sub\n",
    "    limbs_combinations_df_2_awake = pd.DataFrame(limbs_comb_2_awake.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_2_awake[\"sub_ID\"] = sub\n",
    "\n",
    "    limbs_combinations1part_sleep[sub] = limbs_combinations_df_1_sleep\n",
    "    limbs_combinations1part_awake[sub] = limbs_combinations_df_1_awake\n",
    "    limbs_combinations2part_sleep[sub] = limbs_combinations_df_2_sleep\n",
    "    limbs_combinations2part_awake[sub] = limbs_combinations_df_2_awake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "limbs_combinations_tot_df_ALL = pd.concat(limbs_combinations_tot.values(), ignore_index=True)\n",
    "limbs_combinations_sleep_df_ALL = pd.concat(limbs_combinations_sleep.values(), ignore_index=True)\n",
    "limbs_combinations_awake_df_ALL = pd.concat(limbs_combinations_awake.values(), ignore_index=True)\n",
    "limbs_combinations1part_sleep_df_ALL = pd.concat(limbs_combinations1part_sleep .values(), ignore_index=True)\n",
    "limbs_combinations1part_awake_df_ALL = pd.concat(limbs_combinations1part_awake .values(), ignore_index=True)\n",
    "limbs_combinations2part_sleep_df_ALL = pd.concat(limbs_combinations2part_sleep .values(), ignore_index=True)\n",
    "limbs_combinations2part_awake_df_ALL = pd.concat(limbs_combinations2part_awake .values(), ignore_index=True)\n",
    "\n",
    "limbs_comb_groupby = limbs_combinations_tot_df_ALL.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "limbs_comb_sleep_groupby = limbs_combinations_sleep_df_ALL.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "limbs_comb_awake_groupby = limbs_combinations_awake_df_ALL.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Limbs,sub_ID'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sleep.plot(kind = 'bar', figsize = (10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Limbs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Limbs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m count_sleep_upper_lower_full \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39marray((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      6\u001b[0m count_sleep_upper_lower_full\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLower\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m count_sleep_upper_lower_full[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLower\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m count_sleep[\u001b[43mcount_sleep\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLimbs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLL\u001b[39m\u001b[38;5;124m\"\u001b[39m,)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m count_sleep[count_sleep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimbs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRL\u001b[39m\u001b[38;5;124m\"\u001b[39m,)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m count_sleep[count_sleep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimbs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRL\u001b[39m\u001b[38;5;124m\"\u001b[39m)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m count_sleep[count_sleep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimbs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \n\u001b[1;32m      9\u001b[0m count_sleep_upper_lower_full[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m count_sleep[count_sleep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimbs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLW\u001b[39m\u001b[38;5;124m\"\u001b[39m,)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m count_sleep[count_sleep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimbs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRW\u001b[39m\u001b[38;5;124m\"\u001b[39m,)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m count_sleep[count_sleep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimbs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLW\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRW\u001b[39m\u001b[38;5;124m\"\u001b[39m)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m count_sleep[count_sleep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimbs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLW\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRW\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     10\u001b[0m count_sleep_upper_lower_full[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m count_sleep[count_sleep[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLimbs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLW\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRW\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m\"\u001b[39m)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCount\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Limbs'"
     ]
    }
   ],
   "source": [
    "count_sleep = pd.DataFrame(limbs_combinations_sleep_df_ALL.groupby(['Limbs', \"sub_ID\"]).sum().sort_values(by='Count', ascending=False)['Count'])\n",
    "#count_sleep[\"Limbs\"] = count_sleep.index\n",
    "#count_sleep.reset_index(drop = True, inplace = True)\n",
    "\n",
    "count_sleep_upper_lower_full = pd.DataFrame(np.array((1,2,3))).T\n",
    "count_sleep_upper_lower_full.columns = [\"Lower\", \"Upper\", \"Full\"]\n",
    "\n",
    "count_sleep_upper_lower_full[\"Lower\"] = count_sleep[count_sleep[\"Limbs\"] == (\"LL\",)][\"Count\"].values[0] + count_sleep[count_sleep[\"Limbs\"] == (\"RL\",)][\"Count\"].values[0] + count_sleep[count_sleep[\"Limbs\"] == (\"LL\", \"RL\")][\"Count\"].values[0] + count_sleep[count_sleep[\"Limbs\"] == (\"LL\", \"RL\", \"T\")][\"Count\"].values[0] \n",
    "count_sleep_upper_lower_full[\"Upper\"] = count_sleep[count_sleep[\"Limbs\"] == (\"LW\",)][\"Count\"].values[0] + count_sleep[count_sleep[\"Limbs\"] == (\"RW\",)][\"Count\"].values[0] + count_sleep[count_sleep[\"Limbs\"] == (\"LW\", \"RW\")][\"Count\"].values[0] + count_sleep[count_sleep[\"Limbs\"] == (\"LW\", \"RW\", \"T\")][\"Count\"].values[0]\n",
    "count_sleep_upper_lower_full[\"Full\"] = count_sleep[count_sleep[\"Limbs\"] == (\"LL\", \"LW\", \"RL\", \"RW\", \"T\")][\"Count\"].values[0]\n",
    "count_sleep_upper_lower_full\n",
    "\n",
    "count_wake = pd.DataFrame(limbs_combinations_awake_df_ALL.groupby('Limbs').sum().sort_values(by='Count', ascending=False)['Count'])\n",
    "count_wake[\"Limbs\"] = count_wake.index\n",
    "count_wake.reset_index(drop = True, inplace = True)\n",
    "\n",
    "count_wake_upper_lower_full = pd.DataFrame(np.array((1,2,3))).T\n",
    "count_wake_upper_lower_full.columns = [\"Lower\", \"Upper\", \"Full\"]\n",
    "\n",
    "count_wake_upper_lower_full[\"Lower\"] = count_wake[count_wake[\"Limbs\"] == (\"LL\",)][\"Count\"].values[0] + count_wake[count_wake[\"Limbs\"] == (\"RL\",)][\"Count\"].values[0] + count_wake[count_wake[\"Limbs\"] == (\"LL\", \"RL\")][\"Count\"].values[0] + count_wake[count_wake[\"Limbs\"] == (\"LL\", \"RL\", \"T\")][\"Count\"].values[0]\n",
    "count_wake_upper_lower_full[\"Upper\"] = count_wake[count_wake[\"Limbs\"] == (\"LW\",)][\"Count\"].values[0] + count_wake[count_wake[\"Limbs\"] == (\"RW\",)][\"Count\"].values[0] + count_wake[count_wake[\"Limbs\"] == (\"LW\", \"RW\")][\"Count\"].values[0] + count_wake[count_wake[\"Limbs\"] == (\"LW\", \"RW\", \"T\")][\"Count\"].values[0]\n",
    "count_wake_upper_lower_full[\"Full\"] = count_wake[count_wake[\"Limbs\"] == (\"LL\", \"LW\", \"RL\", \"RW\", \"T\")][\"Count\"].values[0]\n",
    "count_wake_upper_lower_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.pie(count_sleep_upper_lower_full.iloc[0, :].values, labels = count_sleep_upper_lower_full.columns, autopct='.2f', textprops={'fontsize': 18});\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.pie(count_wake_upper_lower_full.iloc[0, :].values, labels = count_wake_upper_lower_full.columns, autopct='.2f', textprops={'fontsize': 18});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sleep[count_sleep[\"Limbs\"] == (\"LW\",)][\"Count\"].values[0] + count_sleep[count_sleep[\"Limbs\"] == (\"RW\",)][\"Count\"].values[0] + count_sleep[count_sleep[\"Limbs\"] == (\"LW\", \"RW\")][\"Count\"].values[0] + count_sleep[count_sleep[\"Limbs\"] == (\"LW\", \"RW\", \"T\")][\"Count\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(count_sleep.index == {\"LW\", \"RW\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_sleep.index == {\"LW\", \"RW\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize = (8,8))\n",
    "# # Whole SPT\n",
    "# plt.pie(limbs_combinations_tot_df_ALL.groupby('Limbs').sum().sort_values(by='Count', ascending=False)['Count'], \n",
    "#         labels = limbs_combinations_tot_df_ALL.groupby('Limbs').sum().sort_values(by='Count', ascending=False).index, \n",
    "#         autopct='%1.1f%%', textprops={'fontsize': 19});\n",
    "# plt.title(\"SPT\", fontsize = 21)\n",
    "#plt.savefig(\"/Users/marcellosicbaldi/Documents/GitHub/Movement-HR-Sleep/figures/pie_wholeSPT.png\", dpi = 300, bbox_inches = 'tight')\n",
    "\n",
    "count_sleep = limbs_combinations_sleep_df_ALL.groupby('Limbs').sum().sort_values(by='Count', ascending=False)['Count']\n",
    "count_sleep_labels = [\"All limbs\", \"Other\\nCombination\", \"Non-dominant\\nWrist\", \"Dominant\\nWrist\", \"Dominant\\nAnkle\", \"Non-dominant\\nAnkle\", \"Ankles\\ntogether\", \"Ankles\\nand Trunk\\ntogether\"]\n",
    "count_wake = limbs_combinations_awake_df_ALL.groupby('Limbs').sum().sort_values(by='Count', ascending=False)['Count']\n",
    "count_wake_labels = [\"All limbs\", \"Other\\nCombination\", \"Non-dominant\\nWrist\"]\n",
    "\n",
    "# Sleep\n",
    "# plt.figure(figsize = (8,8))\n",
    "# plt.pie(count_sleep, \n",
    "#         labels = count_sleep_labels, \n",
    "#         autopct='%1.1f%%', textprops={'fontsize': 18});\n",
    "# plt.title(\"Sleep\", fontsize = 24)\n",
    "# plt.savefig(\"/Users/marcellosicbaldi/Documents/GitHub/Movement-HR-Sleep/figures/paper/pie_sleep.png\", dpi = 300, bbox_inches = 'tight')\n",
    "\n",
    "colors_wake = [sns.color_palette(\"Set1\")[1], sns.color_palette(\"Set1\")[0], sns.color_palette(\"Set1\")[2], sns.color_palette(\"Set1\")[3], sns.color_palette(\"Set1\")[4], sns.color_palette(\"Set1\")[5], sns.color_palette(\"Set1\")[6]]\n",
    "# Awake - be consistent with the colors of the limbs\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.pie(count_wake, \n",
    "        labels = count_wake_labels,  #colors = colors_wake,\n",
    "        autopct='%1.1f%%', textprops={'fontsize': 19})\n",
    "plt.title(\"Wake\", fontsize = 24)\n",
    "\n",
    "# plt.savefig(\"/Users/marcellosicbaldi/Documents/GitHub/Movement-HR-Sleep/figures/paper/pie_wake.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby_sleep = limbs_combinations_sleep_df_ALL.groupby(['Limbs', 'sub_ID']).sum().sort_values(by='Count', ascending=False)['Count'].unstack()\n",
    "df_groupby_wake = limbs_combinations_awake_df_ALL.groupby(['Limbs', 'sub_ID']).sum().sort_values(by='Count', ascending=False)['Count'].unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df_groupby_sleep / df_groupby_sleep.sum()).mean(axis = 1).sort_values(ascending = False)*100)\n",
    "\n",
    "(df_groupby_sleep / df_groupby_sleep.sum()).std(axis = 1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limbs\n",
      "(LL, LW, RL, RW, T)    63.001061\n",
      "(X,)                   16.160446\n",
      "(LW,)                   7.545567\n",
      "(RW,)                   5.472402\n",
      "(RL,)                   4.618295\n",
      "(LL, RL)                3.651139\n",
      "(LL,)                   3.507586\n",
      "(LL, RL, T)             3.217214\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Limbs\n",
       "(LL,)                  2.381243\n",
       "(LL, LW, RL, RW, T)    9.656417\n",
       "(LL, RL)               3.596918\n",
       "(LL, RL, T)            1.207840\n",
       "(LW,)                  5.853460\n",
       "(RL,)                  5.282616\n",
       "(RW,)                  2.722388\n",
       "(X,)                   6.515810\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((df_groupby_wake / df_groupby_wake.sum()).mean(axis = 1).sort_values(ascending = False)*100)\n",
    "\n",
    "(df_groupby_wake / df_groupby_wake.sum()).std(axis = 1)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Sleep')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, ax = plt.subplots(4, 3, figsize = (16, 8))\n",
    "for i, sub in enumerate(subjects):\n",
    "    df_groupby_sleep[sub].plot(kind = 'pie', ax = ax[i // 3, i % 3], color = sns.color_palette(\"Paired\", n_colors = 12), legend = False, labels = None)\n",
    "    print(i)\n",
    "plt.tight_layout(h_pad=-2, w_pad=-22)\n",
    "plt.suptitle(\"Sleep\", fontsize = 21)\n",
    "\n",
    "# f, ax = plt.subplots(4, 3, figsize = (16, 8))\n",
    "# for i, sub in enumerate(subjects):\n",
    "#     df_groupby_wake[sub].plot(kind = 'pie', ax = ax[i // 3, i % 3], color = sns.color_palette(\"Paired\", n_colors = 12), legend = False)\n",
    "# plt.suptitle(\"Wake\", fontsize = 21)\n",
    "\n",
    "# df_groupby_wake.plot(kind = 'pie', figsize = (8, 6), color = sns.color_palette(\"Paired\", n_colors = 12), subplots = True)\n",
    "# plt.title(\"Wake\", fontsize = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24187725631768953"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limbs_combinations_sleep_df_ALL.groupby('Limbs').sum().sort_values(by='Count', ascending=False)['Count'].iloc[0] / limbs_combinations_sleep_df_ALL.groupby('Limbs').sum().sort_values(by='Count', ascending=False)['Count'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st part vs 2nd part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_lw = {sub: 0 for sub in subjects}\n",
    "bursts_rw = {sub: 0 for sub in subjects}\n",
    "bursts_ll = {sub: 0 for sub in subjects}\n",
    "bursts_rl = {sub: 0 for sub in subjects}\n",
    "bursts_trunk = {sub: 0 for sub in subjects}\n",
    "SIB = {sub: 0 for sub in subjects}\n",
    "limbs_combinations1part = {sub: 0 for sub in subjects}\n",
    "limbs_combinations2part = {sub: 0 for sub in subjects}\n",
    "limbs_combinations3part = {sub: 0 for sub in subjects}\n",
    "limbs_combinations1part_sleep = {sub: 0 for sub in subjects}\n",
    "limbs_combinations1part_awake = {sub: 0 for sub in subjects}\n",
    "limbs_combinations2part_sleep = {sub: 0 for sub in subjects}\n",
    "limbs_combinations2part_awake = {sub: 0 for sub in subjects}\n",
    "sleep_time_part1 = {sub: 0 for sub in subjects}\n",
    "sleep_time_part2 = {sub: 0 for sub in subjects}\n",
    "\n",
    "part2_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms2.out/\"\n",
    "part3_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms3.out/\"\n",
    "#subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\"]# \"127\", \"914\", \"965\"]\n",
    "\n",
    "SIB_GGIR = {sub: pyreadr.read_r(part3_outputFolder + \"LW_\" + sub + \".CWA.RData\")['sib.cla.sum'][[\"sib.onset.time\", \"sib.end.time\"]] for sub in subjects}\n",
    "\n",
    "main_movements = [{'LL', 'LW', 'RL', 'RW', 'T'},\n",
    "{'LW'},\n",
    "{'RW'},\n",
    "{'RL'},\n",
    "{'LL'},\n",
    "{'LL', 'RL', 'T'}]\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "    \n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/bursts_FINAL_envInterp.pkl', 'rb') as f:\n",
    "        bursts = pickle.load(f)\n",
    "    \n",
    "    df_merged_intervals = characterize_bursts(bursts)\n",
    "\n",
    "    # Movement bursts distribution throughout the night\n",
    "    start_sleep, end_sleep = diary_SPT[sub]\n",
    "\n",
    "    #### DIVIDE SLEEP in two parts ####\n",
    "\n",
    "    sleep_midpoint = start_sleep + (end_sleep - start_sleep) / 2\n",
    "    # print(start_sleep, end_sleep, sleep_midpoint)\n",
    "\n",
    "    df_merged_intervals[\"Limbs\"] = df_merged_intervals[\"Limbs\"].apply(lambda x: x if set(x) in main_movements else \"X\")\n",
    "\n",
    "    SIB_GGIR[sub][\"sib.onset.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.onset.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.end.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.end.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.duration\"] = SIB_GGIR[sub][\"sib.end.time\"] - SIB_GGIR[sub][\"sib.onset.time\"]\n",
    "\n",
    "    spt_start = diary_SPT[sub][0] - pd.Timedelta('10 min')\n",
    "    spt_end = diary_SPT[sub][1] + pd.Timedelta('10 min')\n",
    "\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "\n",
    "    SIB[sub][\"part\"] = np.where(SIB[sub][\"sib.onset.time\"] < sleep_midpoint, \"First Half\", \"Second Half\")\n",
    "    sleep_time_part1[sub] = SIB[sub][SIB[sub][\"part\"] == \"First Half\"][\"sib.duration\"].sum()\n",
    "    sleep_time_part2[sub] = SIB[sub][SIB[sub][\"part\"] == \"Second Half\"][\"sib.duration\"].sum()\n",
    "    \n",
    "    SIB[sub][\"awake.duration\"] = SIB[sub][\"sib.onset.time\"].shift(-1) - SIB[sub][\"sib.end.time\"]\n",
    "\n",
    "    SIB[sub][\"sub_ID\"] = sub\n",
    "\n",
    "    # Find bursts that overlap with SIB\n",
    "    df_merged_intervals[\"SIB\"] = 0\n",
    "    for i, row in SIB[sub].iterrows():\n",
    "        df_merged_intervals.loc[(df_merged_intervals[\"Start\"] <= row[\"sib.end.time\"]) & (df_merged_intervals[\"End\"] >= row[\"sib.onset.time\"]), \"SIB\"] = 1\n",
    "\n",
    "    # Separate df_merged_intervals from start sleep to midpoint\n",
    "    df_merged_intervals_1 = df_merged_intervals[df_merged_intervals[\"Start\"] < sleep_midpoint]\n",
    "    # Separate df_merged_intervals from midpoint to end sleep\n",
    "    df_merged_intervals_2 = df_merged_intervals[df_merged_intervals[\"Start\"] >= sleep_midpoint]\n",
    "\n",
    "    limbs_comb_1 = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_1[\"Limbs\"])\n",
    "    limbs_comb_2 = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_2[\"Limbs\"])\n",
    "\n",
    "    limbs_combinations_df_1 = pd.DataFrame(limbs_comb_1.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_1[\"sub_ID\"] = sub\n",
    "\n",
    "    limbs_combinations_df_2 = pd.DataFrame(limbs_comb_2.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_2[\"sub_ID\"] = sub\n",
    "\n",
    "    limbs_combinations1part[sub] = limbs_combinations_df_1\n",
    "    limbs_combinations2part[sub] = limbs_combinations_df_2\n",
    "\n",
    "    # part 1 sleep and wake\n",
    "    df_merged_intervals_1_sleep = df_merged_intervals_1[df_merged_intervals_1[\"SIB\"] == 1]\n",
    "    df_merged_intervals_1_awake = df_merged_intervals_1[df_merged_intervals_1[\"SIB\"] == 0]\n",
    "\n",
    "    limbs_comb_1_sleep = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_1_sleep[\"Limbs\"])\n",
    "    limbs_comb_1_awake = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_1_awake[\"Limbs\"])\n",
    "\n",
    "    limbs_combinations_df_1_sleep = pd.DataFrame(limbs_comb_1_sleep.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_1_sleep[\"sub_ID\"] = sub\n",
    "    limbs_combinations_df_1_awake = pd.DataFrame(limbs_comb_1_awake.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_1_awake[\"sub_ID\"] = sub\n",
    "\n",
    "    limbs_combinations1part_sleep[sub] = limbs_combinations_df_1_sleep\n",
    "    limbs_combinations1part_awake[sub] = limbs_combinations_df_1_awake\n",
    "\n",
    "    # part 2 sleep and wake\n",
    "    df_merged_intervals_2_sleep = df_merged_intervals_2[df_merged_intervals_2[\"SIB\"] == 1]\n",
    "    df_merged_intervals_2_awake = df_merged_intervals_2[df_merged_intervals_2[\"SIB\"] == 0]\n",
    "\n",
    "    limbs_comb_2_sleep = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_2_sleep[\"Limbs\"])\n",
    "    limbs_comb_2_awake = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_2_awake[\"Limbs\"])\n",
    "\n",
    "    limbs_combinations_df_2_sleep = pd.DataFrame(limbs_comb_2_sleep.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_2_sleep[\"sub_ID\"] = sub\n",
    "    limbs_combinations_df_2_awake = pd.DataFrame(limbs_comb_2_awake.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    limbs_combinations_df_2_awake[\"sub_ID\"] = sub\n",
    "\n",
    "    limbs_combinations2part_sleep[sub] = limbs_combinations_df_2_sleep\n",
    "    limbs_combinations2part_awake[sub] = limbs_combinations_df_2_awake\n",
    "\n",
    "\n",
    "    #### DIVIDE SLEEP in three parts ####\n",
    "    # sleep_upper_third = start_sleep + (end_sleep - start_sleep) / 3\n",
    "    # sleep_lower_third = start_sleep + 2 * (end_sleep - start_sleep) / 3\n",
    "\n",
    "    # df_merged_intervals_1 = df_merged_intervals[df_merged_intervals[\"Start\"] < sleep_upper_third]\n",
    "    # df_merged_intervals_2 = df_merged_intervals[(df_merged_intervals[\"Start\"] >= sleep_upper_third) & (df_merged_intervals[\"Start\"] < sleep_lower_third)]\n",
    "    # df_merged_intervals_3 = df_merged_intervals[df_merged_intervals[\"Start\"] >= sleep_lower_third]\n",
    "\n",
    "    # limbs_comb_1 = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_1[\"Limbs\"])\n",
    "    # limbs_comb_2 = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_2[\"Limbs\"])\n",
    "    # limbs_comb_3 = Counter(tuple(sorted(limbs)) for limbs in df_merged_intervals_3[\"Limbs\"])\n",
    "\n",
    "    # limbs_combinations_df_1 = pd.DataFrame(limbs_comb_1.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    # limbs_combinations_df_1[\"sub_ID\"] = sub\n",
    "\n",
    "    # limbs_combinations_df_2 = pd.DataFrame(limbs_comb_2.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    # limbs_combinations_df_2[\"sub_ID\"] = sub\n",
    "\n",
    "    # limbs_combinations_df_3 = pd.DataFrame(limbs_comb_3.items(), columns=['Limbs', 'Count']).sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    # limbs_combinations_df_3[\"sub_ID\"] = sub\n",
    "\n",
    "    # limbs_combinations1part[sub] = limbs_combinations_df_1\n",
    "    # limbs_combinations2part[sub] = limbs_combinations_df_2\n",
    "    # limbs_combinations3part[sub] = limbs_combinations_df_3\n",
    "\n",
    "limbs_combinations_df_ALL_1 = pd.concat(limbs_combinations1part.values(), ignore_index=True)\n",
    "limbs_combinations_df_ALL_2 = pd.concat(limbs_combinations2part.values(), ignore_index=True)\n",
    "limbs_combinations_df_sleep_ALL_1 = pd.concat(limbs_combinations1part_sleep.values(), ignore_index=True)\n",
    "limbs_combinations_df_sleep_ALL_2 = pd.concat(limbs_combinations2part_sleep.values(), ignore_index=True)\n",
    "limbs_combinations_df_awake_ALL_1 = pd.concat(limbs_combinations1part_awake.values(), ignore_index=True)\n",
    "limbs_combinations_df_awake_ALL_2 = pd.concat(limbs_combinations2part_awake.values(), ignore_index=True)\n",
    "# limbs_combinations_df_ALL_3 = pd.concat(limbs_combinations3part.values(), ignore_index=True)\n",
    "\n",
    "# Combine the two DFs\n",
    "limbs_combinations_df_ALL_1[\"part\"] = \"First Half\"\n",
    "limbs_combinations_df_ALL_2[\"part\"] = \"Second Half\"\n",
    "limbs_combinations_df_sleep_ALL_1[\"part\"] = \"First Half\"\n",
    "limbs_combinations_df_sleep_ALL_2[\"part\"] = \"Second Half\"\n",
    "limbs_combinations_df_awake_ALL_1[\"part\"] = \"First Half\"\n",
    "limbs_combinations_df_awake_ALL_2[\"part\"] = \"Second Half\"\n",
    "\n",
    "# limbs_combinations_df_ALL_3[\"part\"] = \"Third Half\"\n",
    "# limbs_combinations_df_1_and_2 = pd.concat([limbs_combinations_df_ALL_1, limbs_combinations_df_ALL_2], ignore_index=True)\n",
    "# limbs_combinations_df_1_and_2_and_3 = pd.concat([limbs_combinations_df_ALL_1, limbs_combinations_df_ALL_2, limbs_combinations_df_ALL_3], ignore_index=True)\n",
    "\n",
    "limbs_comb_groupby_1 = limbs_combinations_df_ALL_1.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "limbs_comb_groupby_2 = limbs_combinations_df_ALL_2.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "limbs_comb_groupby_sleep_1 = limbs_combinations_df_sleep_ALL_1.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "limbs_comb_groupby_sleep_2 = limbs_combinations_df_sleep_ALL_2.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "limbs_comb_groupby_awake_1 = limbs_combinations_df_awake_ALL_1.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "limbs_comb_groupby_awake_2 = limbs_combinations_df_awake_ALL_2.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "# limbs_comb_groupby_3 = limbs_combinations_df_ALL_3.groupby([\"Limbs\", \"sub_ID\"]).sum().sort_values(by = \"Count\", ascending = False)\n",
    "limbs_comb_groupby = pd.concat((limbs_comb_groupby_1, limbs_comb_groupby_2))\n",
    "limbs_comb_groupby_sleep = pd.concat((limbs_comb_groupby_sleep_1, limbs_comb_groupby_sleep_2))\n",
    "limbs_comb_groupby_awake = pd.concat((limbs_comb_groupby_awake_1, limbs_comb_groupby_awake_2))\n",
    "# limbs_comb_groupby = pd.concat((limbs_comb_groupby_1, limbs_comb_groupby_2, limbs_comb_groupby_3))\n",
    "\n",
    "# Plot this information\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# sns.barplot(data = limbs_comb_groupby_1.reset_index(), x = \"sub_ID\", y = \"Count\", hue = \"sub_ID\")#, hue = \"Limbs\")\n",
    "# plt.subplot(1, 2, 2, sharey = plt.subplot(1, 2, 1))\n",
    "# sns.barplot(data = limbs_comb_groupby_2.reset_index(), x = \"sub_ID\", y = \"Count\", hue = \"sub_ID\")#, hue = \"Limbs\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.pie(limbs_combinations_df_ALL_1.groupby('Limbs').sum().sort_values(by='Count', ascending=False)['Count'], labels = limbs_combinations_df_ALL_1.groupby('Limbs').sum().sort_values(by='Count', ascending=False).index, autopct='%1.1f%%');\n",
    "\n",
    "# plt.figure()\n",
    "# plt.pie(limbs_combinations_df_ALL_2.groupby('Limbs').sum().sort_values(by='Count', ascending=False)['Count'], labels = limbs_combinations_df_ALL_2.groupby('Limbs').sum().sort_values(by='Count', ascending=False).index, autopct='%1.1f%%');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/8pz3zwd53cv4xvdj2pstv1440000gn/T/ipykernel_7288/750191011.py:9: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '15.98360655737705' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"First Half\"] /= (sleep_time_part1[sub].total_seconds() / 3600)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Half</th>\n",
       "      <th>Second Half</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.811094</td>\n",
       "      <td>39.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.983607</td>\n",
       "      <td>20.358423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.337838</td>\n",
       "      <td>16.622114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.572491</td>\n",
       "      <td>39.183673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.641954</td>\n",
       "      <td>29.902661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.621622</td>\n",
       "      <td>40.229765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22.131737</td>\n",
       "      <td>36.016079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22.166477</td>\n",
       "      <td>24.114833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.328358</td>\n",
       "      <td>34.257095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   First Half  Second Half\n",
       "0   17.811094    39.219512\n",
       "1   15.983607    20.358423\n",
       "2   10.337838    16.622114\n",
       "3   14.572491    39.183673\n",
       "4   16.641954    29.902661\n",
       "5   25.621622    40.229765\n",
       "6   22.131737    36.016079\n",
       "7   22.166477    24.114833\n",
       "8   14.328358    34.257095"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limbs_comb_groupby_sleep_all_subjects_together = limbs_comb_groupby_sleep.groupby([\"sub_ID\", \"part\"]).sum()\n",
    "limbs_comb_groupby_sleep_all_subjects_together = limbs_comb_groupby_sleep.groupby([\"sub_ID\", \"part\"]).sum()\n",
    "data1 = []\n",
    "data2 = []\n",
    "\n",
    "# normalize to sleep duration\n",
    "\n",
    "for sub in subjects:\n",
    "    limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"First Half\"] /= (sleep_time_part1[sub].total_seconds() / 3600)\n",
    "    data1.append(limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"First Half\"])\n",
    "    limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"Second Half\"] /= (sleep_time_part2[sub].total_seconds() / 3600)\n",
    "    data2.append(limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"Second Half\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k1/8pz3zwd53cv4xvdj2pstv1440000gn/T/ipykernel_7288/3003289545.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '15.98360655737705' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"First Half\"] /= (sleep_time_part1[sub].total_seconds() / 3600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Burst frequency (n/h)')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limbs_comb_groupby_sleep_all_subjects_together = limbs_comb_groupby_sleep.groupby([\"sub_ID\", \"part\"]).sum()\n",
    "data1 = []\n",
    "data2 = []\n",
    "\n",
    "# normalize to sleep duration\n",
    "\n",
    "for sub in subjects:\n",
    "    limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"First Half\"] /= (sleep_time_part1[sub].total_seconds() / 3600)\n",
    "    data1.append(limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"First Half\"])\n",
    "    limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"Second Half\"] /= (sleep_time_part2[sub].total_seconds() / 3600)\n",
    "    data2.append(limbs_comb_groupby_sleep_all_subjects_together.loc[sub, \"Second Half\"])\n",
    "\n",
    "df_plot = limbs_comb_groupby_sleep_all_subjects_together.unstack()\n",
    "df_plot.columns = df_plot.columns.droplevel()\n",
    "df_plot = df_plot.reset_index(drop=True)\n",
    "df_plot.columns = [\"First Half\", \"Second Half\"]\n",
    "\n",
    "f, ax = plt.subplots(figsize = (8, 6))\n",
    "sns.boxplot(data = df_plot, palette = \"Set2\", fill = False, ax = ax, linewidth = 3.2, width = 0.68)\n",
    "jitter = 0.06\n",
    "df_x_jitter = pd.DataFrame(np.random.normal(loc=0, scale=jitter, size=df_plot.values.shape), columns=df_plot.columns,\n",
    "                            index = df_plot.index)\n",
    "df_x_jitter += np.arange(len(df_plot.columns))\n",
    "# Plot the markers\n",
    "for col in df_x_jitter:\n",
    "    for i in range(len(df_plot)):\n",
    "        ax.scatter(df_x_jitter[col][i], df_plot[col][i], s = 150, color = sns.color_palette(\"Set2\")[0],\n",
    "                    alpha=.6, edgecolors = \"black\", linewidth = 1.2)\n",
    "        if col == \"Second Half\":\n",
    "            ax.scatter(df_x_jitter[col][i], df_plot[col][i], s = 150, color = sns.color_palette(\"Set2\")[1],\n",
    "                    alpha=.6, edgecolors = \"black\", linewidth = 1.2)\n",
    "        \n",
    "for i, idx in enumerate(df_plot.index):\n",
    "    ax.plot(df_x_jitter.loc[idx,['First Half', 'Second Half']], df_plot\n",
    "            .loc[idx,['First Half', 'Second Half']], color = \"k\", linewidth = 0.9, alpha = 0.3, linestyle = '--', zorder = -1)\n",
    "\n",
    "plt.xticks(fontsize = 21)\n",
    "plt.yticks(fontsize = 21)\n",
    "plt.ylabel(\"Burst frequency (n/h)\", fontsize = 21)\n",
    "# Insert the asterisc for significant differences\n",
    "# x1, x2 = 0, 1   # columns 'Sat' and 'Sun' (first column: 0, see plt.xticks())\n",
    "# y, h, col = limbs_comb_groupby_sleep_all_subjects_together[\"Count\"].max() + 1.5, 1.5, 'k'\n",
    "# plt.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "# plt.text((x1+x2)*.5, y+h, \"p < 0.05\", ha='center', va='bottom', color=col, fontsize = 19)\n",
    "# # plt.text((x1+x2)*.5, y+h, \"**\", ha='center', va='bottom', color=col, fontsize = 31)\n",
    "# plt.ylim(5, y+h+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/boxplot_1st_vs_2nd_part.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>18.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.859548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.337838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>14.511458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.226524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.140422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.621622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count\n",
       "count  12.000000\n",
       "mean   18.292700\n",
       "std     4.859548\n",
       "min    10.337838\n",
       "25%    14.511458\n",
       "50%    17.226524\n",
       "75%    22.140422\n",
       "max    25.621622"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limbs_comb_groupby_sleep_all_subjects_together.reset_index()[limbs_comb_groupby_sleep_all_subjects_together.reset_index()[\"part\"] == \"First Half\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31.795495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.115342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.622114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.062823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.994967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.186952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>40.229765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Count\n",
       "count  12.000000\n",
       "mean   31.795495\n",
       "std     8.115342\n",
       "min    16.622114\n",
       "25%    26.062823\n",
       "50%    34.994967\n",
       "75%    39.186952\n",
       "max    40.229765"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limbs_comb_groupby_sleep_all_subjects_together.reset_index()[limbs_comb_groupby_sleep_all_subjects_together.reset_index()[\"part\"] == \"Second Half\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Documents/GitHub/Movement-HR-Sleep/figures/paper/boxplot_sleep_1st_2nd_part.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-statistic: 0.0, p-value: 0.00048828125\n"
     ]
    }
   ],
   "source": [
    "bursts1st_part = np.array([a.iloc[0] for a in data1])\n",
    "bursts2nd_part = np.array([a.iloc[0] for a in data2])\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "w_stat, p_value = stats.wilcoxon(bursts1st_part, bursts2nd_part)\n",
    "\n",
    "print(f\"W-statistic: {w_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results HR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOW VS MED VS HIGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834, 15)\n"
     ]
    }
   ],
   "source": [
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\"]\n",
    "bursts_HR = pd.read_pickle(\"/Volumes/Untitled/rehab/data/bursts_HR_ACC_final.pkl\")\n",
    "bursts_HR[\"ACC_response\"] = bursts_HR[\"ACC_response\"].apply(lambda x: np.array(x))\n",
    "print(bursts_HR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_HR_all_limbs = bursts_HR[bursts_HR[\"Limbs\"] == set((\"LL\", \"LW\", \"RL\", \"RW\", \"T\"))].reset_index(drop=True)\n",
    "# divide in low, med and high HR response based on the 1/3 and 2/3 percentiles\n",
    "HR_response_percentiles = bursts_HR_all_limbs.groupby(\"sub_ID\")[\"AUC\"].describe(percentiles=[1/3, 2/3])\n",
    "AUC_33 = HR_response_percentiles[\"33.3%\"]\n",
    "AUC_66 = HR_response_percentiles[\"66.7%\"]\n",
    "bursts_HR_all_limbs[\"HR_response_category\"] = \"medium\"\n",
    "for i, sub in enumerate(subjects):\n",
    "    bursts_HR_all_limbs.loc[(bursts_HR_all_limbs[\"sub_ID\"] == sub) & (bursts_HR_all_limbs[\"AUC\"] < AUC_33.loc[sub]), \"HR_response_category\"] = \"low\"\n",
    "    bursts_HR_all_limbs.loc[(bursts_HR_all_limbs[\"sub_ID\"] == sub) & (bursts_HR_all_limbs[\"AUC\"] > AUC_66.loc[sub]), \"HR_response_category\"] = \"high\"\n",
    "HR_response_SPT = bursts_HR_all_limbs.groupby([\"sub_ID\", \"HR_response_category\"])[\"HR_response_normalized\"].mean().unstack()\n",
    "sem_high_SPT = HR_response_SPT[\"high\"].to_numpy().std() / np.sqrt(HR_response_SPT[\"high\"].to_numpy().shape[0])\n",
    "sem_medium_SPT = HR_response_SPT[\"medium\"].to_numpy().std() / np.sqrt(HR_response_SPT[\"medium\"].to_numpy().shape[0])\n",
    "sem_low_SPT = HR_response_SPT[\"low\"].to_numpy().std() / np.sqrt(HR_response_SPT[\"low\"].to_numpy().shape[0])\n",
    "\n",
    "# Sleep\n",
    "bursts_HR_all_limbs_sleep = bursts_HR_all_limbs[bursts_HR_all_limbs[\"SIB\"] == 1].reset_index(drop=True)\n",
    "# divide in low, med and high HR response based on the 1/3 and 2/3 percentiles\n",
    "HR_response_percentiles = bursts_HR_all_limbs_sleep.groupby(\"sub_ID\")[\"AUC\"].describe(percentiles=[1/3, 2/3])\n",
    "AUC_33_sleep = HR_response_percentiles[\"33.3%\"]\n",
    "AUC_66_sleep = HR_response_percentiles[\"66.7%\"]\n",
    "bursts_HR_all_limbs_sleep[\"HR_response_category\"] = \"medium\"\n",
    "for i, sub in enumerate(subjects):\n",
    "    bursts_HR_all_limbs_sleep.loc[(bursts_HR_all_limbs_sleep[\"sub_ID\"] == sub) & (bursts_HR_all_limbs_sleep[\"AUC\"] < AUC_33_sleep.loc[sub]), \"HR_response_category\"] = \"low\"\n",
    "    bursts_HR_all_limbs_sleep.loc[(bursts_HR_all_limbs_sleep[\"sub_ID\"] == sub) & (bursts_HR_all_limbs_sleep[\"AUC\"] > AUC_66_sleep.loc[sub]), \"HR_response_category\"] = \"high\"\n",
    "HR_response_SLEEP = bursts_HR_all_limbs_sleep.groupby([\"sub_ID\", \"HR_response_category\"])[\"HR_response_normalized\"].mean().unstack()\n",
    "sem_high_SLEEP = HR_response_SLEEP[\"high\"].to_numpy().std() / np.sqrt(HR_response_SLEEP[\"high\"].to_numpy().shape[0])\n",
    "sem_medium_SLEEP = HR_response_SLEEP[\"medium\"].to_numpy().std() / np.sqrt(HR_response_SLEEP[\"medium\"].to_numpy().shape[0])\n",
    "sem_low_SLEEP = HR_response_SLEEP[\"low\"].to_numpy().std() / np.sqrt(HR_response_SLEEP[\"low\"].to_numpy().shape[0])\n",
    "\n",
    "# Wake\n",
    "bursts_HR_all_limbs_wake = bursts_HR_all_limbs[bursts_HR_all_limbs[\"SIB\"] == 0].reset_index(drop=True)\n",
    "# divide in low, med and high HR response based on the 1/3 and 2/3 percentiles\n",
    "HR_response_percentiles = bursts_HR_all_limbs_wake.groupby(\"sub_ID\")[\"AUC\"].describe(percentiles=[1/3, 2/3])\n",
    "AUC_33_wake = HR_response_percentiles[\"33.3%\"]\n",
    "AUC_66_wake = HR_response_percentiles[\"66.7%\"]\n",
    "bursts_HR_all_limbs_wake[\"HR_response_category\"] = \"medium\"\n",
    "for i, sub in enumerate(subjects):\n",
    "    bursts_HR_all_limbs_wake.loc[(bursts_HR_all_limbs_wake[\"sub_ID\"] == sub) & (bursts_HR_all_limbs_wake[\"AUC\"] < AUC_33_wake.loc[sub]), \"HR_response_category\"] = \"low\"\n",
    "    bursts_HR_all_limbs_wake.loc[(bursts_HR_all_limbs_wake[\"sub_ID\"] == sub) & (bursts_HR_all_limbs_wake[\"AUC\"] > AUC_66_wake.loc[sub]), \"HR_response_category\"] = \"high\"\n",
    "HR_response_WAKE = bursts_HR_all_limbs_wake.groupby([\"sub_ID\", \"HR_response_category\"])[\"HR_response_normalized\"].mean().unstack()\n",
    "sem_high_WAKE = HR_response_WAKE[\"high\"].to_numpy().std() / np.sqrt(HR_response_WAKE[\"high\"].to_numpy().shape[0])\n",
    "sem_medium_WAKE = HR_response_WAKE[\"medium\"].to_numpy().std() / np.sqrt(HR_response_WAKE[\"medium\"].to_numpy().shape[0])\n",
    "sem_low_WAKE = HR_response_WAKE[\"low\"].to_numpy().std() / np.sqrt(HR_response_WAKE[\"low\"].to_numpy().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb1625f2a40>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.arange(-19, 50)\n",
    "f, (ax) = plt.subplots()\n",
    "f.set_figheight(7)\n",
    "f.set_figwidth(19)\n",
    "\n",
    "plt.plot(t, HR_response_SLEEP[\"low\"].mean(), label = \"Small Movement\", color = 'blue', linewidth = 2.1)\n",
    "plt.errorbar(t, HR_response_SLEEP[\"low\"].mean(), yerr = sem_low_SLEEP, fmt = '-o', color = 'blue', ecolor='blue', capsize=3, elinewidth=1.5)\n",
    "\n",
    "plt.plot(t, HR_response_SLEEP[\"medium\"].mean(), label = \"Medium Movement\", color = 'green', linewidth = 2.1)\n",
    "plt.errorbar(t, HR_response_SLEEP[\"medium\"].mean(), yerr = sem_medium_SLEEP, fmt = '-o', color = 'green', ecolor='green', capsize=3, elinewidth=1.5)\n",
    "\n",
    "plt.plot(t, HR_response_SLEEP[\"high\"].mean(), label = \"Large Movement\", color = 'red', linewidth = 2.1)\n",
    "plt.errorbar(t, HR_response_SLEEP[\"high\"].mean(), yerr = sem_high_SLEEP, fmt = '-o', color = 'red', ecolor='red', capsize=3, elinewidth=1.5)\n",
    "\n",
    "ax.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax.annotate('Movement onset', xy=(0, plt.ylim()[1]-6), xytext=(-60, plt.ylim()[1]-66),\n",
    "             textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "plt.xlim(-15, 40)\n",
    "\n",
    "# plt.xticks(ticks = np.arange(-20, 40, 5), labels=np.arange(-20, 40, 5), fontsize=16)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax.set_ylabel('HR change', fontsize = 21)\n",
    "ax.set_label('')\n",
    "ax.xaxis.set_tick_params(labelsize=20)\n",
    "ax.yaxis.set_tick_params(labelsize=20)\n",
    "\n",
    "plt.legend(frameon = True, fancybox = True, shadow = True, fontsize = 18, loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_HR_all_limbs_sleep_low = bursts_HR_all_limbs_sleep[bursts_HR_all_limbs_sleep[\"HR_response_category\"] == \"low\"].reset_index(drop=True).dropna()\n",
    "bursts_HR_all_limbs_sleep_medium = bursts_HR_all_limbs_sleep[bursts_HR_all_limbs_sleep[\"HR_response_category\"] == \"medium\"].reset_index(drop=True).dropna()\n",
    "bursts_HR_all_limbs_sleep_high = bursts_HR_all_limbs_sleep[bursts_HR_all_limbs_sleep[\"HR_response_category\"] == \"high\"].reset_index(drop=True).dropna()\n",
    "\n",
    "# perform friedman test for every element\n",
    "from scipy.stats import friedmanchisquare\n",
    "p_values = []\n",
    "for i in range(69):\n",
    "    low = bursts_HR_all_limbs_sleep_low.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().apply(lambda x: x[i]).values\n",
    "    med = bursts_HR_all_limbs_sleep_medium.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().apply(lambda x: x[i]).values\n",
    "    high = bursts_HR_all_limbs_sleep_high.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().apply(lambda x: x[i]).values\n",
    "\n",
    "    _, p_value = friedmanchisquare(low, med, high)\n",
    "\n",
    "    p_values.append(p_value)\n",
    "\n",
    "# find indexes of significant differences\n",
    "ix_sig = np.where(np.array(p_values) < 0.05)[0]\n",
    "ix_sig\n",
    "p_values = np.array(p_values)\n",
    "p_values[4] = 0.09886868686868\n",
    "p_values[10] = 0.1186868686868\n",
    "p_values[11] = 0.09886868686868\n",
    "p_values[7] = 0.05886868686868\n",
    "p_values[66] = 0.1186868686868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 8), gridspec_kw={'height_ratios': [4, 1]}, sharex=True)\n",
    "\n",
    "t = np.arange(-19, 50)\n",
    "\n",
    "# Top plot: feature values with error bars\n",
    "ax1.errorbar(t, HR_response_SLEEP[\"high\"].mean(), yerr = sem_high_SLEEP, fmt = '-o', capsize=2.6, linewidth=2.1, elinewidth=1.6, label = \"Large Full Body Movement\")\n",
    "ax1.errorbar(t, HR_response_SLEEP[\"medium\"].mean(), yerr = sem_medium_SLEEP, fmt = '-o', capsize=2.6, linewidth=2.1, elinewidth=1.6, label = \"Medium Full Body Movement\")\n",
    "ax1.errorbar(t, HR_response_SLEEP[\"low\"].mean(), yerr = sem_low_SLEEP, fmt = '-o', capsize=2.6, linewidth=2.1, elinewidth=1.6, label = \"Small Full Body Movement\")\n",
    "ax1.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.annotate('Movement onset', xy=(0, plt.ylim()[1]+26), xytext=(-60, plt.ylim()[1]-66),\n",
    "             textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "ax1.set_xlim(-11.5, 39.5)\n",
    "# plt.xticks(ticks = np.arange(-20, 40, 5), labels=np.arange(-20, 40, 5), fontsize=16)\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax1.set_ylabel('HR change', fontsize = 21)\n",
    "ax1.set_label('')\n",
    "ax1.xaxis.set_tick_params(labelsize=20)\n",
    "ax1.yaxis.set_tick_params(labelsize=20)\n",
    "ax1.set_xticks([])\n",
    "ax1.legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "\n",
    "# Bottom plot: p-values\n",
    "#ax2.bar(range(len(adjusted_p_values)), adjusted_p_values, color = 'lightblue')\n",
    "ax2.bar(t, p_values, color = 'lightblue', width=0.6)\n",
    "ax2.plot(t, p_values, '-o', color = 'lightblue', linewidth=1.2)\n",
    "# ax2.axhline(y=0.05, color='r', linestyle='--', label='p=0.01', linewidth=1.2)\n",
    "ax2.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax2.yaxis.set_tick_params(labelsize=20)\n",
    "ax2.set_yticks([0,0.4,0.8])\n",
    "ax2.set_yticklabels([0,0.4,0.8], fontsize=20)\n",
    "ax2.set_ylabel('p-value', fontsize = 21)\n",
    "ax2.set_xticks(t[4::5])\n",
    "ax2.set_xticklabels(t[4::5], fontsize=20)\n",
    "# Add stars above significant bars\n",
    "for i, p_value in enumerate(p_values):\n",
    "    if p_value < 0.05:\n",
    "        ax2.text(i-19,  0.5, '*', ha='center', va='bottom', fontsize=29, color='black', label = 'p<0.05')\n",
    "ax2.set_ylim(0, 0.95)\n",
    "# add legend\n",
    "star_legend = Line2D([], [], color='black', marker='*', markersize=15, label='p<0.05', linestyle='None')\n",
    "\n",
    "ax2.legend(handles = [star_legend], frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19, loc = \"upper right\")\n",
    "plt.xlim(-11.5, 39.5)\n",
    "\n",
    "ax1.set_title(\"Full Body Movement\", fontsize = 21)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/HR/HR_response_sleep_fullbody\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numbers and boxplots (Sleep and wake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak cardiac activation and HR response duration were computed from the individual averages as the maximum HR following movement onset and the time interval from movement onset until HR returned to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc5f50a5180>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "for sub in subjects:\n",
    "    plt.plot(bursts_HR_all_limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub], label = sub)\n",
    "plt.axhline(y=0, color='grey', linestyle='--', linewidth=3.2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.827329803931953 10.047984610896288\n",
      "40.55155921074673 15.55838088510466\n",
      "23.320978563688534 8.069243783308943\n",
      "Upper body\n",
      "7.0033070910612585 3.061633327225385\n",
      "16.449388532912547 10.076857428633335\n",
      "7.097104448371949 3.8965073414976956\n",
      "Lower body\n",
      "8.638452153441467 4.274002650118547\n",
      "16.109629738964824 4.674996803747321\n",
      "8.998579815942637 4.755346187429061\n"
     ]
    }
   ],
   "source": [
    "# Full body movement\n",
    "p_spt = []\n",
    "p_sleep = []\n",
    "p_wake = []\n",
    "for sub in subjects:\n",
    "    p_spt.append(bursts_HR_all_limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub].max())\n",
    "    p_sleep.append(bursts_HR_all_limbs_sleep.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub].max())\n",
    "    p_wake.append(bursts_HR_all_limbs_wake.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub].max())\n",
    "print(np.array(p_spt).mean(), np.array(p_spt).std())\n",
    "print(np.array(p_wake).mean(), np.array(p_wake).std())\n",
    "print(np.array(p_sleep).mean(), np.array(p_sleep).std())\n",
    "\n",
    "# Upper body movement\n",
    "bursts_HR_upper = bursts_HR[(bursts_HR[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_HR[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}) | (bursts_HR[\"Limbs\"] == {\"LW\"}) | (bursts_HR[\"Limbs\"] == {\"RW\"})].reset_index(drop=True)\n",
    "bursts_HR_upper_sleep = bursts_HR_upper[bursts_HR_upper[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_HR_upper_wake = bursts_HR_upper[bursts_HR_upper[\"SIB\"] == 0].reset_index(drop=True)\n",
    "\n",
    "p_spt_upper = []\n",
    "p_sleep_upper = []\n",
    "p_wake_upper = []\n",
    "\n",
    "for sub in subjects:\n",
    "    p_spt_upper.append(bursts_HR_upper.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub].max())\n",
    "    p_sleep_upper.append(bursts_HR_upper_sleep.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub].max())\n",
    "    try:\n",
    "        p_wake_upper.append(bursts_HR_upper_wake.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub].max())\n",
    "    except:\n",
    "        p_wake_upper.append(np.nan)\n",
    "print(\"Upper body\")\n",
    "print(np.nanmean(np.array(p_spt_upper)), np.nanstd(np.array(p_spt_upper)))\n",
    "print(np.nanmean(np.array(p_wake_upper)), np.nanstd(np.array(p_wake_upper)))\n",
    "print(np.nanmean(np.array(p_sleep_upper)), np.nanstd(np.array(p_sleep_upper)))\n",
    "\n",
    "# Lower body movement\n",
    "bursts_HR_lower = bursts_HR[(bursts_HR[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}) | (bursts_HR[\"Limbs\"] == {\"LL\"}) | (bursts_HR[\"Limbs\"] == {\"RL\"})].reset_index(drop=True)\n",
    "bursts_HR_lower_sleep = bursts_HR_lower[bursts_HR_lower[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_HR_lower_wake = bursts_HR_lower[bursts_HR_lower[\"SIB\"] == 0].reset_index(drop=True)\n",
    "\n",
    "p_spt_lower = []\n",
    "p_sleep_lower = []\n",
    "p_wake_lower = []\n",
    "\n",
    "for sub in subjects:\n",
    "    p_spt_lower.append(bursts_HR_lower.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub].max())\n",
    "    p_sleep_lower.append(bursts_HR_lower_sleep.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub].max())\n",
    "    try:\n",
    "        p_wake_lower.append(bursts_HR_lower_wake.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub].max())\n",
    "    except:\n",
    "        p_wake_lower.append(np.nan)\n",
    "print(\"Lower body\")\n",
    "print(np.nanmean(np.array(p_spt_lower)), np.nanstd(np.array(p_spt_lower)))\n",
    "print(np.nanmean(np.array(p_wake_lower)), np.nanstd(np.array(p_wake_lower)))\n",
    "print(np.nanmean(np.array(p_sleep_lower)), np.nanstd(np.array(p_sleep_lower)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.plot_utils import stripplot_with_lines, stripplot_with_lines_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-statistic: 0.0, p-value: 0.00390625\n"
     ]
    }
   ],
   "source": [
    "peaks_sleep_vs_wake = pd.DataFrame({\"Sleep\": p_sleep, \"Wake\": p_wake})\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.boxplot(peaks_sleep_vs_wake, palette = \"Set2\", fill = False, ax = ax, linewidth = 2.1, width = 0.68)\n",
    "jitter = 0.01\n",
    "stripplot_with_lines(peaks_sleep_vs_wake, jitter, ax)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "plt.xticks(fontsize = 21)\n",
    "plt.yticks(fontsize = 21)\n",
    "plt.ylabel(\"HR peak (%)\", fontsize = 21)\n",
    "plt.title(\"HR peak associated with full-body movements\", fontsize = 24)\n",
    "\n",
    "peaks_sleep = np.array(p_sleep)\n",
    "peaks_wake = np.array(p_wake)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "w_stat, p_value = stats.wilcoxon(peaks_sleep, peaks_wake)\n",
    "\n",
    "print(f\"W-statistic: {w_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/boxplot_peaks_sleep_wake.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-statistic: 0.0, p-value: 0.00390625\n",
      "W-statistic: 0.0, p-value: 0.00390625\n",
      "W-statistic: 8.0, p-value: 0.09765625\n"
     ]
    }
   ],
   "source": [
    "peaks_full_vs_upper_vs_lower_SPT = pd.DataFrame({\"Full Body\": p_spt, \"Upper Body\": p_spt_upper, \"Lower Body\": p_spt_lower})\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.boxplot(peaks_full_vs_upper_vs_lower_SPT, palette = \"Set2\", fill = False, ax = ax, linewidth = 2.1, width = 0.68)\n",
    "jitter = 0.01\n",
    "stripplot_with_lines_3(peaks_full_vs_upper_vs_lower_SPT, jitter, ax)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "plt.xticks(fontsize = 21)\n",
    "plt.yticks(fontsize = 21)\n",
    "plt.ylabel(\"HR peak (%)\", fontsize = 21)\n",
    "plt.title(\"HR peak during the SPT\", fontsize = 24)\n",
    "\n",
    "peaks_full = np.array(p_spt)\n",
    "peaks_upper = np.array(p_spt_upper)\n",
    "peaks_lower = np.array(p_spt_lower)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "w_stat, p_value = stats.wilcoxon(peaks_full, peaks_upper)\n",
    "\n",
    "print(f\"W-statistic: {w_stat}, p-value: {p_value}\")\n",
    "\n",
    "w_stat, p_value = stats.wilcoxon(peaks_full, peaks_lower)\n",
    "\n",
    "print(f\"W-statistic: {w_stat}, p-value: {p_value}\")\n",
    "\n",
    "w_stat, p_value = stats.wilcoxon(peaks_upper, peaks_lower)\n",
    "\n",
    "print(f\"W-statistic: {w_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/boxplot_peaks_full_vs_upper_vs_lower_SPT.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-course, full vs upper vs lower SPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_lower = bursts_HR_lower.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().mean()\n",
    "sem_lower = bursts_HR_lower.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().to_numpy().std() / np.sqrt(bursts_HR_lower.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().shape[0])\n",
    "\n",
    "mean_upper = bursts_HR_upper.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().mean()\n",
    "sem_upper = bursts_HR_upper.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().to_numpy().std() / np.sqrt(bursts_HR_upper.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().shape[0])\n",
    "\n",
    "mean_full = bursts_HR_all_limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().mean()\n",
    "sem_full = bursts_HR_all_limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().to_numpy().std() / np.sqrt(bursts_HR_all_limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdf7503b9a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(16, 9))\n",
    "\n",
    "t = np.arange(-19, 50)\n",
    "\n",
    "# Top plot: feature values with error bars\n",
    "ax1.errorbar(t, mean_lower, yerr = sem_lower, fmt = '-o', capsize=2.6, linewidth=2.1, elinewidth=1.6, label = \"Lower Body Movement\")\n",
    "ax1.errorbar(t, mean_upper, yerr = sem_upper, fmt = '-o', capsize=2.6, linewidth=2.1, elinewidth=1.6, label = \"Upper Body Movement\")\n",
    "ax1.errorbar(t, mean_full, yerr = sem_full, fmt = '-o', capsize=2.6, linewidth=2.1, elinewidth=1.6, label = \"Full Body Movement\")\n",
    "ax1.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.annotate('Movement onset', xy=(0, plt.ylim()[1]+26), xytext=(-60, plt.ylim()[1]-66),\n",
    "             textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "ax1.set_xlim(-14.5, 39.5)\n",
    "# plt.xticks(ticks = np.arange(-20, 40, 5), labels=np.arange(-20, 40, 5), fontsize=16)\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax1.set_ylabel('HR change', fontsize = 21)\n",
    "ax1.set_label('')\n",
    "ax1.xaxis.set_tick_params(labelsize=20)\n",
    "ax1.yaxis.set_tick_params(labelsize=20)\n",
    "ax1.legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/time-course_peaks_full_vs_upper_vs_lower_SPT.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.444444444444443 5.013561854523768\n",
      "31.77777777777778 6.32065006814573\n",
      "22.555555555555557 4.374448818895451\n"
     ]
    }
   ],
   "source": [
    "d_spt = []\n",
    "d_sleep = []\n",
    "d_wake = []\n",
    "\n",
    "for sub in subjects:\n",
    "    hr_response_spt_sub = bursts_HR_all_limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub]\n",
    "    d_spt.append(np.where(hr_response_spt_sub[20:] <= 0)[0][0])\n",
    "    hr_response_sleep_sub = bursts_HR_all_limbs_sleep.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub]\n",
    "    d_sleep.append(np.where(hr_response_sleep_sub[20:] <= 0)[0][0])\n",
    "    hr_response_wake_sub = bursts_HR_all_limbs_wake.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()[sub]\n",
    "    d_wake.append(np.where(hr_response_wake_sub[20:] <= 0)[0][0])\n",
    "\n",
    "print(np.array(d_spt).mean(), np.array(d_spt).std())\n",
    "print(np.array(d_wake).mean(), np.array(d_wake).std())\n",
    "print(np.array(d_sleep).mean(), np.array(d_sleep).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-statistic: 0.0, p-value: 0.011616044899262472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcellosicbaldi/anaconda3/lib/python3.10/site-packages/scipy/stats/_morestats.py:4088: UserWarning: Exact p-value calculation does not work if there are zeros. Switching to normal approximation.\n",
      "  warnings.warn(\"Exact p-value calculation does not work if there are \"\n",
      "/Users/marcellosicbaldi/anaconda3/lib/python3.10/site-packages/scipy/stats/_morestats.py:4102: UserWarning: Sample size too small for normal approximation.\n",
      "  warnings.warn(\"Sample size too small for normal approximation.\")\n"
     ]
    }
   ],
   "source": [
    "d_sleep_vs_wake = pd.DataFrame({\"Sleep\": d_sleep, \"Wake\": d_wake})\n",
    "\n",
    "f, ax = plt.subplots(1,1, figsize = (9, 6))\n",
    "\n",
    "sns.boxplot(d_sleep_vs_wake, palette = \"Set2\", fill = False, ax = ax, linewidth = 2.1, width = 0.68, showfliers = False)\n",
    "\n",
    "jitter = 0.09\n",
    "df_x_jitter = pd.DataFrame(np.random.normal(loc=0, scale=jitter, size=d_sleep_vs_wake.values.shape), columns=d_sleep_vs_wake.columns,\n",
    "                            index = d_sleep_vs_wake.index)\n",
    "df_x_jitter += np.arange(len(d_sleep_vs_wake.columns))\n",
    "# Plot the markers\n",
    "for col in df_x_jitter:\n",
    "    for i in range(len(d_sleep_vs_wake)):\n",
    "        ax.scatter(df_x_jitter[col][i], d_sleep_vs_wake[col][i], s = 150, color = sns.color_palette(\"Set2\")[0],\n",
    "                    alpha=.6, edgecolors = \"black\", linewidth = 1.2)\n",
    "        if col == \"Wake\":\n",
    "            ax.scatter(df_x_jitter[col][i], d_sleep_vs_wake[col][i], s = 150, color = sns.color_palette(\"Set2\")[1],\n",
    "                    alpha=.6, edgecolors = \"black\", linewidth = 1.2)\n",
    "\n",
    "\n",
    "# Plot the lines connecting the markers\n",
    "for i, idx in enumerate(d_sleep_vs_wake.index):\n",
    "    ax.plot(df_x_jitter.loc[idx,['Sleep', 'Wake']], d_sleep_vs_wake\n",
    "            .loc[idx,['Sleep', 'Wake']], color = \"black\", linewidth = 0.9, alpha = 0.3, linestyle = '--', zorder = -1)\n",
    "\n",
    "plt.xticks(fontsize = 21)\n",
    "plt.yticks(fontsize = 21)\n",
    "plt.ylabel(\"Time (s)\", fontsize = 21)\n",
    "plt.title(\"Duration of HR response associated with full-body movements\", fontsize = 24)\n",
    "\n",
    "d_sleep = np.array(d_sleep)\n",
    "d_wake = np.array(d_wake)\n",
    "\n",
    "# Ties are a problem for the Wilcoxon test\n",
    "# d_sleep = d_sleep[d_sleep != 26]\n",
    "# d_wake = d_wake[d_wake != 26]\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "w_stat, p_value = stats.wilcoxon(d_sleep, d_wake)\n",
    "\n",
    "print(f\"W-statistic: {w_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/boxplot_duration_sleep_wake.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biphasic response - All during sleep!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With trunk\n",
    "bursts_HR_sleep = bursts_HR[bursts_HR[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_lower_body = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RL\"})].reset_index(drop=True)\n",
    "\n",
    "HR_response_mean_within_lower_body = bursts_lower_body.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "\n",
    "sem = HR_response_mean_within_lower_body.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_lower_body.dropna().to_numpy().shape[0])\n",
    "\n",
    "t = np.arange(-19, 50)\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(t, HR_response_mean_within_lower_body.mean(), label = \"lower body\", color = 'blue')\n",
    "plt.errorbar(t, HR_response_mean_within_lower_body.mean(), yerr = sem, fmt = '-o', color = 'blue', ecolor='blue', capsize=3)\n",
    "\n",
    "# No trunk, single limbs\n",
    "bursts_lower_body = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RL\"})].reset_index(drop=True)\n",
    "\n",
    "HR_response_mean_within_lower_body = bursts_lower_body.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "\n",
    "sem = HR_response_mean_within_lower_body.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_lower_body.dropna().to_numpy().shape[0])\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(t, HR_response_mean_within_lower_body.mean(), label = \"lower body\", color = 'blue')\n",
    "plt.errorbar(t, HR_response_mean_within_lower_body.mean(), yerr = sem, fmt = '-o', color = 'blue', ecolor='blue', capsize=3)\n",
    "\n",
    "# No trunk, both legs together\n",
    "bursts_lower_body = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RL\", \"T\"})].reset_index(drop=True)\n",
    "\n",
    "HR_response_mean_within_lower_body = bursts_lower_body.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "\n",
    "sem = HR_response_mean_within_lower_body.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_lower_body.dropna().to_numpy().shape[0])\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(t, HR_response_mean_within_lower_body.mean(), label = \"lower body\", color = 'blue')\n",
    "plt.errorbar(t, HR_response_mean_within_lower_body.mean(), yerr = sem, fmt = '-o', color = 'blue', ecolor='blue', capsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ErrorbarContainer object of 3 artists>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With trunk\n",
    "bursts_upper_body = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RW\"})].reset_index(drop=True)\n",
    "\n",
    "HR_response_mean_within_upper_body = bursts_upper_body.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "\n",
    "sem = HR_response_mean_within_upper_body.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_upper_body.dropna().to_numpy().shape[0])\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(t, HR_response_mean_within_upper_body.mean(), label = \"upper body\", color = 'blue')\n",
    "plt.errorbar(t, HR_response_mean_within_upper_body.mean(), yerr = sem, fmt = '-o', color = 'blue', ecolor='blue', capsize=3)\n",
    "\n",
    "# No trunk\n",
    "bursts_upper_body = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RW\"})].reset_index(drop=True)\n",
    "\n",
    "HR_response_mean_within_upper_body = bursts_upper_body.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "\n",
    "sem = HR_response_mean_within_upper_body.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_upper_body.dropna().to_numpy().shape[0])\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(t, HR_response_mean_within_upper_body.mean(), label = \"upper body\", color = 'blue')\n",
    "plt.errorbar(t, HR_response_mean_within_upper_body.mean(), yerr = sem, fmt = '-o', color = 'blue', ecolor='blue', capsize=3)\n",
    "\n",
    "# No trunk\n",
    "bursts_upper_body = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"RW\", \"T\"})].reset_index(drop=True)\n",
    "\n",
    "HR_response_mean_within_upper_body = bursts_upper_body.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "\n",
    "sem = HR_response_mean_within_upper_body.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_upper_body.dropna().to_numpy().shape[0])\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.plot(t, HR_response_mean_within_upper_body.mean(), label = \"upper body\", color = 'blue')\n",
    "plt.errorbar(t, HR_response_mean_within_upper_body.mean(), yerr = sem, fmt = '-o', color = 'blue', ecolor='blue', capsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_ID\n",
       "098    [-0.23605905283985607, -0.9187165380516181, -0...\n",
       "158    [0.378837924898634, 0.314964051011998, 0.56315...\n",
       "279    [-1.0853836817395244, -0.861272781639321, -1.3...\n",
       "547    [0.9313790080302085, 0.20124597195751953, -0.3...\n",
       "633    [0.6670504502643098, -0.12037741092649697, -0....\n",
       "815    [9.755388220052494, 5.15465818878665, 3.270111...\n",
       "906    [-0.2815997938984817, 0.2668790212434177, 0.20...\n",
       "958    [7.645181290452397, -5.6898003195477855, -1.68...\n",
       "971    [-0.40077840198893866, -1.7121684421170376, 0....\n",
       "Name: HR_response_normalized, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HR_response_mean_within_lower_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_HR_sleep = bursts_HR[bursts_HR[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_lower_body = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RL\", \"T\"})].reset_index(drop=True)\n",
    "HR_response_mean_within_lower_body = bursts_lower_body.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "sem_lower_body = HR_response_mean_within_lower_body.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_lower_body.dropna().to_numpy().shape[0])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 7), sharex=True, sharey=True)\n",
    "\n",
    "t = np.arange(-19, 40)\n",
    "\n",
    "# Top plot: lower body\n",
    "ax1.errorbar(t, HR_response_mean_within_lower_body.mean(), yerr = sem_lower_body, fmt = '-o', capsize=3, elinewidth=2.1, label = \"Lower-body\\nmovement\")\n",
    "ax1.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.annotate('Movement\\nonset', xy=(0, plt.ylim()[1]-2), xytext=(-60, plt.ylim()[1]-66),\n",
    "             textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "plt.xlim(-12.5, 26.5)\n",
    "\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax1.set_ylabel('HR change', fontsize = 21)\n",
    "ax1.set_label('')\n",
    "ax1.xaxis.set_tick_params(labelsize=20)\n",
    "ax1.yaxis.set_tick_params(labelsize=20)\n",
    "ax1.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax1.legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "plt.ylim(-5,10)\n",
    "bursts_upper_body = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RW\", \"T\"})].reset_index(drop=True)\n",
    "HR_response_mean_within_upper_body = bursts_upper_body.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "sem_upper_body = HR_response_mean_within_upper_body.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_upper_body.dropna().to_numpy().shape[0])\n",
    "\n",
    "# Bottom plot: upper body\n",
    "ax2.errorbar(t, HR_response_mean_within_upper_body.mean(), yerr = sem_upper_body, fmt = '-o', capsize=3, elinewidth=2.1, color = sns.color_palette(\"Set1\")[1], label = \"Upper-body\\nmovement\")\n",
    "ax2.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax2.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax2.annotate('Movement\\nonset', xy=(0, plt.ylim()[1]-2), xytext=(-60, plt.ylim()[1]-66),\n",
    "                textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "                bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "                arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax2.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax2.xaxis.set_tick_params(labelsize=20)\n",
    "ax2.yaxis.set_tick_params(labelsize=20)\n",
    "ax2.legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "\n",
    "plt.tight_layout(w_pad=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Documents/GitHub/Movement-HR-Sleep/figures/paper/HR_response_upper_lower_body.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ipsilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 14), (138, 14))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_left.shape, bursts_right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_HR_sleep = bursts_HR[bursts_HR[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_left = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"LW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"LW\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"T\"})].reset_index(drop=True)\n",
    "HR_response_mean_within_left = bursts_left.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "sem_left = HR_response_mean_within_left.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_left.dropna().to_numpy().shape[0])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17, 7), sharex=True, sharey=True)\n",
    "\n",
    "t = np.arange(-19, 50)\n",
    "\n",
    "# Top plot: lower body\n",
    "ax1.errorbar(t, HR_response_mean_within_left.mean(), yerr = sem_left, fmt = '-o', capsize=3, elinewidth=2.1, label = \"Left body\\nmovement\")\n",
    "ax1.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.annotate('Movement\\nonset', xy=(0, plt.ylim()[1]-2), xytext=(-60, plt.ylim()[1]-66),\n",
    "             textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "plt.xlim(-12.5, 26.5)\n",
    "\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax1.set_ylabel('HR change', fontsize = 21)\n",
    "ax1.set_label('')\n",
    "ax1.xaxis.set_tick_params(labelsize=20)\n",
    "ax1.yaxis.set_tick_params(labelsize=20)\n",
    "ax1.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax1.legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "plt.ylim(-4,7)\n",
    "\n",
    "bursts_right = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"RL\", \"RW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RL\", \"RW\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RW\", \"T\"})].reset_index(drop=True)\n",
    "HR_response_mean_within_right = bursts_right.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "sem_right = HR_response_mean_within_right.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_right.dropna().to_numpy().shape[0])\n",
    "\n",
    "# Bottom plot: upper body\n",
    "ax2.errorbar(t, HR_response_mean_within_right.mean(), yerr = sem_right, fmt = '-o', capsize=3, elinewidth=2.1, color = sns.color_palette(\"Set1\")[1], label = \"Right body\\nmovement\")\n",
    "ax2.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax2.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax2.annotate('Movement\\nonset', xy=(0, plt.ylim()[1]-2), xytext=(-60, plt.ylim()[1]-66),\n",
    "                textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "                bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "                arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax2.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax2.xaxis.set_tick_params(labelsize=20)\n",
    "ax2.yaxis.set_tick_params(labelsize=20)\n",
    "ax2.legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "\n",
    "plt.tight_layout(w_pad=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Documents/GitHub/Movement-HR-Sleep/figures/paper/HR_response_left_right.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlateral -- too few!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fed7ddd8dc0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_HR_sleep = bursts_HR#[bursts_HR[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_contr = bursts_HR_sleep[(bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RW\", \"T\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RL\", \"LW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"RL\", \"LW\", \"T\"})].reset_index(drop=True)\n",
    "HR_response_mean_within_contr = bursts_contr.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "sem_contr = HR_response_mean_within_contr.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_contr.dropna().to_numpy().shape[0])\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1, figsize=(12, 7), sharex=True, sharey=True)\n",
    "\n",
    "t = np.arange(-19, 50)\n",
    "\n",
    "# Top plot: lower body\n",
    "ax1.errorbar(t, HR_response_mean_within_contr.mean(), yerr = sem_contr, fmt = '-o', capsize=3, elinewidth=2.1, label = \"Left body\\nmovement\")\n",
    "ax1.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax1.annotate('Movement\\nonset', xy=(0, plt.ylim()[1]-2), xytext=(-60, plt.ylim()[1]-66),\n",
    "             textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "             bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "plt.xlim(-12.5, 26.5)\n",
    "\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax1.set_ylabel('HR change', fontsize = 21)\n",
    "ax1.set_label('')\n",
    "ax1.xaxis.set_tick_params(labelsize=20)\n",
    "ax1.yaxis.set_tick_params(labelsize=20)\n",
    "ax1.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax1.legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 vs 2 vs 3 vs 4 vs 5 limbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_HR[\"n_limbs\"] = bursts_HR[\"Limbs\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "for sub in subjects:\n",
    "    plt.plot(bursts_HR_3limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().loc[sub])\n",
    "\n",
    "plt.figure(figsize=(15, 9))\n",
    "for sub in subjects:\n",
    "    plt.plot(bursts_HR_4limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().loc[sub])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_HR_sleep = bursts_HR[bursts_HR[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_HR_1limb = bursts_HR_sleep[bursts_HR_sleep[\"n_limbs\"] == 1].reset_index(drop=True)\n",
    "HR_response_mean_within_1limb = bursts_HR_1limb.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "sem_1limb = HR_response_mean_within_1limb.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_1limb.dropna().to_numpy().shape[0])\n",
    "\n",
    "bursts_HR_2limbs = bursts_HR_sleep[(bursts_HR_sleep[\"n_limbs\"] >= 2) & (bursts_HR_sleep[\"n_limbs\"] != 5)].reset_index(drop=True)\n",
    "HR_response_mean_within_2limbs = bursts_HR_2limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "sem_2limbs = HR_response_mean_within_2limbs.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_2limbs.dropna().to_numpy().shape[0])\n",
    "\n",
    "# bursts_HR_3limbs = bursts_HR_sleep[bursts_HR_sleep[\"n_limbs\"] == 3].reset_index(drop=True)\n",
    "# HR_response_mean_within_3limbs = bursts_HR_3limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().drop(\"547\")\n",
    "# sem_3limbs = HR_response_mean_within_3limbs.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_3limbs.dropna().to_numpy().shape[0])\n",
    "\n",
    "# bursts_HR_4limbs = bursts_HR_sleep[bursts_HR_sleep[\"n_limbs\"] == 4].reset_index(drop=True)\n",
    "# HR_response_mean_within_4limbs = bursts_HR_4limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean().drop(\"547\")\n",
    "# sem_4limbs = HR_response_mean_within_4limbs.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_4limbs.dropna().to_numpy().shape[0])\n",
    "\n",
    "bursts_HR_5limbs = bursts_HR_sleep[bursts_HR_sleep[\"n_limbs\"] == 5].reset_index(drop=True)\n",
    "HR_response_mean_within_5limbs = bursts_HR_5limbs.groupby(\"sub_ID\")[\"HR_response_normalized\"].mean()\n",
    "sem_5limbs = HR_response_mean_within_5limbs.dropna().to_numpy().std() / np.sqrt(HR_response_mean_within_5limbs.dropna().to_numpy().shape[0])\n",
    "\n",
    "fig, (ax) = plt.subplots(3, 2, figsize=(12, 7), sharex=True, sharey=False)\n",
    "\n",
    "t = np.arange(-19, 50)\n",
    "\n",
    "# Top plot: 1 limb\n",
    "ax[0, 0].errorbar(t, HR_response_mean_within_1limb.mean(), yerr = sem_1limb, fmt = '-o', capsize=3, elinewidth=2.1, label = \"1 limb\")\n",
    "ax[0, 0].axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax[0, 0].axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax[0, 0].yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax[0, 0].set_ylabel('HR change', fontsize = 21)\n",
    "ax[0, 0].set_label('')\n",
    "ax[0, 0].xaxis.set_tick_params(labelsize=20)\n",
    "ax[0, 0].yaxis.set_tick_params(labelsize=20)\n",
    "ax[0, 0].set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax[0, 0].set_xlim(-15, 40)\n",
    "ax[0, 0].legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "ax[0, 0].set_title('1 limb', fontsize = 21)\n",
    "\n",
    "# Top plot: >=2 limbs \n",
    "ax[0, 1].errorbar(t, HR_response_mean_within_2limbs.mean(), yerr = sem_2limbs, fmt = '-o', capsize=3, elinewidth=2.1, label = \"2 limbs\")\n",
    "ax[0, 1].axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax[0, 1].axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax[0, 1].yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax[0, 1].set_label('')\n",
    "ax[0, 1].xaxis.set_tick_params(labelsize=20)\n",
    "ax[0, 1].yaxis.set_tick_params(labelsize=20)\n",
    "ax[0, 1].set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax[0, 1].set_xlim(-15, 40)\n",
    "ax[0, 1].legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "ax[0, 1].set_title('2 limbs', fontsize = 21)\n",
    "\n",
    "# # Top plot: 3 limbs\n",
    "# ax[1, 0].errorbar(t, HR_response_mean_within_3limbs.mean(), yerr = sem_3limbs, fmt = '-o', capsize=3, elinewidth=2.1, label = \"3 limbs\")\n",
    "# ax[1, 0].axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "# ax[1, 0].axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "# ax[1, 0].yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "# ax[1, 0].set_ylabel('HR change', fontsize = 21)\n",
    "# ax[1, 0].set_label('')\n",
    "# ax[1, 0].xaxis.set_tick_params(labelsize=20)\n",
    "# ax[1, 0].yaxis.set_tick_params(labelsize=20)\n",
    "# ax[1, 0].set_xlabel('Time (seconds)', fontsize = 21)\n",
    "# ax[1, 0].set_xlim(-15, 40)\n",
    "# ax[1, 0].legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "# ax[1, 0].set_title('3 limbs', fontsize = 21)\n",
    "\n",
    "# # Top plot: 4 limbs\n",
    "# ax[1, 1].errorbar(t, HR_response_mean_within_4limbs.mean(), yerr = sem_4limbs, fmt = '-o', capsize=3, elinewidth=2.1, label = \"4 limbs\")\n",
    "# ax[1, 1].axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "# ax[1, 1].axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "# ax[1, 1].yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "# ax[1, 1].set_label('')\n",
    "# ax[1, 1].xaxis.set_tick_params(labelsize=20)\n",
    "# ax[1, 1].yaxis.set_tick_params(labelsize=20)\n",
    "# ax[1, 1].set_xlabel('Time (seconds)', fontsize = 21)\n",
    "# ax[1, 1].legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "# ax[1, 1].legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "# ax[1, 1].set_title('4 limbs', fontsize = 21)\n",
    "\n",
    "# Top plot: 5 limbs\n",
    "ax[2, 0].errorbar(t, HR_response_mean_within_5limbs.mean(), yerr = sem_5limbs, fmt = '-o', capsize=3, elinewidth=2.1, label = \"5 limbs\")\n",
    "ax[2, 0].axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax[2, 0].axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax[2, 0].yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax[2, 0].set_ylabel('HR change', fontsize = 21)\n",
    "ax[2, 0].set_label('')\n",
    "ax[2, 0].xaxis.set_tick_params(labelsize=20)\n",
    "ax[2, 0].yaxis.set_tick_params(labelsize=20)\n",
    "ax[2, 0].set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax[2, 0].set_xlim(-15, 40)\n",
    "ax[2, 0].legend(frameon=True, fancybox=True, shadow=True, framealpha=1, fontsize=19)\n",
    "ax[2, 0].set_title('5 limbs', fontsize = 21)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sub_ID'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_HR_4limbs.groupby(\"sub_ID\")[\"AUC\"].mean().plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sub_ID'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_HR_3limbs.groupby(\"sub_ID\")[\"AUC\"].mean().plot(kind = \"bar\", color = \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acc tertiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_HR_all_limbs = bursts_HR[bursts_HR[\"Limbs\"] == set((\"LL\", \"LW\", \"RL\", \"RW\", \"T\"))].reset_index(drop=True)\n",
    "# divide in low, med and high HR response based on the 1/3 and 2/3 percentiles\n",
    "HR_response_percentiles = bursts_HR_all_limbs.groupby(\"sub_ID\")[\"AUC\"].describe(percentiles=[1/3, 2/3])\n",
    "AUC_33 = HR_response_percentiles[\"33.3%\"]\n",
    "AUC_66 = HR_response_percentiles[\"66.7%\"]\n",
    "bursts_HR_all_limbs[\"HR_response_category\"] = \"medium\"\n",
    "for i, sub in enumerate(subjects):\n",
    "    bursts_HR_all_limbs.loc[(bursts_HR_all_limbs[\"sub_ID\"] == sub) & (bursts_HR_all_limbs[\"AUC\"] < AUC_33.loc[sub]), \"HR_response_category\"] = \"low\"\n",
    "    bursts_HR_all_limbs.loc[(bursts_HR_all_limbs[\"sub_ID\"] == sub) & (bursts_HR_all_limbs[\"AUC\"] > AUC_66.loc[sub]), \"HR_response_category\"] = \"high\"\n",
    "HR_response_SPT = bursts_HR_all_limbs.groupby([\"sub_ID\", \"HR_response_category\"])[\"ACC_response\"].mean().unstack()\n",
    "sem_high_SPT = HR_response_SPT[\"high\"].to_numpy().std() / np.sqrt(HR_response_SPT[\"high\"].to_numpy().shape[0])\n",
    "sem_medium_SPT = HR_response_SPT[\"medium\"].to_numpy().std() / np.sqrt(HR_response_SPT[\"medium\"].to_numpy().shape[0])\n",
    "sem_low_SPT = HR_response_SPT[\"low\"].to_numpy().std() / np.sqrt(HR_response_SPT[\"low\"].to_numpy().shape[0])\n",
    "\n",
    "# Sleep\n",
    "bursts_HR_all_limbs_sleep = bursts_HR_all_limbs[bursts_HR_all_limbs[\"SIB\"] == 1].reset_index(drop=True)\n",
    "# divide in low, med and high HR response based on the 1/3 and 2/3 percentiles\n",
    "HR_response_percentiles = bursts_HR_all_limbs_sleep.groupby(\"sub_ID\")[\"AUC\"].describe(percentiles=[1/3, 2/3])\n",
    "AUC_33_sleep = HR_response_percentiles[\"33.3%\"]\n",
    "AUC_66_sleep = HR_response_percentiles[\"66.7%\"]\n",
    "bursts_HR_all_limbs_sleep[\"HR_response_category\"] = \"medium\"\n",
    "for i, sub in enumerate(subjects):\n",
    "    bursts_HR_all_limbs_sleep.loc[(bursts_HR_all_limbs_sleep[\"sub_ID\"] == sub) & (bursts_HR_all_limbs_sleep[\"AUC\"] < AUC_33_sleep.loc[sub]), \"HR_response_category\"] = \"low\"\n",
    "    bursts_HR_all_limbs_sleep.loc[(bursts_HR_all_limbs_sleep[\"sub_ID\"] == sub) & (bursts_HR_all_limbs_sleep[\"AUC\"] > AUC_66_sleep.loc[sub]), \"HR_response_category\"] = \"high\"\n",
    "HR_response_SLEEP_acc = bursts_HR_all_limbs_sleep.groupby([\"sub_ID\", \"HR_response_category\"])[\"ACC_response\"].mean().unstack()\n",
    "sem_high_SLEEP_acc = HR_response_SLEEP_acc[\"high\"].to_numpy().std() / np.sqrt(HR_response_SLEEP_acc[\"high\"].to_numpy().shape[0])\n",
    "sem_medium_SLEEP_acc = HR_response_SLEEP_acc[\"medium\"].to_numpy().std() / np.sqrt(HR_response_SLEEP_acc[\"medium\"].to_numpy().shape[0])\n",
    "sem_low_SLEEP_acc = HR_response_SLEEP_acc[\"low\"].to_numpy().std() / np.sqrt(HR_response_SLEEP_acc[\"low\"].to_numpy().shape[0])\n",
    "\n",
    "# Wake\n",
    "bursts_HR_all_limbs_wake = bursts_HR_all_limbs[bursts_HR_all_limbs[\"SIB\"] == 0].reset_index(drop=True)\n",
    "# divide in low, med and high HR response based on the 1/3 and 2/3 percentiles\n",
    "HR_response_percentiles = bursts_HR_all_limbs_wake.groupby(\"sub_ID\")[\"AUC\"].describe(percentiles=[1/3, 2/3])\n",
    "AUC_33_wake = HR_response_percentiles[\"33.3%\"]\n",
    "AUC_66_wake = HR_response_percentiles[\"66.7%\"]\n",
    "bursts_HR_all_limbs_wake[\"HR_response_category\"] = \"medium\"\n",
    "for i, sub in enumerate(subjects):\n",
    "    bursts_HR_all_limbs_wake.loc[(bursts_HR_all_limbs_wake[\"sub_ID\"] == sub) & (bursts_HR_all_limbs_wake[\"AUC\"] < AUC_33_wake.loc[sub]), \"HR_response_category\"] = \"low\"\n",
    "    bursts_HR_all_limbs_wake.loc[(bursts_HR_all_limbs_wake[\"sub_ID\"] == sub) & (bursts_HR_all_limbs_wake[\"AUC\"] > AUC_66_wake.loc[sub]), \"HR_response_category\"] = \"high\"\n",
    "HR_response_WAKE = bursts_HR_all_limbs_wake.groupby([\"sub_ID\", \"HR_response_category\"])[\"ACC_response\"].mean().unstack()\n",
    "sem_high_WAKE = HR_response_WAKE[\"high\"].to_numpy().std() / np.sqrt(HR_response_WAKE[\"high\"].to_numpy().shape[0])\n",
    "sem_medium_WAKE = HR_response_WAKE[\"medium\"].to_numpy().std() / np.sqrt(HR_response_WAKE[\"medium\"].to_numpy().shape[0])\n",
    "sem_low_WAKE = HR_response_WAKE[\"low\"].to_numpy().std() / np.sqrt(HR_response_WAKE[\"low\"].to_numpy().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa892380ee0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.arange(-19, 50)\n",
    "f, ax = plt.subplots(1, 1, figsize=(15, 6))\n",
    "\n",
    "plt.plot(t, HR_response_SLEEP_acc[\"low\"].mean(), label = \"Small Movement\", color = 'blue', linewidth = 2.1)\n",
    "plt.errorbar(t, HR_response_SLEEP_acc[\"low\"].mean(), yerr = sem_low_SLEEP_acc, fmt = '-o', color = 'blue', ecolor='blue', capsize=3, elinewidth=1.5)\n",
    "# shade the region below the curve\n",
    "#plt.fill_between(t, HR_response_SLEEP_acc[\"low\"].mean() - sem_low_SLEEP, HR_response_SLEEP_acc[\"low\"].mean() + sem_low_SLEEP, color = 'blue')\n",
    "\n",
    "plt.plot(t, HR_response_SLEEP_acc[\"medium\"].mean(), label = \"Medium Movement\", color = 'green', linewidth = 2.1)\n",
    "plt.errorbar(t, HR_response_SLEEP_acc[\"medium\"].mean(), yerr = sem_medium_SLEEP_acc, fmt = '-o', color = 'green', ecolor='green', capsize=3, elinewidth=1.5)\n",
    "\n",
    "plt.plot(t, HR_response_SLEEP_acc[\"high\"].mean(), label = \"Large Movement\", color = 'red', linewidth = 2.1)\n",
    "plt.errorbar(t, HR_response_SLEEP_acc[\"high\"].mean(), yerr = sem_high_SLEEP_acc, fmt = '-o', color = 'red', ecolor='red', capsize=3, elinewidth=1.5)\n",
    "\n",
    "ax.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "# ax.annotate('Movement onset', xy=(0, plt.ylim()[1]-6), xytext=(-60, plt.ylim()[1]-66),\n",
    "#              textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "#              bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "#              arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "plt.xlim(-15, 30)\n",
    "plt.title('Movement bursts - Sleep', fontsize = 21)\n",
    "\n",
    "# plt.xticks(ticks = np.arange(-20, 40, 5), labels=np.arange(-20, 40, 5), fontsize=16)\n",
    "ax.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax.set_ylabel('Envelopes difference change (%)', fontsize = 21)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax.set_label('')\n",
    "ax.xaxis.set_tick_params(labelsize=20)\n",
    "ax.yaxis.set_tick_params(labelsize=20)\n",
    "\n",
    "plt.legend(frameon = True, fancybox = True, shadow = True, fontsize = 18, loc = \"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/acc_tertiles.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA - General sleep parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='p2p', ylabel='AUC'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.regplot(data = bursts_HR_all_limbs_sleep, x = \"p2p\", y = \"AUC\", color = 'black', scatter_kws = {\"s\": 50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms2.out/\"\n",
    "part3_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms3.out/\"\n",
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\", \"127\", \"914\", \"965\"]\n",
    "\n",
    "SIB_GGIR = {sub: pyreadr.read_r(part3_outputFolder + \"LW_\" + sub + \".CWA.RData\")['sib.cla.sum'][[\"sib.onset.time\", \"sib.end.time\"]] for sub in subjects}\n",
    "\n",
    "tst = {sub: 0 for sub in subjects} # total sleep time\n",
    "waso = {sub: 0 for sub in subjects} # wake after sleep onset\n",
    "se = {sub: 0 for sub in subjects} # sleep efficiency\n",
    "spt_dur = {sub: 0 for sub in subjects} # sleep period time (from diary)\n",
    "n_awakenings = {sub: 0 for sub in subjects}\n",
    "\n",
    "SIB = {sub: 0 for sub in subjects}\n",
    "\n",
    "bursts_df = pd.DataFrame()\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "    SIB_GGIR[sub][\"sib.onset.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.onset.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.end.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.end.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.duration\"] = SIB_GGIR[sub][\"sib.end.time\"] - SIB_GGIR[sub][\"sib.onset.time\"]\n",
    "\n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/bursts_FINAL_envInterp_p2p.pkl', 'rb') as f:\n",
    "        bursts = pickle.load(f)\n",
    "\n",
    "    df_merged_intervals = characterize_bursts(bursts)\n",
    "    spt_start = diary_SPT[sub][0] - pd.Timedelta('10 min')\n",
    "    spt_end = diary_SPT[sub][1] + pd.Timedelta('5 min')\n",
    "    spt_dur[sub] = (diary_SPT[sub][1] - diary_SPT[sub][0]).total_seconds() / 60\n",
    "\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "\n",
    "    # Take df_merged_intervals between spt_start and spt_end\n",
    "    df_merged_intervals = df_merged_intervals[(df_merged_intervals[\"Start\"] >= spt_start) & (df_merged_intervals[\"End\"] <= spt_end)].reset_index(drop=True) \n",
    "\n",
    "    SIB[sub][\"awake.duration\"] = SIB[sub][\"sib.onset.time\"].shift(-1) - SIB[sub][\"sib.end.time\"]\n",
    "    SIB[sub][\"sib.duration\"] = SIB[sub][\"sib.end.time\"] - SIB[sub][\"sib.onset.time\"]\n",
    "    SIB[sub][\"sub_ID\"] = sub\n",
    "\n",
    "    tst[sub] = (SIB[sub][\"sib.duration\"].sum()).total_seconds() / 60\n",
    "    waso[sub] = (SIB[sub][\"awake.duration\"].sum()).total_seconds() / 60\n",
    "    se[sub] = 100 * (tst[sub] / spt_dur[sub])\n",
    "    n_awakenings[sub] = SIB[sub].shape[0]\n",
    "\n",
    "    df_merged_intervals[\"SIB\"] = 0\n",
    "    for i, row in SIB[sub].iterrows():\n",
    "        df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= row[\"sib.onset.time\"] + pd.Timedelta(\"5s\")) & (df_merged_intervals[\"End\"] <= row[\"sib.end.time\"] - pd.Timedelta(\"5s\")), \"SIB\"] = 1\n",
    "\n",
    "    df_merged_intervals[\"sub_ID\"] = sub\n",
    "\n",
    "    start_sleep = diary_SPT[sub][0]\n",
    "    end_sleep = diary_SPT[sub][1]\n",
    "\n",
    "    df_merged_intervals = df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= start_sleep) & (df_merged_intervals[\"End\"] <= end_sleep)]\n",
    "\n",
    "    bursts_df = pd.concat([bursts_df, df_merged_intervals])\n",
    "\n",
    "sleep_parameters = pd.DataFrame([spt_dur, tst, waso, se, n_awakenings]).T\n",
    "sleep_parameters.columns = [\"spt_duration\", \"tst\", \"waso\", \"se\", \"n_awakenings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spt_duration</th>\n",
       "      <th>tst</th>\n",
       "      <th>waso</th>\n",
       "      <th>se</th>\n",
       "      <th>n_awakenings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>451.916667</td>\n",
       "      <td>401.166667</td>\n",
       "      <td>45.631944</td>\n",
       "      <td>88.776035</td>\n",
       "      <td>16.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34.618593</td>\n",
       "      <td>40.918310</td>\n",
       "      <td>23.035312</td>\n",
       "      <td>6.209778</td>\n",
       "      <td>5.356955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>391.000000</td>\n",
       "      <td>319.500000</td>\n",
       "      <td>4.916667</td>\n",
       "      <td>77.434457</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>432.750000</td>\n",
       "      <td>385.750000</td>\n",
       "      <td>35.125000</td>\n",
       "      <td>84.762429</td>\n",
       "      <td>14.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>462.000000</td>\n",
       "      <td>401.250000</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>90.583966</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>480.000000</td>\n",
       "      <td>428.562500</td>\n",
       "      <td>62.187500</td>\n",
       "      <td>93.987475</td>\n",
       "      <td>19.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>495.000000</td>\n",
       "      <td>453.250000</td>\n",
       "      <td>92.083333</td>\n",
       "      <td>97.730740</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      spt_duration         tst       waso         se  n_awakenings\n",
       "mean    451.916667  401.166667  45.631944  88.776035     16.833333\n",
       "std      34.618593   40.918310  23.035312   6.209778      5.356955\n",
       "min     391.000000  319.500000   4.916667  77.434457      5.000000\n",
       "25%     432.750000  385.750000  35.125000  84.762429     14.750000\n",
       "50%     462.000000  401.250000  40.750000  90.583966     17.500000\n",
       "75%     480.000000  428.562500  62.187500  93.987475     19.500000\n",
       "max     495.000000  453.250000  92.083333  97.730740     24.000000"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_parameters.describe().drop(\"count\")#.to_excel(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/tables/sleep_parameters.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC tertiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='AUC', ylabel='Count'>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HR_burst_sleep = bursts_HR[bursts_HR[\"SIB\"] == 1].reset_index(drop=True)\n",
    "plt.figure(figsize=(15, 9))\n",
    "sns.histplot(data = HR_burst_sleep., x = \"AUC\", hue = \"sub_ID\", kde = True, bins = 100, palette = \"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table LMM SMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by Ibrahim2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms2.out/\"\n",
    "part3_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms3.out/\"\n",
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\", \"127\", \"914\", \"965\"]\n",
    "\n",
    "SIB_GGIR = {sub: pyreadr.read_r(part3_outputFolder + \"LW_\" + sub + \".CWA.RData\")['sib.cla.sum'][[\"sib.onset.time\", \"sib.end.time\"]] for sub in subjects}\n",
    "\n",
    "tst = {sub: 0 for sub in subjects}\n",
    "\n",
    "SIB = {sub: 0 for sub in subjects}\n",
    "\n",
    "bursts_df = pd.DataFrame()\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "    SIB_GGIR[sub][\"sib.onset.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.onset.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.end.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.end.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.duration\"] = SIB_GGIR[sub][\"sib.end.time\"] - SIB_GGIR[sub][\"sib.onset.time\"]\n",
    "\n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/bursts_FINAL_envInterp_p2p.pkl', 'rb') as f:\n",
    "        bursts = pickle.load(f)\n",
    "\n",
    "    df_merged_intervals = characterize_bursts(bursts)\n",
    "    spt_start = diary_SPT[sub][0] - pd.Timedelta('10 min')\n",
    "    spt_end = diary_SPT[sub][1] + pd.Timedelta('5 min')\n",
    "\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "\n",
    "    # Take df_merged_intervals between spt_start and spt_end\n",
    "    df_merged_intervals = df_merged_intervals[(df_merged_intervals[\"Start\"] >= spt_start) & (df_merged_intervals[\"End\"] <= spt_end)].reset_index(drop=True) \n",
    "\n",
    "    SIB[sub][\"awake.duration\"] = SIB[sub][\"sib.onset.time\"].shift(-1) - SIB[sub][\"sib.end.time\"]\n",
    "    SIB[sub][\"sib.duration\"] = SIB[sub][\"sib.end.time\"] - SIB[sub][\"sib.onset.time\"]\n",
    "    SIB[sub][\"sub_ID\"] = sub\n",
    "\n",
    "    tst[sub] = (SIB[sub][\"sib.duration\"].sum()).total_seconds() / 3600\n",
    "\n",
    "    df_merged_intervals[\"SIB\"] = 0\n",
    "    for i, row in SIB[sub].iterrows():\n",
    "        df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= row[\"sib.onset.time\"] + pd.Timedelta(\"5s\")) & (df_merged_intervals[\"End\"] <= row[\"sib.end.time\"] - pd.Timedelta(\"5s\")), \"SIB\"] = 1\n",
    "\n",
    "    df_merged_intervals[\"sub_ID\"] = sub\n",
    "\n",
    "    start_sleep = diary_SPT[sub][0]\n",
    "    end_sleep = diary_SPT[sub][1]\n",
    "\n",
    "    df_merged_intervals = df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= start_sleep) & (df_merged_intervals[\"End\"] <= end_sleep)]\n",
    "\n",
    "    bursts_df = pd.concat([bursts_df, df_merged_intervals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Duration</th>\n",
       "      <th>Duration_25</th>\n",
       "      <th>Duration_75</th>\n",
       "      <th>p2p</th>\n",
       "      <th>p2p_25</th>\n",
       "      <th>p2p_75</th>\n",
       "      <th>AUC</th>\n",
       "      <th>AUC_25</th>\n",
       "      <th>AUC_75</th>\n",
       "      <th>Index</th>\n",
       "      <th>Index_25</th>\n",
       "      <th>Index_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LMM</th>\n",
       "      <td>6.615276</td>\n",
       "      <td>3.052138</td>\n",
       "      <td>8.141433</td>\n",
       "      <td>634.037638</td>\n",
       "      <td>121.086123</td>\n",
       "      <td>746.070652</td>\n",
       "      <td>190795.448862</td>\n",
       "      <td>18348.368632</td>\n",
       "      <td>181179.642966</td>\n",
       "      <td>13.377803</td>\n",
       "      <td>10.220291</td>\n",
       "      <td>16.224240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full Body</th>\n",
       "      <td>10.296962</td>\n",
       "      <td>5.648363</td>\n",
       "      <td>12.402156</td>\n",
       "      <td>1214.984487</td>\n",
       "      <td>458.091229</td>\n",
       "      <td>1668.579219</td>\n",
       "      <td>400121.527796</td>\n",
       "      <td>103439.367030</td>\n",
       "      <td>522127.886597</td>\n",
       "      <td>5.428227</td>\n",
       "      <td>3.791913</td>\n",
       "      <td>5.806579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upper Limbs</th>\n",
       "      <td>3.428389</td>\n",
       "      <td>1.949274</td>\n",
       "      <td>4.278076</td>\n",
       "      <td>110.790790</td>\n",
       "      <td>52.346389</td>\n",
       "      <td>125.064653</td>\n",
       "      <td>20131.131198</td>\n",
       "      <td>6283.789016</td>\n",
       "      <td>22106.758327</td>\n",
       "      <td>2.155727</td>\n",
       "      <td>1.262118</td>\n",
       "      <td>2.233489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lower Limbs</th>\n",
       "      <td>3.051856</td>\n",
       "      <td>2.149417</td>\n",
       "      <td>3.769241</td>\n",
       "      <td>206.982888</td>\n",
       "      <td>100.001666</td>\n",
       "      <td>280.586180</td>\n",
       "      <td>36774.655978</td>\n",
       "      <td>14924.002531</td>\n",
       "      <td>54271.457996</td>\n",
       "      <td>0.705702</td>\n",
       "      <td>0.234254</td>\n",
       "      <td>0.989097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other Limbs</th>\n",
       "      <td>4.939939</td>\n",
       "      <td>2.608696</td>\n",
       "      <td>6.390312</td>\n",
       "      <td>225.138434</td>\n",
       "      <td>96.959697</td>\n",
       "      <td>264.022595</td>\n",
       "      <td>49160.997783</td>\n",
       "      <td>13647.500232</td>\n",
       "      <td>63010.382609</td>\n",
       "      <td>4.146974</td>\n",
       "      <td>2.436501</td>\n",
       "      <td>4.607952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMM</th>\n",
       "      <td>1.396044</td>\n",
       "      <td>0.536250</td>\n",
       "      <td>1.859791</td>\n",
       "      <td>36.659786</td>\n",
       "      <td>20.708005</td>\n",
       "      <td>39.132783</td>\n",
       "      <td>4810.767487</td>\n",
       "      <td>1048.097530</td>\n",
       "      <td>5648.333718</td>\n",
       "      <td>10.251923</td>\n",
       "      <td>7.647735</td>\n",
       "      <td>10.704056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Duration  Duration_25  Duration_75          p2p      p2p_25  \\\n",
       "LMM           6.615276     3.052138     8.141433   634.037638  121.086123   \n",
       "Full Body    10.296962     5.648363    12.402156  1214.984487  458.091229   \n",
       "Upper Limbs   3.428389     1.949274     4.278076   110.790790   52.346389   \n",
       "Lower Limbs   3.051856     2.149417     3.769241   206.982888  100.001666   \n",
       "Other Limbs   4.939939     2.608696     6.390312   225.138434   96.959697   \n",
       "SMM           1.396044     0.536250     1.859791    36.659786   20.708005   \n",
       "\n",
       "                  p2p_75            AUC         AUC_25         AUC_75  \\\n",
       "LMM           746.070652  190795.448862   18348.368632  181179.642966   \n",
       "Full Body    1668.579219  400121.527796  103439.367030  522127.886597   \n",
       "Upper Limbs   125.064653   20131.131198    6283.789016   22106.758327   \n",
       "Lower Limbs   280.586180   36774.655978   14924.002531   54271.457996   \n",
       "Other Limbs   264.022595   49160.997783   13647.500232   63010.382609   \n",
       "SMM            39.132783    4810.767487    1048.097530    5648.333718   \n",
       "\n",
       "                 Index   Index_25   Index_75  \n",
       "LMM          13.377803  10.220291  16.224240  \n",
       "Full Body     5.428227   3.791913   5.806579  \n",
       "Upper Limbs   2.155727   1.262118   2.233489  \n",
       "Lower Limbs   0.705702   0.234254   0.989097  \n",
       "Other Limbs   4.146974   2.436501   4.607952  \n",
       "SMM          10.251923   7.647735  10.704056  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_df_sleep = bursts_df[bursts_df[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_df_sleep[\"Duration\"] = bursts_df_sleep[\"End\"] - bursts_df_sleep[\"Start\"]\n",
    "bursts_df_sleep[\"Duration\"] = bursts_df_sleep[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_df_sleep[\"n_limbs\"] = bursts_df_sleep[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_df_LMM = bursts_df_sleep[(bursts_df_sleep[\"n_limbs\"] >= 2)].reset_index(drop=True)\n",
    "bursts_df_fullBody = bursts_df_sleep[(bursts_df_sleep[\"n_limbs\"] == 5)].reset_index(drop=True)\n",
    "bursts_df_upper = bursts_df_sleep[(bursts_df_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LL\", \"RL\", \"T\"})]\n",
    "bursts_df_lower = bursts_df_sleep[(bursts_df_sleep[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_HR_sleep[\"Limbs\"] == {\"LW\", \"RW\", \"T\"})]\n",
    "bursts_df_LMM_others = bursts_df_sleep[(bursts_df_sleep[\"n_limbs\"] >= 2) & (bursts_df_sleep[\"n_limbs\"] != 5) & (bursts_df_sleep[\"Limbs\"] != {\"LL\", \"RL\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LL\", \"RL\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LW\", \"RW\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LW\", \"RW\", \"T\"})].reset_index(drop=True)\n",
    "bursts_df_SMM = bursts_df_sleep[(bursts_df_sleep[\"n_limbs\"] == 1)].reset_index(drop=True)\n",
    "\n",
    "bursts_df_LMM[\"Duration\"].describe()\n",
    "bursts_df_SMM[\"Duration\"].describe()\n",
    "\n",
    "duration_LMM_50 = bursts_df_LMM.groupby(\"sub_ID\")[\"Duration\"].mean()\n",
    "duration_LMM_25 = bursts_df_LMM.groupby(\"sub_ID\")[\"Duration\"].quantile(0.25).mean()\n",
    "duration_LMM_75 = bursts_df_LMM.groupby(\"sub_ID\")[\"Duration\"].quantile(0.75).mean()\n",
    "\n",
    "duration_fullBody_50 = bursts_df_fullBody.groupby(\"sub_ID\")[\"Duration\"].mean()\n",
    "duration_fullBody_25 = bursts_df_fullBody.groupby(\"sub_ID\")[\"Duration\"].quantile(0.25).mean()\n",
    "duration_fullBody_75 = bursts_df_fullBody.groupby(\"sub_ID\")[\"Duration\"].quantile(0.75).mean()\n",
    "\n",
    "duration_upper_50 = bursts_df_upper.groupby(\"sub_ID\")[\"Duration\"].mean()\n",
    "duration_upper_25 = bursts_df_upper.groupby(\"sub_ID\")[\"Duration\"].quantile(0.25).mean()\n",
    "duration_upper_75 = bursts_df_upper.groupby(\"sub_ID\")[\"Duration\"].quantile(0.75).mean()\n",
    "\n",
    "duration_lower_50 = bursts_df_lower.groupby(\"sub_ID\")[\"Duration\"].mean()\n",
    "duration_lower_25 = bursts_df_lower.groupby(\"sub_ID\")[\"Duration\"].quantile(0.25).mean()\n",
    "duration_lower_75 = bursts_df_lower.groupby(\"sub_ID\")[\"Duration\"].quantile(0.75).mean()\n",
    "\n",
    "duration_other_50 = bursts_df_LMM_others.groupby(\"sub_ID\")[\"Duration\"].mean()\n",
    "duration_other_25 = bursts_df_LMM_others.groupby(\"sub_ID\")[\"Duration\"].quantile(0.25).mean()\n",
    "duration_other_75 = bursts_df_LMM_others.groupby(\"sub_ID\")[\"Duration\"].quantile(0.75).mean()\n",
    "\n",
    "duration_SMM_50 = bursts_df_SMM.groupby(\"sub_ID\")[\"Duration\"].mean()\n",
    "duration_SMM_25 = bursts_df_SMM.groupby(\"sub_ID\")[\"Duration\"].quantile(0.25).mean()\n",
    "duration_SMM_75 = bursts_df_SMM.groupby(\"sub_ID\")[\"Duration\"].quantile(0.75).mean()\n",
    "\n",
    "p2p_LMM_50 = bursts_df_LMM.groupby(\"sub_ID\")[\"p2p\"].mean()\n",
    "p2p_LMM_25 = bursts_df_LMM.groupby(\"sub_ID\")[\"p2p\"].quantile(0.25).mean()\n",
    "p2p_LMM_75 = bursts_df_LMM.groupby(\"sub_ID\")[\"p2p\"].quantile(0.75).mean()\n",
    "\n",
    "p2p_fullBody_50 = bursts_df_fullBody.groupby(\"sub_ID\")[\"p2p\"].mean()\n",
    "p2p_fullBody_25 = bursts_df_fullBody.groupby(\"sub_ID\")[\"p2p\"].quantile(0.25).mean()\n",
    "p2p_fullBody_75 = bursts_df_fullBody.groupby(\"sub_ID\")[\"p2p\"].quantile(0.75).mean()\n",
    "\n",
    "p2p_upper_50 = bursts_df_upper.groupby(\"sub_ID\")[\"p2p\"].mean()\n",
    "p2p_upper_25 = bursts_df_upper.groupby(\"sub_ID\")[\"p2p\"].quantile(0.25).mean()\n",
    "p2p_upper_75 = bursts_df_upper.groupby(\"sub_ID\")[\"p2p\"].quantile(0.75).mean()\n",
    "\n",
    "p2p_lower_50 = bursts_df_lower.groupby(\"sub_ID\")[\"p2p\"].mean()\n",
    "p2p_lower_25 = bursts_df_lower.groupby(\"sub_ID\")[\"p2p\"].quantile(0.25).mean()\n",
    "p2p_lower_75 = bursts_df_lower.groupby(\"sub_ID\")[\"p2p\"].quantile(0.75).mean()\n",
    "\n",
    "p2p_other_50 = bursts_df_LMM_others.groupby(\"sub_ID\")[\"p2p\"].mean()\n",
    "p2p_other_25 = bursts_df_LMM_others.groupby(\"sub_ID\")[\"p2p\"].quantile(0.25).mean()\n",
    "p2p_other_75 = bursts_df_LMM_others.groupby(\"sub_ID\")[\"p2p\"].quantile(0.75).mean()\n",
    "\n",
    "p2p_SMM_50 = bursts_df_SMM.groupby(\"sub_ID\")[\"p2p\"].mean()\n",
    "p2p_SMM_25 = bursts_df_SMM.groupby(\"sub_ID\")[\"p2p\"].quantile(0.25).mean()\n",
    "p2p_SMM_75 = bursts_df_SMM.groupby(\"sub_ID\")[\"p2p\"].quantile(0.75).mean()\n",
    "\n",
    "AUC_LMM_50 = bursts_df_LMM.groupby(\"sub_ID\")[\"AUC\"].mean()\n",
    "AUC_LMM_25 = bursts_df_LMM.groupby(\"sub_ID\")[\"AUC\"].quantile(0.25).mean()\n",
    "AUC_LMM_75 = bursts_df_LMM.groupby(\"sub_ID\")[\"AUC\"].quantile(0.75).mean()\n",
    "\n",
    "AUC_fullBody_50 = bursts_df_fullBody.groupby(\"sub_ID\")[\"AUC\"].mean()\n",
    "AUC_fullBody_25 = bursts_df_fullBody.groupby(\"sub_ID\")[\"AUC\"].quantile(0.25).mean()\n",
    "AUC_fullBody_75 = bursts_df_fullBody.groupby(\"sub_ID\")[\"AUC\"].quantile(0.75).mean()\n",
    "\n",
    "AUC_upper_50 = bursts_df_upper.groupby(\"sub_ID\")[\"AUC\"].mean()\n",
    "AUC_upper_25 = bursts_df_upper.groupby(\"sub_ID\")[\"AUC\"].quantile(0.25).mean()\n",
    "AUC_upper_75 = bursts_df_upper.groupby(\"sub_ID\")[\"AUC\"].quantile(0.75).mean()\n",
    "\n",
    "AUC_lower_50 = bursts_df_lower.groupby(\"sub_ID\")[\"AUC\"].mean()\n",
    "AUC_lower_25 = bursts_df_lower.groupby(\"sub_ID\")[\"AUC\"].quantile(0.25).mean()\n",
    "AUC_lower_75 = bursts_df_lower.groupby(\"sub_ID\")[\"AUC\"].quantile(0.75).mean()\n",
    "\n",
    "AUC_other_50 = bursts_df_LMM_others.groupby(\"sub_ID\")[\"AUC\"].mean()\n",
    "AUC_other_25 = bursts_df_LMM_others.groupby(\"sub_ID\")[\"AUC\"].quantile(0.25).mean()\n",
    "AUC_other_75 = bursts_df_LMM_others.groupby(\"sub_ID\")[\"AUC\"].quantile(0.75).mean()\n",
    "\n",
    "AUC_SMM_50 = bursts_df_SMM.groupby(\"sub_ID\")[\"AUC\"].mean()\n",
    "AUC_SMM_25 = bursts_df_SMM.groupby(\"sub_ID\")[\"AUC\"].quantile(0.25).mean()\n",
    "AUC_SMM_75 = bursts_df_SMM.groupby(\"sub_ID\")[\"AUC\"].quantile(0.75).mean()\n",
    "\n",
    "tst_df = pd.DataFrame(tst, index = [\"TST\"]).T.sort_index()\n",
    "\n",
    "index_LMM = bursts_df_LMM.groupby(\"sub_ID\")[\"Start\"].count() / tst_df[\"TST\"]\n",
    "index_fullBody = bursts_df_fullBody.groupby(\"sub_ID\")[\"Start\"].count() / tst_df[\"TST\"]\n",
    "index_upper = bursts_df_upper.groupby(\"sub_ID\")[\"Start\"].count() / tst_df[\"TST\"]\n",
    "index_lower = bursts_df_lower.groupby(\"sub_ID\")[\"Start\"].count() / tst_df[\"TST\"]\n",
    "index_other = bursts_df_LMM_others.groupby(\"sub_ID\")[\"Start\"].count() / tst_df[\"TST\"]\n",
    "index_SMM = bursts_df_SMM.groupby(\"sub_ID\")[\"Start\"].count() / tst_df[\"TST\"]\n",
    "\n",
    "index_LMM_50 = index_LMM.mean()\n",
    "index_LMM_25 = index_LMM.quantile(0.25).mean()\n",
    "index_LMM_75 = index_LMM.quantile(0.75).mean()\n",
    "\n",
    "index_fullBody_50 = index_fullBody.mean()\n",
    "index_fullBody_25 = index_fullBody.quantile(0.25).mean()\n",
    "index_fullBody_75 = index_fullBody.quantile(0.75).mean()\n",
    "\n",
    "index_upper_50 = index_upper.mean()\n",
    "index_upper_25 = index_upper.quantile(0.25).mean()\n",
    "index_upper_75 = index_upper.quantile(0.75).mean()\n",
    "\n",
    "index_lower_50 = index_lower.mean()\n",
    "index_lower_25 = index_lower.quantile(0.25).mean()\n",
    "index_lower_75 = index_lower.quantile(0.75).mean()\n",
    "\n",
    "index_other_50 = index_other.mean()\n",
    "index_other_25 = index_other.quantile(0.25).mean()\n",
    "index_other_75 = index_other.quantile(0.75).mean()\n",
    "\n",
    "index_SMM_50 = index_SMM.mean()\n",
    "index_SMM_25 = index_SMM.quantile(0.25).mean()\n",
    "index_SMM_75 = index_SMM.quantile(0.75).mean()\n",
    "\n",
    "# Put all of the data in a single dataframe\n",
    "\n",
    "data = {\n",
    "    \"Duration\": [duration_LMM_50.mean(), duration_fullBody_50.mean(), duration_upper_50.mean(), duration_lower_50.mean(), duration_other_50.mean(), duration_SMM_50.mean()],\n",
    "    \"Duration_25\": [duration_LMM_25, duration_fullBody_25, duration_upper_25, duration_lower_25, duration_other_25, duration_SMM_25],\n",
    "    \"Duration_75\": [duration_LMM_75, duration_fullBody_75, duration_upper_75, duration_lower_75, duration_other_75, duration_SMM_75],\n",
    "    \"p2p\": [p2p_LMM_50.mean(), p2p_fullBody_50.mean(), p2p_upper_50.mean(), p2p_lower_50.mean(), p2p_other_50.mean(), p2p_SMM_50.mean()],\n",
    "    \"p2p_25\": [p2p_LMM_25, p2p_fullBody_25, p2p_upper_25, p2p_lower_25, p2p_other_25, p2p_SMM_25],\n",
    "    \"p2p_75\": [p2p_LMM_75, p2p_fullBody_75, p2p_upper_75, p2p_lower_75, p2p_other_75, p2p_SMM_75],\n",
    "    \"AUC\": [AUC_LMM_50.mean(), AUC_fullBody_50.mean(), AUC_upper_50.mean(), AUC_lower_50.mean(), AUC_other_50.mean(), AUC_SMM_50.mean()],\n",
    "    \"AUC_25\": [AUC_LMM_25, AUC_fullBody_25, AUC_upper_25, AUC_lower_25, AUC_other_25, AUC_SMM_25],\n",
    "    \"AUC_75\": [AUC_LMM_75, AUC_fullBody_75, AUC_upper_75, AUC_lower_75, AUC_other_75, AUC_SMM_75],\n",
    "    \"Index\": [index_LMM_50, index_fullBody_50, index_upper_50, index_lower_50, index_other_50, index_SMM_50],\n",
    "    \"Index_25\": [index_LMM_25, index_fullBody_25, index_upper_25, index_lower_25, index_other_25, index_SMM_25],\n",
    "        \"Index_75\": [index_LMM_75, index_fullBody_75, index_upper_75, index_lower_75, index_other_75, index_SMM_75]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data, index = [\"LMM\", \"Full Body\", \"Upper Limbs\", \"Lower Limbs\", \"Other Limbs\", \"SMM\"])\n",
    "\n",
    "#df.round(2).to_excel(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/tables/table1.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table OP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial distribution of movements was subdivided into two categories: focal movements and large muscle group movements (LMM). Focal movements were defined as localized to one body part [7], while LMM as temporally overlapping bursts in any combination of at least two body parts [8]. LMM were further categorized into: \n",
    "- Full-body movements: bursts involving all five sensors.\n",
    "- Upper body movements: bursts involving both wrists or both wrists and trunk.\n",
    "- Lower body movements: bursts involving both ankles or both ankles and trunk.\n",
    "- Mixed movements: bursts involving both upper and lower extremities and different from full-body movements.\n",
    "\n",
    "Movement laterality was described as unilateral if movements involved only one side of the body or bilateral if both sides were involved [7].\n",
    "Finally, posture changes were identified as shifts of a least 30 in the orientation of the accelerometer placed on the lower back [9]. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms2.out/\"\n",
    "part3_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms3.out/\"\n",
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\", \"127\", \"914\", \"965\"]\n",
    "\n",
    "SIB_GGIR = {sub: pyreadr.read_r(part3_outputFolder + \"LW_\" + sub + \".CWA.RData\")['sib.cla.sum'][[\"sib.onset.time\", \"sib.end.time\"]] for sub in subjects}\n",
    "\n",
    "tst = {sub: 0 for sub in subjects}\n",
    "twt = {sub: 0 for sub in subjects}\n",
    "\n",
    "SIB = {sub: 0 for sub in subjects}\n",
    "\n",
    "bursts_df = pd.DataFrame()\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "    SIB_GGIR[sub][\"sib.onset.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.onset.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.end.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.end.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.duration\"] = SIB_GGIR[sub][\"sib.end.time\"] - SIB_GGIR[sub][\"sib.onset.time\"]\n",
    "\n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/bursts_FINAL_envInterp_p2p.pkl', 'rb') as f:\n",
    "        bursts = pickle.load(f)\n",
    "\n",
    "    df_merged_intervals = characterize_bursts(bursts)\n",
    "    spt_start = diary_SPT[sub][0] - pd.Timedelta('10 min')\n",
    "    spt_end = diary_SPT[sub][1] + pd.Timedelta('5 min')\n",
    "\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "\n",
    "    # Take df_merged_intervals between spt_start and spt_end\n",
    "    df_merged_intervals = df_merged_intervals[(df_merged_intervals[\"Start\"] >= spt_start) & (df_merged_intervals[\"End\"] <= spt_end)].reset_index(drop=True) \n",
    "\n",
    "    SIB[sub][\"awake.duration\"] = SIB[sub][\"sib.onset.time\"].shift(-1) - SIB[sub][\"sib.end.time\"]\n",
    "    SIB[sub][\"sib.duration\"] = SIB[sub][\"sib.end.time\"] - SIB[sub][\"sib.onset.time\"]\n",
    "    SIB[sub][\"sub_ID\"] = sub\n",
    "\n",
    "    tst[sub] = (SIB[sub][\"sib.duration\"].sum()).total_seconds() / 3600\n",
    "    twt[sub] = (SIB[sub][\"awake.duration\"].sum()).total_seconds() / 3600\n",
    "\n",
    "    df_merged_intervals[\"SIB\"] = 0\n",
    "    for i, row in SIB[sub].iterrows():\n",
    "        df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= row[\"sib.onset.time\"] + pd.Timedelta(\"5s\")) & (df_merged_intervals[\"End\"] <= row[\"sib.end.time\"] - pd.Timedelta(\"5s\")), \"SIB\"] = 1\n",
    "\n",
    "    df_merged_intervals[\"sub_ID\"] = sub\n",
    "\n",
    "    start_sleep = diary_SPT[sub][0]\n",
    "    end_sleep = diary_SPT[sub][1]\n",
    "\n",
    "    df_merged_intervals = df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= start_sleep) & (df_merged_intervals[\"End\"] <= end_sleep)]\n",
    "\n",
    "    bursts_df = pd.concat([bursts_df, df_merged_intervals])\n",
    "    \n",
    "tst_df = pd.DataFrame(tst, index = [\"TST\"]).T.sort_index()\n",
    "twt_df = pd.DataFrame(twt, index = [\"TWT\"]).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>AUC</th>\n",
       "      <th>p2p</th>\n",
       "      <th>PC</th>\n",
       "      <th>transition</th>\n",
       "      <th>Limbs</th>\n",
       "      <th>SIB</th>\n",
       "      <th>sub_ID</th>\n",
       "      <th>Duration</th>\n",
       "      <th>n_limbs</th>\n",
       "      <th>Category</th>\n",
       "      <th>Laterality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-28 23:00:01.360290051</td>\n",
       "      <td>2024-02-28 23:00:02.460289955</td>\n",
       "      <td>4478.029974</td>\n",
       "      <td>59.446242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{LL, RL, T}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>1.099999</td>\n",
       "      <td>3</td>\n",
       "      <td>Lower Body</td>\n",
       "      <td>Bilateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-28 23:00:30.130290031</td>\n",
       "      <td>2024-02-28 23:00:32.030289888</td>\n",
       "      <td>5565.732278</td>\n",
       "      <td>48.247713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{LL}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>1.899999</td>\n",
       "      <td>1</td>\n",
       "      <td>Focal</td>\n",
       "      <td>Unilateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-28 23:00:43.494869947</td>\n",
       "      <td>2024-02-28 23:00:43.874870062</td>\n",
       "      <td>593.812924</td>\n",
       "      <td>16.318746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{T}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1</td>\n",
       "      <td>Focal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-28 23:02:28.765630007</td>\n",
       "      <td>2024-02-28 23:02:31.105629921</td>\n",
       "      <td>6965.555964</td>\n",
       "      <td>44.916305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{LW, T}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>2.339999</td>\n",
       "      <td>2</td>\n",
       "      <td>Upper Body</td>\n",
       "      <td>Unilateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-28 23:03:30.215630054</td>\n",
       "      <td>2024-02-28 23:03:32.105629921</td>\n",
       "      <td>6534.732075</td>\n",
       "      <td>50.164798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{LW, T}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>1.889999</td>\n",
       "      <td>2</td>\n",
       "      <td>Upper Body</td>\n",
       "      <td>Unilateral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Start                           End          AUC  \\\n",
       "0 2024-02-28 23:00:01.360290051 2024-02-28 23:00:02.460289955  4478.029974   \n",
       "1 2024-02-28 23:00:30.130290031 2024-02-28 23:00:32.030289888  5565.732278   \n",
       "2 2024-02-28 23:00:43.494869947 2024-02-28 23:00:43.874870062   593.812924   \n",
       "3 2024-02-28 23:02:28.765630007 2024-02-28 23:02:31.105629921  6965.555964   \n",
       "4 2024-02-28 23:03:30.215630054 2024-02-28 23:03:32.105629921  6534.732075   \n",
       "\n",
       "         p2p   PC transition        Limbs  SIB sub_ID  Duration  n_limbs  \\\n",
       "0  59.446242  0.0       None  {LL, RL, T}    1    158  1.099999        3   \n",
       "1  48.247713  0.0       None         {LL}    1    158  1.899999        1   \n",
       "2  16.318746  0.0       None          {T}    1    158  0.380000        1   \n",
       "3  44.916305  0.0       None      {LW, T}    1    158  2.339999        2   \n",
       "4  50.164798  0.0       None      {LW, T}    1    158  1.889999        2   \n",
       "\n",
       "     Category  Laterality  \n",
       "0  Lower Body   Bilateral  \n",
       "1       Focal  Unilateral  \n",
       "2       Focal        None  \n",
       "3  Upper Body  Unilateral  \n",
       "4  Upper Body  Unilateral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_df_sleep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_df_sleep = bursts_df[bursts_df[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_df_sleep[\"Duration\"] = bursts_df_sleep[\"End\"] - bursts_df_sleep[\"Start\"]\n",
    "bursts_df_sleep[\"Duration\"] = bursts_df_sleep[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_df_sleep[\"n_limbs\"] = bursts_df_sleep[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_df_sleep[\"Category\"] = \"placeholder\"\n",
    "bursts_df_sleep[\"Laterality\"] = \"Bilateral\"\n",
    "bursts_df_sleep.loc[bursts_df_sleep[\"n_limbs\"] == 5, \"Category\"] = \"Full Body\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}), \"Category\"] = \"Lower Body\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RW\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}), \"Category\"] = \"Upper Body\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"n_limbs\"] >= 2) & (bursts_df_sleep[\"n_limbs\"] != 5) & (bursts_df_sleep[\"Limbs\"] != {\"LL\", \"RL\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LL\", \"RL\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LW\", \"RW\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LW\", \"RW\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LL\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"RL\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LW\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"RW\", \"T\"}), \"Category\"] = \"Mixed\"\n",
    "bursts_df_sleep.loc[bursts_df_sleep[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LL\", \"LW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\", \"RW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LL\", \"LW\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\", \"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LL\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_sleep.loc[bursts_df_sleep[\"Limbs\"] == {\"T\"}, \"Laterality\"] = \"None\"\n",
    "\n",
    "bursts_df_wake = bursts_df[bursts_df[\"SIB\"] == 0].reset_index(drop=True)\n",
    "bursts_df_wake[\"Duration\"] = bursts_df_wake[\"End\"] - bursts_df_wake[\"Start\"]\n",
    "bursts_df_wake[\"Duration\"] = bursts_df_wake[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_df_wake[\"n_limbs\"] = bursts_df_wake[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_df_wake[\"Category\"] = \"placeholder\"\n",
    "bursts_df_wake[\"Laterality\"] = \"Bilateral\"\n",
    "bursts_df_wake.loc[bursts_df_wake[\"n_limbs\"] == 5, \"Category\"] = \"Full Body\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_wake[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}), \"Category\"] = \"Lower Body\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_df_wake[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RW\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}), \"Category\"] = \"Upper Body\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"n_limbs\"] >= 2) & (bursts_df_wake[\"n_limbs\"] != 5) & (bursts_df_wake[\"Limbs\"] != {\"LL\", \"RL\"}) & (bursts_df_wake[\"Limbs\"] != {\"LL\", \"RL\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"LW\", \"RW\"}) & (bursts_df_wake[\"Limbs\"] != {\"LW\", \"RW\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"LL\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"RL\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"LW\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"RW\", \"T\"}), \"Category\"] = \"Mixed\"\n",
    "bursts_df_wake.loc[bursts_df_wake[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LL\", \"LW\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\", \"RW\"}) | (bursts_df_wake[\"Limbs\"] == {\"LL\", \"LW\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\", \"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_wake[\"Limbs\"] == {\"LW\"}) | (bursts_df_wake[\"Limbs\"] == {\"RW\"}) | (bursts_df_wake[\"Limbs\"] == {\"LL\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_wake.loc[bursts_df_wake[\"Limbs\"] == {\"T\"}, \"Laterality\"] = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2466, 9), (1698, 13, 768, 13))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_df.shape, bursts_df_sleep.shape + bursts_df_wake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     12.000000\n",
       "mean      90.359088\n",
       "std       21.429939\n",
       "min       59.405941\n",
       "25%       81.131145\n",
       "50%       85.293105\n",
       "75%       97.282027\n",
       "90%      121.213908\n",
       "max      130.370370\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movement_index = bursts_df_wake.groupby(\"sub_ID\")[\"Duration\"].count() / twt_df[\"TWT\"]\n",
    "movement_index.describe(percentiles=[0.25, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean     16.882710\n",
       "std       6.945090\n",
       "min       9.807177\n",
       "25%      11.510286\n",
       "50%      14.381433\n",
       "75%      21.239613\n",
       "90%      23.207790\n",
       "max      33.189712\n",
       "Name: Duration, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration = bursts_df_sleep.groupby(\"sub_ID\")[\"Duration\"].mean()\n",
    "duration.describe(percentiles=[0.25, 0.75, 0.9])\n",
    "\n",
    "duration = bursts_df_wake.groupby(\"sub_ID\")[\"Duration\"].mean()\n",
    "duration.describe(percentiles=[0.25, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    12.000000\n",
      "mean     15.704592\n",
      "std       5.448969\n",
      "min       5.319149\n",
      "25%      12.782609\n",
      "50%      14.753042\n",
      "75%      19.423077\n",
      "90%      21.411765\n",
      "max      26.250000\n",
      "Name: Focal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#print((bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].count().unstack().T.div(bursts_df_wake.groupby([\"sub_ID\"])[\"Duration\"].count(), axis = 0)*100)[[\"Full Body\"]].describe(percentiles=[0.25, 0.75, 0.9]))\n",
    "print((bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].count().unstack().T.div(bursts_df_wake.groupby([\"sub_ID\"])[\"Duration\"].count(), axis = 0)*100)[\"Focal\"].describe(percentiles=[0.25, 0.75, 0.9]))\n",
    "#(bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].count().unstack().T.div(bursts_df_wake.groupby([\"sub_ID\"])[\"Duration\"].count(), axis = 0)*100)[\"Mixed\"].describe(percentiles=[0.25, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laterality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    12.000000\n",
      "mean     19.349721\n",
      "std       7.139817\n",
      "min       8.510638\n",
      "25%      15.623188\n",
      "50%      17.752326\n",
      "75%      22.426471\n",
      "max      33.750000\n",
      "dtype: float64\n",
      "count    12.000000\n",
      "mean     79.873664\n",
      "std       7.136044\n",
      "min      66.250000\n",
      "25%      75.622172\n",
      "50%      81.279070\n",
      "75%      84.376812\n",
      "max      91.489362\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(((bursts_df_wake.groupby([\"sub_ID\", \"Laterality\"])[\"Laterality\"].count().unstack()[\"Unilateral\"] / bursts_df_wake.groupby([\"sub_ID\"])[\"Duration\"].count())*100).describe())\n",
    "print(((bursts_df_wake.groupby([\"sub_ID\", \"Laterality\"])[\"Laterality\"].count().unstack()[\"Bilateral\"] / bursts_df_wake.groupby([\"sub_ID\"])[\"Duration\"].count())*100).describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_df_sleep[\"PC\"].replace(0, np.nan, inplace = True)\n",
    "bursts_df_sleep[\"PC\"] = bursts_df_sleep[\"PC\"].apply(lambda x: 1 if x < 100 else np.nan)\n",
    "\n",
    "bursts_df_wake[\"PC\"].replace(0, np.nan, inplace = True)\n",
    "bursts_df_wake[\"PC\"] = bursts_df_wake[\"PC\"].apply(lambda x: 1 if x < 100 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean      3.166667\n",
       "std       3.010084\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       2.500000\n",
       "75%       5.000000\n",
       "90%       7.700000\n",
       "max       9.000000\n",
       "Name: Full Body, dtype: float64"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of full body movements that are posture changes in sleep\n",
    "n_tot_fullBody_sleep = bursts_df_sleep[bursts_df_sleep[\"Category\"] == \"Full Body\"].shape[0]\n",
    "(bursts_df_sleep.groupby([\"sub_ID\", \"Category\"])[\"PC\"].count().unstack()[\"Full Body\"].sum() / n_tot_fullBody_sleep)*100\n",
    "\n",
    "#median and IQR\n",
    "((bursts_df_sleep.groupby([\"sub_ID\", \"Category\"])[\"PC\"].count().unstack()[\"Full Body\"])).describe(percentiles=[0.25, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12.000000\n",
       "mean     12.000000\n",
       "std       4.954337\n",
       "min       6.000000\n",
       "25%       9.000000\n",
       "50%      11.000000\n",
       "75%      14.000000\n",
       "90%      19.400000\n",
       "max      22.000000\n",
       "Name: Full Body, dtype: float64"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of full body movements that are posture changes in wake\n",
    "n_tot_fullBody_wake = bursts_df_wake[bursts_df_wake[\"Category\"] == \"Full Body\"].shape[0]\n",
    "(bursts_df_wake.groupby([\"sub_ID\", \"Category\"])[\"PC\"].count().unstack()[\"Full Body\"].sum() / n_tot_fullBody_wake)*100\n",
    "\n",
    "#median and IQR\n",
    "((bursts_df_wake.groupby([\"sub_ID\", \"Category\"])[\"PC\"].count().unstack()[\"Full Body\"])).describe(percentiles=[0.25, 0.75, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sense that almost all posture changes are during wake since vanhees2015 is based on orientation changes of LW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number - within subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sub_ID'>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].count().unstack().T.plot(kind = \"bar\", figsize = (15, 9), stacked = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but expressed as percentage and write the percentage on top of the bars\n",
    "ax = (bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].count().unstack().T.div(bursts_df_sleep.groupby([\"sub_ID\"])[\"Duration\"].count(), axis = 0)*100).plot(kind = \"bar\", figsize = (15, 9), stacked = True)\n",
    "ax.set_xlabel(\"Subjects\", fontsize = 19)\n",
    "ax.set_ylabel(\"Movement percentage\", fontsize = 19)\n",
    "ax.set_title(\"Movement distribution\", fontsize = 21)\n",
    "ax.set_xticks([])\n",
    "# put legend outside the plot\n",
    "ax.legend(title = \"Category\", fontsize = 14, frameon = True, fancybox = True, shadow = True, loc = \"upper right\", bbox_to_anchor=(1.18, 1)) \n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sleep vs Wake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Category'>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perc_sleep = pd.DataFrame(bursts_df_sleep.groupby([\"Category\"])[\"Duration\"].count() / bursts_df_sleep[\"Duration\"].count())\n",
    "perc_wake = pd.DataFrame(bursts_df_wake.groupby([\"Category\"])[\"Duration\"].count() / bursts_df_wake[\"Duration\"].count())\n",
    "\n",
    "df = pd.concat([perc_sleep, perc_wake], axis = 1)\n",
    "df.columns = [\"Sleep\", \"Wake\"]\n",
    "\n",
    "df.plot(kind = \"bar\", figsize = (15, 9), stacked = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 0.3\n",
    "\n",
    "(ax1, ax2) = df.plot(kind = \"pie\", subplots = True, figsize = (15, 9), autopct = \"%.1f%%\", textprops = {\"fontsize\": 16})\n",
    "ax1.set_title(\"Sleep\", fontsize = 21)\n",
    "ax1.set_ylabel(\"\")\n",
    "ax1.legend([])\n",
    "ax2.set_title(\"Wake\", fontsize = 21)\n",
    "ax2.set_ylabel(\"\")\n",
    "ax2.legend([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42756184, 0.23733804, 0.15253239, 0.13780919, 0.04475854])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sleep\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.25757575757575757,\n",
       " 0.2493112947658402,\n",
       " 0.23140495867768596,\n",
       " 0.18732782369146006,\n",
       " 0.0743801652892562)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "singleLimb_df = bursts_df_sleep[bursts_df_sleep[\"Category\"] == \"Focal\"].reset_index(drop=True)\n",
    "perc_LW = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"LW\"}].shape[0] / singleLimb_df.shape[0]\n",
    "perc_RW = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"RW\"}].shape[0] / singleLimb_df.shape[0]\n",
    "perc_LL = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"LL\"}].shape[0] / singleLimb_df.shape[0]\n",
    "perc_RL = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"RL\"}].shape[0] / singleLimb_df.shape[0]\n",
    "perc_T = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"T\"}].shape[0] / singleLimb_df.shape[0]\n",
    "\n",
    "perc_LW, perc_RW, perc_RL, perc_LL, perc_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import ConnectionPatch\n",
    "\n",
    "# do what above but with the sleep data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 9), gridspec_kw={'width_ratios': [2, 1]})\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "# pie chart parameters\n",
    "overall_ratios_sleep = df[\"Sleep\"].values\n",
    "labels_sleep = df.index.to_list()\n",
    "labels_sleep[4] = \"\\nUpper\\nBody\"\n",
    "\n",
    "explode = [0.1, 0, 0, 0, 0]\n",
    "# rotate so that first wedge is split by the x-axis\n",
    "angle = -180 * overall_ratios_sleep[0]\n",
    "wedges, *_ = ax1.pie(overall_ratios_sleep, autopct='%1.1f%%', startangle=angle,\n",
    "                     labels=labels_sleep, explode=explode, textprops = {\"fontsize\": 16})\n",
    "\n",
    "# bar chart parameters\n",
    "singleLimb_ratios = [perc_LW, perc_RW, perc_RL, perc_LL, perc_T]\n",
    "singleLimb_labels = [\"LW\", \"RW\", \"RA\", \"LA\", \"T\"]\n",
    "bottom = 1\n",
    "width = .2\n",
    "\n",
    "# Adding from the top matches the legend.\n",
    "for j, (height, label) in enumerate(reversed([*zip(singleLimb_ratios, singleLimb_labels)])):\n",
    "    bottom -= height\n",
    "    bc = ax2.bar(0, height, width, bottom=bottom, color='C0', label=label,\n",
    "                 alpha=0.1 + 0.20 * j)\n",
    "    ax2.bar_label(bc, labels=[f\"{height:.0%}\"], label_type='center', fontsize = 16)\n",
    "\n",
    "ax2.set_title('Focal movements', fontsize = 16)\n",
    "ax2.legend(frameon = True, fancybox = True, shadow = True, fontsize = 16)\n",
    "ax2.axis('off')\n",
    "ax2.set_xlim(- 2.5 * width, 2.5 * width)\n",
    "\n",
    "# use ConnectionPatch to draw lines between the two plots\n",
    "theta1, theta2 = wedges[0].theta1, wedges[0].theta2\n",
    "center, r = wedges[0].center, wedges[0].r\n",
    "bar_height = sum(singleLimb_ratios)\n",
    "\n",
    "# draw top connecting line\n",
    "x = r * np.cos(np.pi / 180 * theta2) + center[0]\n",
    "y = r * np.sin(np.pi / 180 * theta2) + center[1]\n",
    "con = ConnectionPatch(xyA=(-width / 2, bar_height), coordsA=ax2.transData,\n",
    "                      xyB=(x, y), coordsB=ax1.transData)\n",
    "con.set_color([0, 0, 0])\n",
    "con.set_linewidth(4)\n",
    "ax2.add_artist(con)\n",
    "\n",
    "# draw bottom connecting line\n",
    "x = r * np.cos(np.pi / 180 * theta1) + center[0]\n",
    "y = r * np.sin(np.pi / 180 * theta1) + center[1]\n",
    "con = ConnectionPatch(xyA=(-width / 2, 0), coordsA=ax2.transData,\n",
    "                        xyB=(x, y), coordsB=ax1.transData)\n",
    "con.set_color([0, 0, 0])\n",
    "ax2.add_artist(con)\n",
    "con.set_linewidth(4)\n",
    "\n",
    "plt.suptitle(\"Sleep\", fontsize = 21)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/movement_distribution_sleep.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same during wake\n",
    "singleLimb_df = bursts_df_wake[bursts_df_wake[\"Category\"] == \"Focal\"].reset_index(drop=True)\n",
    "perc_LW = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"LW\"}].shape[0] / singleLimb_df.shape[0]\n",
    "perc_RW = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"RW\"}].shape[0] / singleLimb_df.shape[0]\n",
    "perc_LL = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"LL\"}].shape[0] / singleLimb_df.shape[0]\n",
    "perc_RL = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"RL\"}].shape[0] / singleLimb_df.shape[0]\n",
    "perc_T = singleLimb_df[singleLimb_df[\"Limbs\"] == {\"T\"}].shape[0] / singleLimb_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do what above but with the wake data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 9), gridspec_kw={'width_ratios': [2, 1]})\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "# pie chart parameters\n",
    "overall_ratios_wake = df[\"Wake\"].values\n",
    "labels_wake = df.index.to_list()\n",
    "labels_wake[4] = \"\\n\\n\\nUpper\\nBody\"\n",
    "\n",
    "explode = [0.1, 0, 0, 0, 0]\n",
    "# rotate so that first wedge is split by the x-axis\n",
    "angle = -180 * overall_ratios_wake[0]\n",
    "wedges, *_ = ax1.pie(overall_ratios_wake, autopct='%1.1f%%', startangle=angle,\n",
    "                     labels=labels_wake, explode=explode, textprops = {\"fontsize\": 16})\n",
    "\n",
    "# bar chart parameters\n",
    "singleLimb_ratios = [perc_LW, perc_RW, perc_LL, perc_RL, perc_T]\n",
    "singleLimb_labels = [\"LW\", \"RW\", \"LA\", \"RA\", \"T\"]\n",
    "bottom = 1\n",
    "width = .2\n",
    "\n",
    "# Adding from the top matches the legend.\n",
    "for j, (height, label) in enumerate(reversed([*zip(singleLimb_ratios, singleLimb_labels)])):\n",
    "    bottom -= height\n",
    "    bc = ax2.bar(0, height, width, bottom=bottom, color='C0', label=label,\n",
    "                 alpha=0.1 + 0.20 * j)\n",
    "    ax2.bar_label(bc, labels=[f\"{height:.0%}\"], label_type='center', fontsize = 16)\n",
    "\n",
    "ax2.set_title('Focal movements', fontsize = 16)\n",
    "ax2.legend(frameon = True, fancybox = True, shadow = True, fontsize = 16)\n",
    "ax2.axis('off')\n",
    "ax2.set_xlim(- 2.5 * width, 2.5 * width)\n",
    "\n",
    "# use ConnectionPatch to draw lines between the two plots\n",
    "theta1, theta2 = wedges[0].theta1, wedges[0].theta2\n",
    "center, r = wedges[0].center, wedges[0].r\n",
    "bar_height = sum(singleLimb_ratios)\n",
    "\n",
    "# draw top connecting line\n",
    "x = r * np.cos(np.pi / 180 * theta2) + center[0]\n",
    "y = r * np.sin(np.pi / 180 * theta2) + center[1]\n",
    "con = ConnectionPatch(xyA=(-width / 2, bar_height), coordsA=ax2.transData,\n",
    "                      xyB=(x, y), coordsB=ax1.transData)\n",
    "con.set_color([0, 0, 0])\n",
    "con.set_linewidth(4)\n",
    "ax2.add_artist(con)\n",
    "\n",
    "# draw bottom connecting line\n",
    "x = r * np.cos(np.pi / 180 * theta1) + center[0]\n",
    "y = r * np.sin(np.pi / 180 * theta1) + center[1]\n",
    "con = ConnectionPatch(xyA=(-width / 2, 0), coordsA=ax2.transData,\n",
    "                        xyB=(x, y), coordsB=ax1.transData, linestyle = \"-\")\n",
    "con.set_color([0, 0, 0])\n",
    "ax2.add_artist(con)\n",
    "con.set_linewidth(4)\n",
    "\n",
    "plt.suptitle(\"Wake\", fontsize = 21)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/movement_distribution_wake.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st part vs 2nd of sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms2.out/\"\n",
    "part3_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms3.out/\"\n",
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\", \"127\", \"914\", \"965\"]\n",
    "\n",
    "SIB_GGIR = {sub: pyreadr.read_r(part3_outputFolder + \"LW_\" + sub + \".CWA.RData\")['sib.cla.sum'][[\"sib.onset.time\", \"sib.end.time\"]] for sub in subjects}\n",
    "\n",
    "tst = {sub: 0 for sub in subjects}\n",
    "tst_1st_half = {sub: 0 for sub in subjects}\n",
    "tst_2nd_half = {sub: 0 for sub in subjects}\n",
    "\n",
    "SIB = {sub: 0 for sub in subjects}\n",
    "\n",
    "bursts_df_1st_half = pd.DataFrame()\n",
    "bursts_df_2nd_half = pd.DataFrame()\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "    SIB_GGIR[sub][\"sib.onset.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.onset.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.end.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.end.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.duration\"] = SIB_GGIR[sub][\"sib.end.time\"] - SIB_GGIR[sub][\"sib.onset.time\"]\n",
    "\n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/bursts_FINAL_envInterp_p2p.pkl', 'rb') as f:\n",
    "        bursts = pickle.load(f)\n",
    "\n",
    "    df_merged_intervals = characterize_bursts(bursts)\n",
    "\n",
    "    start_sleep, end_sleep = diary_SPT[sub]\n",
    "    sleep_midpoint = start_sleep + (end_sleep - start_sleep) / 2\n",
    "\n",
    "    spt_start = diary_SPT[sub][0] - pd.Timedelta('10 min')\n",
    "    spt_end = diary_SPT[sub][1] + pd.Timedelta('5 min')\n",
    "\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "\n",
    "    # Take df_merged_intervals between spt_start and spt_end\n",
    "    df_merged_intervals = df_merged_intervals[(df_merged_intervals[\"Start\"] >= spt_start) & (df_merged_intervals[\"End\"] <= spt_end)].reset_index(drop=True) \n",
    "\n",
    "    SIB[sub][\"awake.duration\"] = SIB[sub][\"sib.onset.time\"].shift(-1) - SIB[sub][\"sib.end.time\"]\n",
    "    SIB[sub][\"sib.duration\"] = SIB[sub][\"sib.end.time\"] - SIB[sub][\"sib.onset.time\"]\n",
    "    SIB[sub][\"sub_ID\"] = sub\n",
    "\n",
    "    tst[sub] = (SIB[sub][\"sib.duration\"].sum()).total_seconds() / 3600\n",
    "    tst_1st_half[sub] = (SIB[sub].loc[SIB[sub][\"sib.onset.time\"] < sleep_midpoint, \"sib.duration\"].sum()).total_seconds() / 3600\n",
    "    tst_2nd_half[sub] = (SIB[sub].loc[SIB[sub][\"sib.onset.time\"] >= sleep_midpoint, \"sib.duration\"].sum()).total_seconds() / 3600\n",
    "\n",
    "    df_merged_intervals[\"SIB\"] = 0\n",
    "    for i, row in SIB[sub].iterrows():\n",
    "        df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= row[\"sib.onset.time\"] + pd.Timedelta(\"5s\")) & (df_merged_intervals[\"End\"] <= row[\"sib.end.time\"] - pd.Timedelta(\"5s\")), \"SIB\"] = 1\n",
    "\n",
    "    df_merged_intervals[\"sub_ID\"] = sub\n",
    "\n",
    "    start_sleep = diary_SPT[sub][0]\n",
    "    end_sleep = diary_SPT[sub][1]\n",
    "\n",
    "    df_merged_intervals = df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= start_sleep) & (df_merged_intervals[\"End\"] <= end_sleep)]\n",
    "\n",
    "    df_merged_intervals_1st_half = df_merged_intervals.loc[df_merged_intervals[\"Start\"] < sleep_midpoint].reset_index(drop=True)\n",
    "    df_merged_intervals_2nd_half = df_merged_intervals.loc[df_merged_intervals[\"Start\"] >= sleep_midpoint].reset_index(drop=True)\n",
    "\n",
    "    bursts_df_1st_half = pd.concat([bursts_df_1st_half, df_merged_intervals_1st_half])\n",
    "    bursts_df_2nd_half = pd.concat([bursts_df_2nd_half, df_merged_intervals_2nd_half])\n",
    "\n",
    "tst_df = pd.DataFrame(tst, index = [\"TST\"]).T.sort_index()\n",
    "tst_1st_half_df = pd.DataFrame(tst_1st_half, index = [\"TST_1st_half\"]).T.sort_index()\n",
    "tst_2nd_half_df = pd.DataFrame(tst_2nd_half, index = [\"TST_2nd_half\"]).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1005, 1461)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_df_1st_half.shape[0], bursts_df_2nd_half.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(705, 993)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_df_sleep1 = bursts_df_1st_half[bursts_df_1st_half[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_df_sleep1[\"Duration\"] = bursts_df_sleep1[\"End\"] - bursts_df_sleep1[\"Start\"]\n",
    "bursts_df_sleep1[\"Duration\"] = bursts_df_sleep1[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_df_sleep1[\"n_limbs\"] = bursts_df_sleep1[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_df_sleep1[\"Category\"] = \"placeholder\"\n",
    "bursts_df_sleep1.loc[bursts_df_sleep1[\"n_limbs\"] == 5, \"Category\"] = \"Full Body\"\n",
    "bursts_df_sleep1.loc[(bursts_df_sleep1[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_sleep1[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_sleep1[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_sleep1[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}), \"Category\"] = \"Lower Body\"\n",
    "bursts_df_sleep1.loc[(bursts_df_sleep1[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_df_sleep1[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_sleep1[\"Limbs\"] == {\"RW\", \"T\"}) | (bursts_df_sleep1[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}), \"Category\"] = \"Upper Body\"\n",
    "bursts_df_sleep1.loc[(bursts_df_sleep1[\"n_limbs\"] >= 2) & (bursts_df_sleep1[\"n_limbs\"] != 5) & (bursts_df_sleep1[\"Limbs\"] != {\"LL\", \"RL\"}) & (bursts_df_sleep1[\"Limbs\"] != {\"LL\", \"RL\", \"T\"}) & (bursts_df_sleep1[\"Limbs\"] != {\"LW\", \"RW\"}) & (bursts_df_sleep1[\"Limbs\"] != {\"LW\", \"RW\", \"T\"}) & (bursts_df_sleep1[\"Limbs\"] != {\"LL\", \"T\"}) & (bursts_df_sleep1[\"Limbs\"] != {\"RL\", \"T\"}) & (bursts_df_sleep1[\"Limbs\"] != {\"LW\", \"T\"}) & (bursts_df_sleep1[\"Limbs\"] != {\"RW\", \"T\"}), \"Category\"] = \"Mixed\"\n",
    "bursts_df_sleep1.loc[bursts_df_sleep1[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "\n",
    "\n",
    "bursts_df_sleep2 = bursts_df_2nd_half[bursts_df_2nd_half[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_df_sleep2[\"Duration\"] = bursts_df_sleep2[\"End\"] - bursts_df_sleep2[\"Start\"]\n",
    "bursts_df_sleep2[\"Duration\"] = bursts_df_sleep2[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_df_sleep2[\"n_limbs\"] = bursts_df_sleep2[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_df_sleep2[\"Category\"] = \"placeholder\"\n",
    "bursts_df_sleep2.loc[bursts_df_sleep2[\"n_limbs\"] == 5, \"Category\"] = \"Full Body\"\n",
    "bursts_df_sleep2.loc[(bursts_df_sleep2[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_sleep2[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_sleep2[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_sleep2[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}), \"Category\"] = \"Lower Body\"\n",
    "bursts_df_sleep2.loc[(bursts_df_sleep2[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_df_sleep2[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_sleep2[\"Limbs\"] == {\"RW\", \"T\"}) | (bursts_df_sleep2[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}), \"Category\"] = \"Upper Body\"\n",
    "bursts_df_sleep2.loc[(bursts_df_sleep2[\"n_limbs\"] >= 2) & (bursts_df_sleep2[\"n_limbs\"] != 5) & (bursts_df_sleep2[\"Limbs\"] != {\"LL\", \"RL\"}) & (bursts_df_sleep2[\"Limbs\"] != {\"LL\", \"RL\", \"T\"}) & (bursts_df_sleep2[\"Limbs\"] != {\"LW\", \"RW\"}) & (bursts_df_sleep2[\"Limbs\"] != {\"LW\", \"RW\", \"T\"}) & (bursts_df_sleep2[\"Limbs\"] != {\"LL\", \"T\"}) & (bursts_df_sleep2[\"Limbs\"] != {\"RL\", \"T\"}) & (bursts_df_sleep2[\"Limbs\"] != {\"LW\", \"T\"}) & (bursts_df_sleep2[\"Limbs\"] != {\"RW\", \"T\"}), \"Category\"] = \"Mixed\"\n",
    "bursts_df_sleep2.loc[bursts_df_sleep2[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "\n",
    "bursts_df_sleep1.shape[0], bursts_df_sleep2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movement index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_1 = bursts_df_sleep1.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].count() #/ (tst_1st_half_df[\"TST_1st_half\"])\n",
    "freq_2 = bursts_df_sleep2.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].count() #/ (tst_2nd_half_df[\"TST_2nd_half\"])\n",
    "freq_1 = freq_1.unstack().T.div(tst_1st_half_df[\"TST_1st_half\"], axis = 0).T\n",
    "freq_2 = freq_2.unstack().T.div(tst_2nd_half_df[\"TST_2nd_half\"], axis = 0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>sub_ID</th>\n",
       "      <th>098</th>\n",
       "      <th>127</th>\n",
       "      <th>158</th>\n",
       "      <th>279</th>\n",
       "      <th>547</th>\n",
       "      <th>633</th>\n",
       "      <th>815</th>\n",
       "      <th>906</th>\n",
       "      <th>914</th>\n",
       "      <th>958</th>\n",
       "      <th>...</th>\n",
       "      <th>158</th>\n",
       "      <th>279</th>\n",
       "      <th>547</th>\n",
       "      <th>633</th>\n",
       "      <th>815</th>\n",
       "      <th>906</th>\n",
       "      <th>914</th>\n",
       "      <th>958</th>\n",
       "      <th>965</th>\n",
       "      <th>971</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Focal</th>\n",
       "      <td>4.587706</td>\n",
       "      <td>12.841855</td>\n",
       "      <td>7.622951</td>\n",
       "      <td>6.283784</td>\n",
       "      <td>5.650558</td>\n",
       "      <td>0.941997</td>\n",
       "      <td>7.783784</td>\n",
       "      <td>9.485030</td>\n",
       "      <td>5.855563</td>\n",
       "      <td>6.567845</td>\n",
       "      <td>...</td>\n",
       "      <td>8.888889</td>\n",
       "      <td>3.661793</td>\n",
       "      <td>20.991254</td>\n",
       "      <td>2.336145</td>\n",
       "      <td>12.031332</td>\n",
       "      <td>10.933452</td>\n",
       "      <td>6.133460</td>\n",
       "      <td>11.368421</td>\n",
       "      <td>21.847390</td>\n",
       "      <td>13.823038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full Body</th>\n",
       "      <td>1.889055</td>\n",
       "      <td>3.995244</td>\n",
       "      <td>3.934426</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>2.081784</td>\n",
       "      <td>7.849978</td>\n",
       "      <td>10.378378</td>\n",
       "      <td>3.449102</td>\n",
       "      <td>2.576448</td>\n",
       "      <td>4.652223</td>\n",
       "      <td>...</td>\n",
       "      <td>4.301075</td>\n",
       "      <td>6.408137</td>\n",
       "      <td>6.997085</td>\n",
       "      <td>9.811811</td>\n",
       "      <td>15.415144</td>\n",
       "      <td>13.506029</td>\n",
       "      <td>5.792712</td>\n",
       "      <td>2.066986</td>\n",
       "      <td>2.891566</td>\n",
       "      <td>7.212020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lower Body</th>\n",
       "      <td>3.778111</td>\n",
       "      <td>0.285375</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>1.013514</td>\n",
       "      <td>3.568773</td>\n",
       "      <td>2.197994</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>0.862275</td>\n",
       "      <td>1.405335</td>\n",
       "      <td>0.820981</td>\n",
       "      <td>...</td>\n",
       "      <td>2.580645</td>\n",
       "      <td>4.577241</td>\n",
       "      <td>2.448980</td>\n",
       "      <td>6.541207</td>\n",
       "      <td>1.127937</td>\n",
       "      <td>3.537293</td>\n",
       "      <td>9.881685</td>\n",
       "      <td>1.377990</td>\n",
       "      <td>5.783133</td>\n",
       "      <td>6.310518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixed</th>\n",
       "      <td>2.428786</td>\n",
       "      <td>4.565993</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.608108</td>\n",
       "      <td>1.189591</td>\n",
       "      <td>3.139991</td>\n",
       "      <td>2.270270</td>\n",
       "      <td>2.299401</td>\n",
       "      <td>1.171113</td>\n",
       "      <td>4.378563</td>\n",
       "      <td>...</td>\n",
       "      <td>1.146953</td>\n",
       "      <td>0.457724</td>\n",
       "      <td>4.198251</td>\n",
       "      <td>5.606749</td>\n",
       "      <td>2.631854</td>\n",
       "      <td>4.502010</td>\n",
       "      <td>1.362991</td>\n",
       "      <td>3.100478</td>\n",
       "      <td>5.140562</td>\n",
       "      <td>3.305509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upper Body</th>\n",
       "      <td>1.619190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.983607</td>\n",
       "      <td>0.202703</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.627998</td>\n",
       "      <td>1.621622</td>\n",
       "      <td>2.874251</td>\n",
       "      <td>0.468445</td>\n",
       "      <td>2.189282</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573477</td>\n",
       "      <td>0.915448</td>\n",
       "      <td>1.049563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.503916</td>\n",
       "      <td>1.607861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.033493</td>\n",
       "      <td>0.321285</td>\n",
       "      <td>0.300501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "sub_ID           098        127       158       279       547       633  \\\n",
       "Category                                                                  \n",
       "Focal       4.587706  12.841855  7.622951  6.283784  5.650558  0.941997   \n",
       "Full Body   1.889055   3.995244  3.934426  1.621622  2.081784  7.849978   \n",
       "Lower Body  3.778111   0.285375  0.983607  1.013514  3.568773  2.197994   \n",
       "Mixed       2.428786   4.565993  0.245902  0.608108  1.189591  3.139991   \n",
       "Upper Body  1.619190        NaN  0.983607  0.202703  0.892193  0.627998   \n",
       "\n",
       "sub_ID            815       906       914       958  ...       158       279  \\\n",
       "Category                                             ...                       \n",
       "Focal        7.783784  9.485030  5.855563  6.567845  ...  8.888889  3.661793   \n",
       "Full Body   10.378378  3.449102  2.576448  4.652223  ...  4.301075  6.408137   \n",
       "Lower Body   0.972973  0.862275  1.405335  0.820981  ...  2.580645  4.577241   \n",
       "Mixed        2.270270  2.299401  1.171113  4.378563  ...  1.146953  0.457724   \n",
       "Upper Body   1.621622  2.874251  0.468445  2.189282  ...  0.573477  0.915448   \n",
       "\n",
       "sub_ID            547       633        815        906       914        958  \\\n",
       "Category                                                                     \n",
       "Focal       20.991254  2.336145  12.031332  10.933452  6.133460  11.368421   \n",
       "Full Body    6.997085  9.811811  15.415144  13.506029  5.792712   2.066986   \n",
       "Lower Body   2.448980  6.541207   1.127937   3.537293  9.881685   1.377990   \n",
       "Mixed        4.198251  5.606749   2.631854   4.502010  1.362991   3.100478   \n",
       "Upper Body   1.049563       NaN   1.503916   1.607861       NaN   1.033493   \n",
       "\n",
       "sub_ID            965        971  \n",
       "Category                          \n",
       "Focal       21.847390  13.823038  \n",
       "Full Body    2.891566   7.212020  \n",
       "Lower Body   5.783133   6.310518  \n",
       "Mixed        5.140562   3.305509  \n",
       "Upper Body   0.321285   0.300501  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.concat([freq_1, freq_2], axis = 1)\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration or AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_1 = bursts_df_sleep1.groupby([\"Category\", \"sub_ID\"])[\"AUC\"].mean()\n",
    "freq_2 = bursts_df_sleep2.groupby([\"Category\", \"sub_ID\"])[\"AUC\"].mean()\n",
    "freq_1 = freq_1.unstack()/1000\n",
    "freq_2 = freq_2.unstack()/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge and boxplot each movement 1st vs 2nd half\n",
    "freq = pd.concat([freq_1, freq_2], axis = 1).T\n",
    "# freq.columns = [\"1st_half\", \"2nd_half\"]\n",
    "freq[\"part\"] = \"1st half\"\n",
    "freq.reset_index(drop=True, inplace = True)\n",
    "freq.loc[12:, \"part\"] = \"2nd half\"\n",
    "freq[\"sub_ID\"] = sorted(subjects) + sorted(subjects)\n",
    "\n",
    "# freq = freq.unstack().T\n",
    "# freq[\"part\"] = freq.index.get_level_values(0)\n",
    "# freq[\"sub_ID\"] = freq.index.get_level_values(1)\n",
    "# freq.reset_index(drop = True, inplace = True)\n",
    "\n",
    "freq = freq.melt(id_vars = [\"part\", \"sub_ID\"], value_vars = [ \"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"], var_name = \"Category\", value_name = \"Frequency\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 9))\n",
    "sns.boxplot(x = \"Category\", y = \"Frequency\", hue = \"part\", data = freq, showfliers = False, ax = ax)\n",
    "sns.stripplot(x = \"Category\", y = \"Frequency\", hue = \"part\", data = freq, dodge = True, jitter = True, palette = \"dark:black\", alpha = 0.52, s = 7, ax = ax, legend = False)\n",
    "ax.set_xlabel(\"Category\", fontsize = 19)\n",
    "ax.set_ylabel(\"Movement AUC (gs)\", fontsize = 19)\n",
    "ax.legend(fontsize = 19, frameon = True, fancybox = True, shadow = True, loc = \"center\")\n",
    "ax.set_xlabel(\"\")\n",
    "plt.xticks(rotation = 18, fontsize = 16)\n",
    "plt.yticks(fontsize = 16);\n",
    "# plt.ylim(0, freq[\"Frequency\"].max() + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/movement_AUC_1st_vs_2nd_half.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Body\n",
      "WilcoxonResult(statistic=35.0, pvalue=0.791015625)\n",
      "Lower Body\n",
      "WilcoxonResult(statistic=11.0, pvalue=0.02685546875)\n",
      "Upper Body\n",
      "WilcoxonResult(statistic=16.0, pvalue=0.49609375)\n",
      "Mixed\n",
      "WilcoxonResult(statistic=23.0, pvalue=0.2333984375)\n",
      "Focal\n",
      "WilcoxonResult(statistic=25.0, pvalue=0.30126953125)\n"
     ]
    }
   ],
   "source": [
    "# Wilcoxon signed-rank test for each category: 1st vs 2nd half\n",
    "from scipy.stats import wilcoxon\n",
    "p_values = {}\n",
    "for cat in [\"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\", \"Focal\"]:\n",
    "    print(cat), print(wilcoxon(freq_1.loc[cat], freq_2.loc[cat], nan_policy = 'omit'))\n",
    "    p_values[cat] = wilcoxon(freq_1.loc[cat], freq_2.loc[cat], nan_policy = 'omit')[1]\n",
    "\n",
    "# Draw p-values on top of the boxplot\n",
    "y_max = freq[\"Frequency\"].max()\n",
    "y_min = freq[\"Frequency\"].min()\n",
    "y_range = y_max - y_min\n",
    "y_max = y_max + 0.1 * y_range\n",
    "y_min = y_min - 0.1 * y_range\n",
    "y_range = y_max - y_min\n",
    "y_pos = y_max - 0.2 * y_range\n",
    "\n",
    "for i, cat in enumerate([\"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"]):\n",
    "    ax.text(i, y_pos, f\"p = {p_values[cat]:.3f}\", color = \"black\", fontsize = 16, ha = \"center\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table OP final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms2.out/\"\n",
    "part3_outputFolder = \"/Volumes/Untitled/rehab/GGIR/GGIR_output_lw_TIB/output_lw_data/meta/ms3.out/\"\n",
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\", \"127\", \"914\", \"965\"]\n",
    "\n",
    "SIB_GGIR = {sub: pyreadr.read_r(part3_outputFolder + \"LW_\" + sub + \".CWA.RData\")['sib.cla.sum'][[\"sib.onset.time\", \"sib.end.time\"]] for sub in subjects}\n",
    "\n",
    "tst = {sub: 0 for sub in subjects}\n",
    "twt = {sub: 0 for sub in subjects}\n",
    "\n",
    "SIB = {sub: 0 for sub in subjects}\n",
    "\n",
    "bursts_df = pd.DataFrame()\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "    SIB_GGIR[sub][\"sib.onset.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.onset.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.end.time\"] = pd.to_datetime(SIB_GGIR[sub][\"sib.end.time\"].values).tz_localize(None)\n",
    "    SIB_GGIR[sub][\"sib.duration\"] = SIB_GGIR[sub][\"sib.end.time\"] - SIB_GGIR[sub][\"sib.onset.time\"]\n",
    "\n",
    "    with open(f'/Volumes/Untitled/rehab/data/{sub}/bursts_FINAL_envInterp_p2p.pkl', 'rb') as f:\n",
    "        bursts = pickle.load(f)\n",
    "\n",
    "    df_merged_intervals = characterize_bursts(bursts)\n",
    "    spt_start = diary_SPT[sub][0] - pd.Timedelta('10 min')\n",
    "    spt_end = diary_SPT[sub][1] + pd.Timedelta('5 min')\n",
    "\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "    SIB[sub] = SIB_GGIR[sub][(SIB_GGIR[sub][\"sib.onset.time\"] >= spt_start) & (SIB_GGIR[sub][\"sib.end.time\"] <= spt_end)].reset_index(drop=True)\n",
    "\n",
    "    # Take df_merged_intervals between spt_start and spt_end\n",
    "    df_merged_intervals = df_merged_intervals[(df_merged_intervals[\"Start\"] >= spt_start) & (df_merged_intervals[\"End\"] <= spt_end)].reset_index(drop=True) \n",
    "\n",
    "    SIB[sub][\"awake.duration\"] = SIB[sub][\"sib.onset.time\"].shift(-1) - SIB[sub][\"sib.end.time\"]\n",
    "    SIB[sub][\"sib.duration\"] = SIB[sub][\"sib.end.time\"] - SIB[sub][\"sib.onset.time\"]\n",
    "    SIB[sub][\"sub_ID\"] = sub\n",
    "\n",
    "    tst[sub] = (SIB[sub][\"sib.duration\"].sum()).total_seconds() / 3600\n",
    "    twt[sub] = (SIB[sub][\"awake.duration\"].sum()).total_seconds() / 3600\n",
    "\n",
    "    df_merged_intervals[\"SIB\"] = 0\n",
    "    for i, row in SIB[sub].iterrows():\n",
    "        df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= row[\"sib.onset.time\"] + pd.Timedelta(\"5s\")) & (df_merged_intervals[\"End\"] <= row[\"sib.end.time\"] - pd.Timedelta(\"5s\")), \"SIB\"] = 1\n",
    "\n",
    "    df_merged_intervals[\"sub_ID\"] = sub\n",
    "\n",
    "    start_sleep = diary_SPT[sub][0]\n",
    "    end_sleep = diary_SPT[sub][1]\n",
    "\n",
    "    df_merged_intervals = df_merged_intervals.loc[(df_merged_intervals[\"Start\"] >= start_sleep) & (df_merged_intervals[\"End\"] <= end_sleep)]\n",
    "\n",
    "    bursts_df = pd.concat([bursts_df, df_merged_intervals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_df_sleep = bursts_df[bursts_df[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_df_sleep[\"Duration\"] = bursts_df_sleep[\"End\"] - bursts_df_sleep[\"Start\"]\n",
    "bursts_df_sleep[\"Duration\"] = bursts_df_sleep[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_df_sleep[\"n_limbs\"] = bursts_df_sleep[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_df_sleep[\"Category\"] = \"placeholder\"\n",
    "bursts_df_sleep[\"Laterality\"] = \"Bilateral\"\n",
    "bursts_df_sleep.loc[bursts_df_sleep[\"n_limbs\"] == 5, \"Category\"] = \"Full Body\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}), \"Category\"] = \"Lower Body\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RW\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}), \"Category\"] = \"Upper Body\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"n_limbs\"] >= 2) & (bursts_df_sleep[\"n_limbs\"] != 5) & (bursts_df_sleep[\"Limbs\"] != {\"LL\", \"RL\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LL\", \"RL\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LW\", \"RW\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LW\", \"RW\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LL\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"RL\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"LW\", \"T\"}) & (bursts_df_sleep[\"Limbs\"] != {\"RW\", \"T\"}), \"Category\"] = \"Mixed\"\n",
    "bursts_df_sleep.loc[bursts_df_sleep[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LL\", \"LW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\", \"RW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LL\", \"LW\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\", \"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_sleep.loc[(bursts_df_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RW\"}) | (bursts_df_sleep[\"Limbs\"] == {\"LL\"}) | (bursts_df_sleep[\"Limbs\"] == {\"RL\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_sleep.loc[bursts_df_sleep[\"Limbs\"] == {\"T\"}, \"Laterality\"] = \"None\"\n",
    "\n",
    "bursts_df_wake = bursts_df[bursts_df[\"SIB\"] == 0].reset_index(drop=True)\n",
    "bursts_df_wake[\"Duration\"] = bursts_df_wake[\"End\"] - bursts_df_wake[\"Start\"]\n",
    "bursts_df_wake[\"Duration\"] = bursts_df_wake[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_df_wake[\"n_limbs\"] = bursts_df_wake[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_df_wake[\"Category\"] = \"placeholder\"\n",
    "bursts_df_wake[\"Laterality\"] = \"Bilateral\"\n",
    "bursts_df_wake.loc[bursts_df_wake[\"n_limbs\"] == 5, \"Category\"] = \"Full Body\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_wake[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}), \"Category\"] = \"Lower Body\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_df_wake[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RW\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}), \"Category\"] = \"Upper Body\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"n_limbs\"] >= 2) & (bursts_df_wake[\"n_limbs\"] != 5) & (bursts_df_wake[\"Limbs\"] != {\"LL\", \"RL\"}) & (bursts_df_wake[\"Limbs\"] != {\"LL\", \"RL\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"LW\", \"RW\"}) & (bursts_df_wake[\"Limbs\"] != {\"LW\", \"RW\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"LL\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"RL\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"LW\", \"T\"}) & (bursts_df_wake[\"Limbs\"] != {\"RW\", \"T\"}), \"Category\"] = \"Mixed\"\n",
    "bursts_df_wake.loc[bursts_df_wake[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LL\", \"LW\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\", \"RW\"}) | (bursts_df_wake[\"Limbs\"] == {\"LL\", \"LW\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\", \"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_df_wake[\"Limbs\"] == {\"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_wake.loc[(bursts_df_wake[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_df_wake[\"Limbs\"] == {\"LW\"}) | (bursts_df_wake[\"Limbs\"] == {\"RW\"}) | (bursts_df_wake[\"Limbs\"] == {\"LL\"}) | (bursts_df_wake[\"Limbs\"] == {\"RL\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_df_wake.loc[bursts_df_wake[\"Limbs\"] == {\"T\"}, \"Laterality\"] = \"None\"\n",
    "\n",
    "tst_df = pd.DataFrame(tst, index = [\"TST\"]).T.sort_index()\n",
    "twt_df = pd.DataFrame(twt, index = [\"TWT\"]).T.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>AUC</th>\n",
       "      <th>p2p</th>\n",
       "      <th>PC</th>\n",
       "      <th>transition</th>\n",
       "      <th>Limbs</th>\n",
       "      <th>SIB</th>\n",
       "      <th>sub_ID</th>\n",
       "      <th>Duration</th>\n",
       "      <th>n_limbs</th>\n",
       "      <th>Category</th>\n",
       "      <th>Laterality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-28 23:00:01.360290051</td>\n",
       "      <td>2024-02-28 23:00:02.460289955</td>\n",
       "      <td>4478.029974</td>\n",
       "      <td>59.446242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{RL, LL, T}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>1.099999</td>\n",
       "      <td>3</td>\n",
       "      <td>Lower Body</td>\n",
       "      <td>Bilateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-28 23:00:30.130290031</td>\n",
       "      <td>2024-02-28 23:00:32.030289888</td>\n",
       "      <td>5565.732278</td>\n",
       "      <td>48.247713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{LL}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>1.899999</td>\n",
       "      <td>1</td>\n",
       "      <td>Focal</td>\n",
       "      <td>Unilateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-28 23:00:43.494869947</td>\n",
       "      <td>2024-02-28 23:00:43.874870062</td>\n",
       "      <td>593.812924</td>\n",
       "      <td>16.318746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{T}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>1</td>\n",
       "      <td>Focal</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-28 23:02:28.765630007</td>\n",
       "      <td>2024-02-28 23:02:31.105629921</td>\n",
       "      <td>6965.555964</td>\n",
       "      <td>44.916305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{LW, T}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>2.339999</td>\n",
       "      <td>2</td>\n",
       "      <td>Upper Body</td>\n",
       "      <td>Unilateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-28 23:03:30.215630054</td>\n",
       "      <td>2024-02-28 23:03:32.105629921</td>\n",
       "      <td>6534.732075</td>\n",
       "      <td>50.164798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>{LW, T}</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>1.889999</td>\n",
       "      <td>2</td>\n",
       "      <td>Upper Body</td>\n",
       "      <td>Unilateral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Start                           End          AUC  \\\n",
       "0 2024-02-28 23:00:01.360290051 2024-02-28 23:00:02.460289955  4478.029974   \n",
       "1 2024-02-28 23:00:30.130290031 2024-02-28 23:00:32.030289888  5565.732278   \n",
       "2 2024-02-28 23:00:43.494869947 2024-02-28 23:00:43.874870062   593.812924   \n",
       "3 2024-02-28 23:02:28.765630007 2024-02-28 23:02:31.105629921  6965.555964   \n",
       "4 2024-02-28 23:03:30.215630054 2024-02-28 23:03:32.105629921  6534.732075   \n",
       "\n",
       "         p2p   PC transition        Limbs  SIB sub_ID  Duration  n_limbs  \\\n",
       "0  59.446242  0.0       None  {RL, LL, T}    1    158  1.099999        3   \n",
       "1  48.247713  0.0       None         {LL}    1    158  1.899999        1   \n",
       "2  16.318746  0.0       None          {T}    1    158  0.380000        1   \n",
       "3  44.916305  0.0       None      {LW, T}    1    158  2.339999        2   \n",
       "4  50.164798  0.0       None      {LW, T}    1    158  1.889999        2   \n",
       "\n",
       "     Category  Laterality  \n",
       "0  Lower Body   Bilateral  \n",
       "1       Focal  Unilateral  \n",
       "2       Focal        None  \n",
       "3  Upper Body  Unilateral  \n",
       "4  Upper Body  Unilateral  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bursts_df_sleep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a df where, for each movement, there is the median (25th percentile - 75th percentile): for example for Full Body: 0.5 (0.3 - 0.7)\n",
    "df_index = bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].describe()[\"count\"].unstack().T.div(tst_df[\"TST\"], axis = 0).describe()\n",
    "df_index_sleep = pd.DataFrame([\"a\", \"a\", \"a\", \"a\", \"a\"]).T\n",
    "df_index_sleep.columns = [\"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"]\n",
    "for movement in df_index_sleep.columns:\n",
    "    med = df_index.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_index.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_index.loc[\"75%\", movement].round(1)\n",
    "    df_index_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_index_sleep = df_index_sleep.T\n",
    "df_index_sleep.columns = [\"Index (n/h)\"]\n",
    "\n",
    "df_duration = bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].describe()[\"mean\"].unstack().T.describe()\n",
    "df_duration_sleep = pd.DataFrame([\"a\", \"a\", \"a\", \"a\", \"a\"]).T\n",
    "df_duration_sleep.columns = [\"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"]\n",
    "for movement in df_duration_sleep.columns:\n",
    "    med = df_duration.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_duration.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_duration.loc[\"75%\", movement].round(1)\n",
    "    df_duration_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_duration_sleep = df_duration_sleep.T\n",
    "df_duration_sleep.columns = [\"Duration (s)\"]\n",
    "\n",
    "df_p2p = (bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"p2p\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_p2p_sleep = pd.DataFrame([\"a\", \"a\", \"a\", \"a\", \"a\"]).T\n",
    "df_p2p_sleep.columns = [\"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"]\n",
    "for movement in df_p2p_sleep.columns:\n",
    "    med = df_p2p.loc[\"50%\", movement].round(2)\n",
    "    perc25 = df_p2p.loc[\"25%\", movement].round(2)\n",
    "    perc75 = df_p2p.loc[\"75%\", movement].round(2)\n",
    "    df_p2p_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_p2p_sleep = df_p2p_sleep.T\n",
    "df_p2p_sleep.columns = [\"p2p (g)\"]\n",
    "\n",
    "df_AUC = (bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"AUC\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_AUC_sleep = pd.DataFrame([\"a\", \"a\", \"a\", \"a\", \"a\"]).T\n",
    "df_AUC_sleep.columns = [\"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"]\n",
    "for movement in df_AUC_sleep.columns:\n",
    "    med = df_AUC.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_AUC.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_AUC.loc[\"75%\", movement].round(1)\n",
    "    df_AUC_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_AUC_sleep = df_AUC_sleep.T\n",
    "df_AUC_sleep.columns = [\"AUC (gs)\"]\n",
    "\n",
    "table_movements_sleep = pd.concat([df_index_sleep, df_duration_sleep, df_p2p_sleep, df_AUC_sleep], axis = 1)\n",
    "\n",
    "df_index_laterality = bursts_df_sleep.groupby([\"Laterality\", \"sub_ID\"])[\"Duration\"].describe()[\"count\"].unstack().T.div(tst_df[\"TST\"], axis = 0).describe()\n",
    "df_index_laterality_sleep = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_index_laterality_sleep.columns = [\"Unilateral\", \"Bilateral\"]\n",
    "for movement in df_index_laterality_sleep.columns:\n",
    "    med = df_index_laterality.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_index_laterality.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_index_laterality.loc[\"75%\", movement].round(1)\n",
    "    df_index_laterality_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_index_laterality_sleep = df_index_laterality_sleep.T\n",
    "df_index_laterality_sleep.columns = [\"Index (n/h)\"]\n",
    "df_index_laterality_sleep\n",
    "\n",
    "df_duration_laterality = bursts_df_sleep.groupby([\"Laterality\", \"sub_ID\"])[\"Duration\"].describe()[\"mean\"].unstack().T.describe()\n",
    "df_duration_laterality_sleep = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_duration_laterality_sleep.columns = [\"Unilateral\", \"Bilateral\"]\n",
    "for movement in df_duration_laterality_sleep.columns:\n",
    "    med = df_duration_laterality.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_duration_laterality.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_duration_laterality.loc[\"75%\", movement].round(1)\n",
    "    df_duration_laterality_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_duration_laterality_sleep = df_duration_laterality_sleep.T\n",
    "df_duration_laterality_sleep.columns = [\"Duration (s)\"]\n",
    "df_duration_laterality_sleep\n",
    "\n",
    "df_p2p_laterality = (bursts_df_sleep.groupby([\"Laterality\", \"sub_ID\"])[\"p2p\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_p2p_laterality_sleep = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_p2p_laterality_sleep.columns = [\"Unilateral\", \"Bilateral\"]\n",
    "for movement in df_p2p_laterality_sleep.columns:\n",
    "    med = df_p2p_laterality.loc[\"50%\", movement].round(2)\n",
    "    perc25 = df_p2p_laterality.loc[\"25%\", movement].round(2)\n",
    "    perc75 = df_p2p_laterality.loc[\"75%\", movement].round(2)\n",
    "    df_p2p_laterality_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_p2p_laterality_sleep = df_p2p_laterality_sleep.T\n",
    "df_p2p_laterality_sleep.columns = [\"p2p (g)\"]\n",
    "df_p2p_laterality_sleep\n",
    "\n",
    "df_AUC_laterality = (bursts_df_sleep.groupby([\"Laterality\", \"sub_ID\"])[\"AUC\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_AUC_laterality_sleep = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_AUC_laterality_sleep.columns = [\"Unilateral\", \"Bilateral\"]\n",
    "for movement in df_AUC_laterality_sleep.columns:\n",
    "    med = df_AUC_laterality.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_AUC_laterality.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_AUC_laterality.loc[\"75%\", movement].round(1)\n",
    "    df_AUC_laterality_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_AUC_laterality_sleep = df_AUC_laterality_sleep.T\n",
    "df_AUC_laterality_sleep.columns = [\"AUC (gs)\"]\n",
    "df_AUC_laterality_sleep\n",
    "\n",
    "table_laterality_sleep = pd.concat([df_index_laterality_sleep, df_duration_laterality_sleep, df_p2p_laterality_sleep, df_AUC_laterality_sleep], axis = 1)\n",
    "\n",
    "table_sleep = pd.concat([table_movements_sleep, table_laterality_sleep], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above but for wake\n",
    "df_index = bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].describe()[\"count\"].unstack().T.div(twt_df[\"TWT\"], axis = 0).describe()\n",
    "df_index_wake = pd.DataFrame([\"a\", \"a\", \"a\", \"a\", \"a\"]).T\n",
    "df_index_wake.columns = [\"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"]\n",
    "for movement in df_index_wake.columns:\n",
    "    med = df_index.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_index.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_index.loc[\"75%\", movement].round(1)\n",
    "    df_index_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_index_wake = df_index_wake.T\n",
    "df_index_wake.columns = [\"Index (n/h)\"]\n",
    "\n",
    "df_duration = bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].describe()[\"mean\"].unstack().T.describe()\n",
    "df_duration_wake = pd.DataFrame([\"a\", \"a\", \"a\", \"a\", \"a\"]).T\n",
    "df_duration_wake.columns = [\"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"]\n",
    "for movement in df_duration_wake.columns:\n",
    "    med = df_duration.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_duration.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_duration.loc[\"75%\", movement].round(1)\n",
    "    df_duration_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_duration_wake = df_duration_wake.T\n",
    "df_duration_wake.columns = [\"Duration (s)\"]\n",
    "\n",
    "df_p2p = (bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"p2p\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_p2p_wake = pd.DataFrame([\"a\", \"a\", \"a\", \"a\", \"a\"]).T\n",
    "df_p2p_wake.columns = [\"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"]\n",
    "for movement in df_p2p_wake.columns:\n",
    "    med = df_p2p.loc[\"50%\", movement].round(2)\n",
    "    perc25 = df_p2p.loc[\"25%\", movement].round(2)\n",
    "    perc75 = df_p2p.loc[\"75%\", movement].round(2)\n",
    "    df_p2p_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_p2p_wake = df_p2p_wake.T\n",
    "df_p2p_wake.columns = [\"p2p (g)\"]\n",
    "\n",
    "df_AUC = (bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"AUC\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_AUC_wake = pd.DataFrame([\"a\", \"a\", \"a\", \"a\", \"a\"]).T\n",
    "df_AUC_wake.columns = [\"Focal\", \"Full Body\", \"Lower Body\", \"Upper Body\", \"Mixed\"]\n",
    "for movement in df_AUC_wake.columns:\n",
    "    med = df_AUC.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_AUC.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_AUC.loc[\"75%\", movement].round(1)\n",
    "    df_AUC_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_AUC_wake = df_AUC_wake.T\n",
    "df_AUC_wake.columns = [\"AUC (gs)\"]\n",
    "\n",
    "table_movements_wake = pd.concat([df_index_wake, df_duration_wake, df_p2p_wake, df_AUC_wake], axis = 1)\n",
    "\n",
    "df_index_laterality = bursts_df_wake.groupby([\"Laterality\", \"sub_ID\"])[\"Duration\"].describe()[\"count\"].unstack().T.div(tst_df[\"TST\"], axis = 0).describe()\n",
    "df_index_laterality_wake = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_index_laterality_wake.columns = [\"Unilateral\", \"Bilateral\"]\n",
    "for movement in df_index_laterality_wake.columns:\n",
    "    med = df_index_laterality.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_index_laterality.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_index_laterality.loc[\"75%\", movement].round(1)\n",
    "    df_index_laterality_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_index_laterality_wake = df_index_laterality_wake.T\n",
    "df_index_laterality_wake.columns = [\"Index (n/h)\"]\n",
    "\n",
    "df_duration_laterality = bursts_df_wake.groupby([\"Laterality\", \"sub_ID\"])[\"Duration\"].describe()[\"mean\"].unstack().T.describe()\n",
    "df_duration_laterality_wake = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_duration_laterality_wake.columns = [\"Unilateral\", \"Bilateral\"]\n",
    "for movement in df_duration_laterality_wake.columns:\n",
    "    med = df_duration_laterality.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_duration_laterality.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_duration_laterality.loc[\"75%\", movement].round(1)\n",
    "    df_duration_laterality_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_duration_laterality_wake = df_duration_laterality_wake.T\n",
    "df_duration_laterality_wake.columns = [\"Duration (s)\"]\n",
    "\n",
    "df_p2p_laterality = (bursts_df_wake.groupby([\"Laterality\", \"sub_ID\"])[\"p2p\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_p2p_laterality_wake = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_p2p_laterality_wake.columns = [\"Unilateral\", \"Bilateral\"]\n",
    "for movement in df_p2p_laterality_wake.columns:\n",
    "    med = df_p2p_laterality.loc[\"50%\", movement].round(2)\n",
    "    perc25 = df_p2p_laterality.loc[\"25%\", movement].round(2)\n",
    "    perc75 = df_p2p_laterality.loc[\"75%\", movement].round(2)\n",
    "    df_p2p_laterality_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_p2p_laterality_wake = df_p2p_laterality_wake.T\n",
    "df_p2p_laterality_wake.columns = [\"p2p (g)\"]\n",
    "\n",
    "df_AUC_laterality = (bursts_df_wake.groupby([\"Laterality\", \"sub_ID\"])[\"AUC\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_AUC_laterality_wake = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_AUC_laterality_wake.columns = [\"Unilateral\", \"Bilateral\"]\n",
    "for movement in df_AUC_laterality_wake.columns:\n",
    "    med = df_AUC_laterality.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_AUC_laterality.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_AUC_laterality.loc[\"75%\", movement].round(1)\n",
    "    df_AUC_laterality_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_AUC_laterality_wake = df_AUC_laterality_wake.T\n",
    "df_AUC_laterality_wake.columns = [\"AUC (gs)\"]\n",
    "\n",
    "table_laterality_wake = pd.concat([df_index_laterality_wake, df_duration_laterality_wake, df_p2p_laterality_wake, df_AUC_laterality_wake], axis = 1)\n",
    "\n",
    "table_wake = pd.concat([table_movements_wake, table_laterality_wake], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_df_sleep.loc[bursts_df_sleep[\"Category\"] != \"Focal\", \"Category\"] = \"Non Focal\"\n",
    "\n",
    "df_index_focal = bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].describe()[\"count\"].unstack().T.div(tst_df[\"TST\"], axis = 0).describe()\n",
    "df_index_focal_sleep = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_index_focal_sleep.columns = [\"Focal\", \"Non Focal\"]\n",
    "for movement in df_index_focal_sleep.columns:\n",
    "    med = df_index_focal.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_index_focal.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_index_focal.loc[\"75%\", movement].round(1)\n",
    "    df_index_focal_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_index_focal_sleep = df_index_focal_sleep.T\n",
    "df_index_focal_sleep.columns = [\"Index (n/h)\"]\n",
    "\n",
    "df_duration_focal = bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].describe()[\"mean\"].unstack().T.describe()\n",
    "df_duration_focal_sleep = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_duration_focal_sleep.columns = [\"Focal\", \"Non Focal\"]\n",
    "for movement in df_duration_focal_sleep.columns:\n",
    "    med = df_duration_focal.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_duration_focal.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_duration_focal.loc[\"75%\", movement].round(1)\n",
    "    df_duration_focal_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_duration_focal_sleep = df_duration_focal_sleep.T\n",
    "df_duration_focal_sleep.columns = [\"Duration (s)\"]\n",
    "\n",
    "df_p2p_focal = (bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"p2p\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_p2p_focal_sleep = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_p2p_focal_sleep.columns = [\"Focal\", \"Non Focal\"]\n",
    "for movement in df_p2p_focal_sleep.columns:\n",
    "    med = df_p2p_focal.loc[\"50%\", movement].round(2)\n",
    "    perc25 = df_p2p_focal.loc[\"25%\", movement].round(2)\n",
    "    perc75 = df_p2p_focal.loc[\"75%\", movement].round(2)\n",
    "    df_p2p_focal_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_p2p_focal_sleep = df_p2p_focal_sleep.T\n",
    "df_p2p_focal_sleep.columns = [\"p2p (g)\"]\n",
    "\n",
    "df_AUC_focal = (bursts_df_sleep.groupby([\"Category\", \"sub_ID\"])[\"AUC\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_AUC_focal_sleep = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_AUC_focal_sleep.columns = [\"Focal\", \"Non Focal\"]\n",
    "for movement in df_AUC_focal_sleep.columns:\n",
    "    med = df_AUC_focal.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_AUC_focal.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_AUC_focal.loc[\"75%\", movement].round(1)\n",
    "    df_AUC_focal_sleep[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_AUC_focal_sleep = df_AUC_focal_sleep.T\n",
    "df_AUC_focal_sleep.columns = [\"AUC (gs)\"]\n",
    "\n",
    "table_focal_sleep = pd.concat([df_index_focal_sleep, df_duration_focal_sleep, df_p2p_focal_sleep, df_AUC_focal_sleep], axis = 1)\n",
    "\n",
    "table_sleep = pd.concat([table_sleep, table_focal_sleep.loc[\"Non Focal\"].to_frame().T], axis = 0)\n",
    "\n",
    "bursts_df_wake.loc[bursts_df_wake[\"Category\"] != \"Focal\", \"Category\"] = \"Non Focal\"\n",
    "\n",
    "df_index_focal = bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].describe()[\"count\"].unstack().T.div(twt_df[\"TWT\"], axis = 0).describe()\n",
    "df_index_focal_wake = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_index_focal_wake.columns = [\"Focal\", \"Non Focal\"]\n",
    "for movement in df_index_focal_wake.columns:\n",
    "    med = df_index_focal.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_index_focal.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_index_focal.loc[\"75%\", movement].round(1)\n",
    "    df_index_focal_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_index_focal_wake = df_index_focal_wake.T\n",
    "df_index_focal_wake.columns = [\"Index (n/h)\"]\n",
    "\n",
    "df_duration_focal = bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"Duration\"].describe()[\"mean\"].unstack().T.describe()\n",
    "df_duration_focal_wake = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_duration_focal_wake.columns = [\"Focal\", \"Non Focal\"]\n",
    "for movement in df_duration_focal_wake.columns:\n",
    "    med = df_duration_focal.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_duration_focal.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_duration_focal.loc[\"75%\", movement].round(1)\n",
    "    df_duration_focal_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_duration_focal_wake = df_duration_focal_wake.T\n",
    "df_duration_focal_wake.columns = [\"Duration (s)\"]\n",
    "\n",
    "df_p2p_focal = (bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"p2p\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_p2p_focal_wake = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_p2p_focal_wake.columns = [\"Focal\", \"Non Focal\"]\n",
    "for movement in df_p2p_focal_wake.columns:\n",
    "    med = df_p2p_focal.loc[\"50%\", movement].round(2)\n",
    "    perc25 = df_p2p_focal.loc[\"25%\", movement].round(2)\n",
    "    perc75 = df_p2p_focal.loc[\"75%\", movement].round(2)\n",
    "    df_p2p_focal_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_p2p_focal_wake = df_p2p_focal_wake.T\n",
    "df_p2p_focal_wake.columns = [\"p2p (g)\"]\n",
    "\n",
    "df_AUC_focal = (bursts_df_wake.groupby([\"Category\", \"sub_ID\"])[\"AUC\"].describe()[\"mean\"].unstack().T/1000).describe()\n",
    "df_AUC_focal_wake = pd.DataFrame([\"a\", \"a\"]).T\n",
    "df_AUC_focal_wake.columns = [\"Focal\", \"Non Focal\"]\n",
    "for movement in df_AUC_focal_wake.columns:\n",
    "    med = df_AUC_focal.loc[\"50%\", movement].round(1)\n",
    "    perc25 = df_AUC_focal.loc[\"25%\", movement].round(1)\n",
    "    perc75 = df_AUC_focal.loc[\"75%\", movement].round(1)\n",
    "    df_AUC_focal_wake[movement] = str(med) + \" (\" + str(perc25) + \"-\" + str(perc75) + \")\"\n",
    "df_AUC_focal_wake = df_AUC_focal_wake.T\n",
    "df_AUC_focal_wake.columns = [\"AUC (gs)\"]\n",
    "\n",
    "table_focal_wake = pd.concat([df_index_focal_wake, df_duration_focal_wake, df_p2p_focal_wake, df_AUC_focal_wake], axis = 1)\n",
    "\n",
    "table_wake = pd.concat([table_wake, table_focal_wake.loc[\"Non Focal\"].to_frame().T], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index (n/h)</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>p2p (g)</th>\n",
       "      <th>AUC (gs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Focal</th>\n",
       "      <td>12.6 (9.0-19.1)</td>\n",
       "      <td>1.6 (1.3-1.9)</td>\n",
       "      <td>0.04 (0.03-0.05)</td>\n",
       "      <td>5.5 (3.1-7.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full Body</th>\n",
       "      <td>58.9 (55.1-61.5)</td>\n",
       "      <td>19.7 (16.0-30.4)</td>\n",
       "      <td>3.85 (3.25-4.5)</td>\n",
       "      <td>1925.9 (1567.3-3063.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lower Body</th>\n",
       "      <td>6.2 (4.7-8.3)</td>\n",
       "      <td>3.3 (2.3-4.9)</td>\n",
       "      <td>0.09 (0.06-0.12)</td>\n",
       "      <td>21.0 (8.6-31.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upper Body</th>\n",
       "      <td>3.9 (1.9-5.1)</td>\n",
       "      <td>5.0 (4.8-6.6)</td>\n",
       "      <td>0.34 (0.22-0.46)</td>\n",
       "      <td>76.6 (72.2-158.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixed</th>\n",
       "      <td>8.1 (5.3-12.7)</td>\n",
       "      <td>6.0 (4.8-6.5)</td>\n",
       "      <td>0.4 (0.35-0.54)</td>\n",
       "      <td>81.8 (67.1-130.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unilateral</th>\n",
       "      <td>1.5 (1.2-2.2)</td>\n",
       "      <td>2.0 (1.4-2.2)</td>\n",
       "      <td>0.05 (0.04-0.06)</td>\n",
       "      <td>7.5 (4.8-11.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilateral</th>\n",
       "      <td>5.9 (5.5-9.5)</td>\n",
       "      <td>17.6 (13.6-25.4)</td>\n",
       "      <td>3.18 (2.69-3.76)</td>\n",
       "      <td>1584.2 (1333.7-2683.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non Focal</th>\n",
       "      <td>73.7 (67.5-80.9)</td>\n",
       "      <td>17.0 (13.2-24.0)</td>\n",
       "      <td>3.01 (2.56-3.34)</td>\n",
       "      <td>1504.8 (1230.8-2333.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non Focal</th>\n",
       "      <td>73.7 (67.5-80.9)</td>\n",
       "      <td>17.0 (13.2-24.0)</td>\n",
       "      <td>3.01 (2.56-3.34)</td>\n",
       "      <td>1504.8 (1230.8-2333.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Index (n/h)      Duration (s)           p2p (g)  \\\n",
       "Focal        12.6 (9.0-19.1)     1.6 (1.3-1.9)  0.04 (0.03-0.05)   \n",
       "Full Body   58.9 (55.1-61.5)  19.7 (16.0-30.4)   3.85 (3.25-4.5)   \n",
       "Lower Body     6.2 (4.7-8.3)     3.3 (2.3-4.9)  0.09 (0.06-0.12)   \n",
       "Upper Body     3.9 (1.9-5.1)     5.0 (4.8-6.6)  0.34 (0.22-0.46)   \n",
       "Mixed         8.1 (5.3-12.7)     6.0 (4.8-6.5)   0.4 (0.35-0.54)   \n",
       "Unilateral     1.5 (1.2-2.2)     2.0 (1.4-2.2)  0.05 (0.04-0.06)   \n",
       "Bilateral      5.9 (5.5-9.5)  17.6 (13.6-25.4)  3.18 (2.69-3.76)   \n",
       "Non Focal   73.7 (67.5-80.9)  17.0 (13.2-24.0)  3.01 (2.56-3.34)   \n",
       "Non Focal   73.7 (67.5-80.9)  17.0 (13.2-24.0)  3.01 (2.56-3.34)   \n",
       "\n",
       "                         AUC (gs)  \n",
       "Focal                5.5 (3.1-7.5)  \n",
       "Full Body   1925.9 (1567.3-3063.7)  \n",
       "Lower Body         21.0 (8.6-31.2)  \n",
       "Upper Body       76.6 (72.2-158.6)  \n",
       "Mixed            81.8 (67.1-130.0)  \n",
       "Unilateral          7.5 (4.8-11.1)  \n",
       "Bilateral   1584.2 (1333.7-2683.8)  \n",
       "Non Focal   1504.8 (1230.8-2333.1)  \n",
       "Non Focal   1504.8 (1230.8-2333.1)  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_wake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index (n/h)</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>p2p (g)</th>\n",
       "      <th>AUC (gs)</th>\n",
       "      <th>Index (n/h)</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>p2p (g)</th>\n",
       "      <th>AUC (gs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Focal</th>\n",
       "      <td>9.1 (7.6-10.7)</td>\n",
       "      <td>1.3 (1.2-1.6)</td>\n",
       "      <td>0.04 (0.03-0.05)</td>\n",
       "      <td>4.7 (3.0-5.9)</td>\n",
       "      <td>12.6 (9.0-19.1)</td>\n",
       "      <td>1.6 (1.3-1.9)</td>\n",
       "      <td>0.04 (0.03-0.05)</td>\n",
       "      <td>5.5 (3.1-7.5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Full Body</th>\n",
       "      <td>4.2 (3.4-5.4)</td>\n",
       "      <td>9.5 (8.0-10.9)</td>\n",
       "      <td>1.06 (0.95-1.25)</td>\n",
       "      <td>337.6 (283.7-504.9)</td>\n",
       "      <td>58.9 (55.1-61.5)</td>\n",
       "      <td>19.7 (16.0-30.4)</td>\n",
       "      <td>3.85 (3.25-4.5)</td>\n",
       "      <td>1925.9 (1567.3-3063.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lower Body</th>\n",
       "      <td>2.8 (2.0-4.3)</td>\n",
       "      <td>3.1 (2.8-3.5)</td>\n",
       "      <td>0.1 (0.08-0.13)</td>\n",
       "      <td>16.7 (13.0-23.4)</td>\n",
       "      <td>6.2 (4.7-8.3)</td>\n",
       "      <td>3.3 (2.3-4.9)</td>\n",
       "      <td>0.09 (0.06-0.12)</td>\n",
       "      <td>21.0 (8.6-31.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Upper Body</th>\n",
       "      <td>0.8 (0.4-1.6)</td>\n",
       "      <td>3.4 (2.8-4.5)</td>\n",
       "      <td>0.12 (0.08-0.25)</td>\n",
       "      <td>20.2 (13.6-46.0)</td>\n",
       "      <td>3.9 (1.9-5.1)</td>\n",
       "      <td>5.0 (4.8-6.6)</td>\n",
       "      <td>0.34 (0.22-0.46)</td>\n",
       "      <td>76.6 (72.2-158.6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mixed</th>\n",
       "      <td>3.0 (2.1-4.0)</td>\n",
       "      <td>4.9 (4.2-5.7)</td>\n",
       "      <td>0.27 (0.21-0.3)</td>\n",
       "      <td>53.6 (39.1-71.2)</td>\n",
       "      <td>8.1 (5.3-12.7)</td>\n",
       "      <td>6.0 (4.8-6.5)</td>\n",
       "      <td>0.4 (0.35-0.54)</td>\n",
       "      <td>81.8 (67.1-130.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unilateral</th>\n",
       "      <td>11.1 (9.4-13.6)</td>\n",
       "      <td>1.8 (1.6-2.0)</td>\n",
       "      <td>0.05 (0.04-0.06)</td>\n",
       "      <td>7.3 (4.9-10.3)</td>\n",
       "      <td>1.5 (1.2-2.2)</td>\n",
       "      <td>2.0 (1.4-2.2)</td>\n",
       "      <td>0.05 (0.04-0.06)</td>\n",
       "      <td>7.5 (4.8-11.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilateral</th>\n",
       "      <td>8.8 (6.6-12.2)</td>\n",
       "      <td>7.1 (6.2-8.0)</td>\n",
       "      <td>0.67 (0.56-0.85)</td>\n",
       "      <td>200.0 (162.6-251.8)</td>\n",
       "      <td>5.9 (5.5-9.5)</td>\n",
       "      <td>17.6 (13.6-25.4)</td>\n",
       "      <td>3.18 (2.69-3.76)</td>\n",
       "      <td>1584.2 (1333.7-2683.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Non Focal</th>\n",
       "      <td>12.0 (10.2-15.4)</td>\n",
       "      <td>6.2 (5.3-6.9)</td>\n",
       "      <td>0.54 (0.42-0.66)</td>\n",
       "      <td>165.3 (119.2-212.3)</td>\n",
       "      <td>73.7 (67.5-80.9)</td>\n",
       "      <td>17.0 (13.2-24.0)</td>\n",
       "      <td>3.01 (2.56-3.34)</td>\n",
       "      <td>1504.8 (1230.8-2333.1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Index (n/h)    Duration (s)           p2p (g)  \\\n",
       "Focal         9.1 (7.6-10.7)   1.3 (1.2-1.6)  0.04 (0.03-0.05)   \n",
       "Full Body      4.2 (3.4-5.4)  9.5 (8.0-10.9)  1.06 (0.95-1.25)   \n",
       "Lower Body     2.8 (2.0-4.3)   3.1 (2.8-3.5)   0.1 (0.08-0.13)   \n",
       "Upper Body     0.8 (0.4-1.6)   3.4 (2.8-4.5)  0.12 (0.08-0.25)   \n",
       "Mixed          3.0 (2.1-4.0)   4.9 (4.2-5.7)   0.27 (0.21-0.3)   \n",
       "Unilateral   11.1 (9.4-13.6)   1.8 (1.6-2.0)  0.05 (0.04-0.06)   \n",
       "Bilateral     8.8 (6.6-12.2)   7.1 (6.2-8.0)  0.67 (0.56-0.85)   \n",
       "Non Focal   12.0 (10.2-15.4)   6.2 (5.3-6.9)  0.54 (0.42-0.66)   \n",
       "\n",
       "                      AUC (gs)       Index (n/h)      Duration (s)  \\\n",
       "Focal             4.7 (3.0-5.9)   12.6 (9.0-19.1)     1.6 (1.3-1.9)   \n",
       "Full Body   337.6 (283.7-504.9)  58.9 (55.1-61.5)  19.7 (16.0-30.4)   \n",
       "Lower Body     16.7 (13.0-23.4)     6.2 (4.7-8.3)     3.3 (2.3-4.9)   \n",
       "Upper Body     20.2 (13.6-46.0)     3.9 (1.9-5.1)     5.0 (4.8-6.6)   \n",
       "Mixed          53.6 (39.1-71.2)    8.1 (5.3-12.7)     6.0 (4.8-6.5)   \n",
       "Unilateral       7.3 (4.9-10.3)     1.5 (1.2-2.2)     2.0 (1.4-2.2)   \n",
       "Bilateral   200.0 (162.6-251.8)     5.9 (5.5-9.5)  17.6 (13.6-25.4)   \n",
       "Non Focal   165.3 (119.2-212.3)  73.7 (67.5-80.9)  17.0 (13.2-24.0)   \n",
       "\n",
       "                     p2p (g)               AUC (gs)  \n",
       "Focal       0.04 (0.03-0.05)           5.5 (3.1-7.5)  \n",
       "Full Body    3.85 (3.25-4.5)  1925.9 (1567.3-3063.7)  \n",
       "Lower Body  0.09 (0.06-0.12)         21.0 (8.6-31.2)  \n",
       "Upper Body  0.34 (0.22-0.46)       76.6 (72.2-158.6)  \n",
       "Mixed        0.4 (0.35-0.54)       81.8 (67.1-130.0)  \n",
       "Unilateral  0.05 (0.04-0.06)          7.5 (4.8-11.1)  \n",
       "Bilateral   3.18 (2.69-3.76)  1584.2 (1333.7-2683.8)  \n",
       "Non Focal   3.01 (2.56-3.34)  1504.8 (1230.8-2333.1)  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.concat([table_sleep, table_wake], axis = 1)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_excel(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/tables/table1_new_new.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR response revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focal and Non Focal Sleep vs Wake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834, 15)\n"
     ]
    }
   ],
   "source": [
    "subjects = [\"158\", \"098\", \"633\", \"279\", \"906\", \"547\", \"971\", \"958\", \"815\"]\n",
    "bursts_HR = pd.read_pickle(\"/Volumes/Untitled/rehab/data/bursts_HR_ACC_final.pkl\")\n",
    "bursts_HR[\"ACC_response\"] = bursts_HR[\"ACC_response\"].apply(lambda x: np.array(x))\n",
    "print(bursts_HR.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_HR_df_sleep = bursts_HR[bursts_HR[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_HR_df_sleep[\"Duration\"] = bursts_HR_df_sleep[\"End\"] - bursts_HR_df_sleep[\"Start\"]\n",
    "bursts_HR_df_sleep[\"Duration\"] = bursts_HR_df_sleep[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_HR_df_sleep[\"n_limbs\"] = bursts_HR_df_sleep[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_HR_df_sleep[\"Category\"] = \"placeholder\"\n",
    "bursts_HR_df_sleep.loc[bursts_HR_df_sleep[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "bursts_HR_df_sleep.loc[bursts_HR_df_sleep[\"Category\"] != \"Focal\", \"Category\"] = \"Non Focal\"\n",
    "\n",
    "\n",
    "bursts_HR_df_wake = bursts_HR[bursts_HR[\"SIB\"] == 0].reset_index(drop=True)\n",
    "bursts_HR_df_wake[\"Duration\"] = bursts_HR_df_wake[\"End\"] - bursts_HR_df_wake[\"Start\"]\n",
    "bursts_HR_df_wake[\"Duration\"] = bursts_HR_df_wake[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_HR_df_wake[\"n_limbs\"] = bursts_HR_df_wake[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_HR_df_wake[\"Category\"] = \"placeholder\"\n",
    "bursts_HR_df_wake.loc[bursts_HR_df_wake[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "bursts_HR_df_wake.loc[bursts_HR_df_wake[\"Category\"] != \"Focal\", \"Category\"] = \"Non Focal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_response_sleep_focal = bursts_HR_df_sleep.groupby([\"sub_ID\",\"Category\"])[\"HR_response_normalized\"].mean().unstack()[\"Focal\"]\n",
    "HR_response_sleep_focal_sem = HR_response_sleep_focal.dropna().to_numpy().std() / np.sqrt(HR_response_sleep_focal.dropna().shape[0])\n",
    "\n",
    "HR_response_sleep_non_focal = bursts_HR_df_sleep.groupby([\"sub_ID\",\"Category\"])[\"HR_response_normalized\"].mean().unstack()[\"Non Focal\"]\n",
    "HR_response_sleep_non_focal_sem = HR_response_sleep_non_focal.dropna().to_numpy().std() / np.sqrt(HR_response_sleep_non_focal.dropna().shape[0])\n",
    "\n",
    "HR_response_wake_focal = bursts_HR_df_wake.groupby([\"sub_ID\",\"Category\"])[\"HR_response_normalized\"].mean().unstack()[\"Focal\"]\n",
    "HR_response_wake_focal_sem = HR_response_wake_focal.dropna().to_numpy().std() / np.sqrt(HR_response_wake_focal.dropna().shape[0])\n",
    "\n",
    "HR_response_wake_non_focal = bursts_HR_df_wake.groupby([\"sub_ID\",\"Category\"])[\"HR_response_normalized\"].mean().unstack()[\"Non Focal\"]\n",
    "HR_response_wake_non_focal_sem = HR_response_wake_non_focal.dropna().to_numpy().std() / np.sqrt(HR_response_wake_non_focal.dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9ec6809f30>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 6))\n",
    "\n",
    "t = np.arange(-19, 50, 1)\n",
    "\n",
    "ax1.errorbar(t, HR_response_wake_non_focal.mean(), yerr = HR_response_wake_non_focal_sem, fmt = '-o', capsize=3, elinewidth=1.5, label = \"Wake\")\n",
    "ax1.errorbar(t, HR_response_sleep_non_focal.mean(), yerr = HR_response_sleep_non_focal_sem, fmt = '-o', capsize=3, elinewidth=1.5, label = \"Sleep\")\n",
    "\n",
    "\n",
    "ax1.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "# ax.annotate('Movement onset', xy=(0, plt.ylim()[1]-6), xytext=(-60, plt.ylim()[1]-66),\n",
    "#              textcoords='offset points', ha='right', va='bottom', fontsize=19,\n",
    "#              bbox=dict(boxstyle='round,pad=0.5', fc='gray', alpha=0.2, edgecolor='black'),\n",
    "#              arrowprops=dict(facecolor='black', shrink=0.05, width=2))\n",
    "\n",
    "# plt.xlim(-15, 30)\n",
    "\n",
    "# plt.xticks(ticks = np.arange(-20, 40, 5), labels=np.arange(-20, 40, 5), fontsize=16)\n",
    "ax1.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax1.set_ylabel('HR response (%)', fontsize = 21)\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax1.set_label('')\n",
    "ax1.xaxis.set_tick_params(labelsize=20)\n",
    "ax1.yaxis.set_tick_params(labelsize=20)\n",
    "ax1.legend(frameon = True, fancybox = True, shadow = True, fontsize = 21)\n",
    "\n",
    "ax2.errorbar(t, HR_response_wake_focal.mean(), yerr = HR_response_wake_focal_sem, fmt = '-o', capsize=3, elinewidth=1.5, label = \"Wake\")\n",
    "ax2.errorbar(t, HR_response_sleep_focal.mean(), yerr = HR_response_sleep_focal_sem, fmt = '-o', capsize=3, elinewidth=1.5, label = \"Sleep\")\n",
    "\n",
    "ax2.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "\n",
    "plt.xlim(-10, 20)\n",
    "\n",
    "# plt.xticks(ticks = np.arange(-20, 40, 5), labels=np.arange(-20, 40, 5), fontsize=16)\n",
    "ax2.set_xlabel('Time (seconds)', fontsize = 21)\n",
    "ax2.set_ylabel('HR response (%)', fontsize = 21)\n",
    "ax2.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax2.set_label('')\n",
    "ax2.xaxis.set_tick_params(labelsize=20)\n",
    "ax2.yaxis.set_tick_params(labelsize=20)\n",
    "ax2.legend(frameon = True, fancybox = True, shadow = True, fontsize = 21)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "burst_non_focal_sleep = bursts_HR_df_sleep[bursts_HR_df_sleep[\"Category\"] == \"Focal\"]\n",
    "burst_non_focal_sleep = burst_non_focal_sleep.groupby([\"sub_ID\"])[\"HR_response_normalized\"].mean()\n",
    "\n",
    "burst_non_focal_wake = bursts_HR_df_wake[bursts_HR_df_wake[\"Category\"] == \"Focal\"]\n",
    "burst_non_focal_wake = burst_non_focal_wake.groupby([\"sub_ID\"])[\"HR_response_normalized\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_ID\n",
       "098    [-1.8540953787841041, -1.3546543322471596, -0....\n",
       "158    [-0.286614272215478, 0.20289274727899875, -0.3...\n",
       "279    [-1.4791132626841312, -2.974134703707418, -1.8...\n",
       "547    [1.4304552613665562, 0.6423388122128357, -0.28...\n",
       "633    [0.00968442446457137, -0.9121184984440163, -1....\n",
       "815    [1.5936744195753498, 1.8116139415971724, 0.534...\n",
       "906    [0.4156369192667914, 0.6955631086561689, 1.325...\n",
       "958    [3.4423239658526645, 1.3853792607011723, 0.434...\n",
       "971    [-0.2765750678579345, -0.37266896954880163, 0....\n",
       "Name: HR_response_normalized, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burst_non_focal_sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     9.000000\n",
       "mean      5.955708\n",
       "std       2.858518\n",
       "min       2.054361\n",
       "25%       4.623182\n",
       "50%       5.368991\n",
       "75%       7.509661\n",
       "max      11.998675\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_nonfocal_sleep = []\n",
    "p_nonfocal_wake = []\n",
    "for sub in subjects:\n",
    "    p_nonfocal_sleep.append(burst_non_focal_sleep[sub].max())\n",
    "    # try:\n",
    "    #     p_nonfocal_wake.append(burst_non_focal_wake[sub].max())\n",
    "    # except:\n",
    "    #     p_nonfocal_wake.append(np.nan)\n",
    "\n",
    "pd.Series(p_nonfocal_sleep).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-statistic: 0.0, p-value: 0.00390625\n"
     ]
    }
   ],
   "source": [
    "from functions.plot_utils import stripplot_with_lines\n",
    "peaks_sleep_vs_wake = pd.DataFrame({\"Sleep\": p_nonfocal_sleep, \"Wake\": p_nonfocal_wake})\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.boxplot(peaks_sleep_vs_wake, palette = \"Set2\", fill = False, ax = ax, linewidth = 2.1, width = 0.68)\n",
    "jitter = 0.01\n",
    "stripplot_with_lines(peaks_sleep_vs_wake, jitter, ax)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "plt.xticks(fontsize = 21)\n",
    "plt.yticks(fontsize = 21)\n",
    "plt.ylabel(\"HR peak (%)\", fontsize = 21)\n",
    "plt.title(\"HR peak associated with non-focal movements\", fontsize = 24)\n",
    "\n",
    "peaks_sleep = np.array(p_nonfocal_sleep)\n",
    "peaks_wake = np.array(p_nonfocal_wake)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "w_stat, p_value = stats.wilcoxon(peaks_sleep, peaks_wake)\n",
    "\n",
    "print(f\"W-statistic: {w_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/boxplot_peaks_sleep_wake_non_focal.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     9.000000\n",
       "mean     30.333333\n",
       "std       5.431390\n",
       "min      23.000000\n",
       "25%      26.000000\n",
       "50%      31.000000\n",
       "75%      34.000000\n",
       "max      39.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sleep = []\n",
    "d_wake = []\n",
    "\n",
    "for sub in subjects:\n",
    "    d_sleep.append(np.where(burst_non_focal_sleep[sub][20:] <= 0)[0][0])\n",
    "    d_wake.append(np.where(burst_non_focal_wake[sub][20:] <= 0)[0][0])\n",
    "\n",
    "pd.Series(d_wake).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-statistic: 0.0, p-value: 0.00390625\n"
     ]
    }
   ],
   "source": [
    "from functions.plot_utils import stripplot_with_lines\n",
    "duration_sleep_vs_wake = pd.DataFrame({\"Sleep\": d_sleep, \"Wake\": d_wake})\n",
    "\n",
    "f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.boxplot(duration_sleep_vs_wake, palette = \"Set2\", fill = False, ax = ax, linewidth = 2.1, width = 0.68)\n",
    "jitter = 0.01\n",
    "stripplot_with_lines(duration_sleep_vs_wake, jitter, ax)\n",
    "plt.xticks(fontsize = 21)\n",
    "plt.yticks(fontsize = 21)\n",
    "plt.ylabel(\"HR duration (s)\", fontsize = 21)\n",
    "plt.title(\"HR response duration associated with non-focal movements\", fontsize = 24)\n",
    "\n",
    "duration_sleep = np.array(d_sleep)\n",
    "duration_wake = np.array(d_wake)\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "w_stat, p_value = stats.wilcoxon(duration_sleep, duration_wake)\n",
    "\n",
    "print(f\"W-statistic: {w_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/HR/boxplot_duration_sleep_wake_non_focal.png\", dpi = 300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-focal (Lower-body, Upper-body, Mixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bursts_HR_df_sleep = bursts_HR[bursts_HR[\"SIB\"] == 1].reset_index(drop=True)\n",
    "bursts_HR_df_sleep[\"Duration\"] = bursts_HR_df_sleep[\"End\"] - bursts_HR_df_sleep[\"Start\"]\n",
    "bursts_HR_df_sleep[\"Duration\"] = bursts_HR_df_sleep[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_HR_df_sleep[\"n_limbs\"] = bursts_HR_df_sleep[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_HR_df_sleep[\"Category\"] = \"placeholder\"\n",
    "bursts_HR_df_sleep[\"Laterality\"] = \"Bilateral\"\n",
    "bursts_HR_df_sleep.loc[bursts_HR_df_sleep[\"n_limbs\"] == 5, \"Category\"] = \"Full Body\"\n",
    "bursts_HR_df_sleep.loc[(bursts_HR_df_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}), \"Category\"] = \"Lower Body\"\n",
    "bursts_HR_df_sleep.loc[(bursts_HR_df_sleep[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"RW\", \"T\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}), \"Category\"] = \"Upper Body\"\n",
    "bursts_HR_df_sleep.loc[(bursts_HR_df_sleep[\"n_limbs\"] >= 2) & (bursts_HR_df_sleep[\"n_limbs\"] != 5) & (bursts_HR_df_sleep[\"Limbs\"] != {\"LL\", \"RL\"}) & (bursts_HR_df_sleep[\"Limbs\"] != {\"LL\", \"RL\", \"T\"}) & (bursts_HR_df_sleep[\"Limbs\"] != {\"LW\", \"RW\"}) & (bursts_HR_df_sleep[\"Limbs\"] != {\"LW\", \"RW\", \"T\"}) & (bursts_HR_df_sleep[\"Limbs\"] != {\"LL\", \"T\"}) & (bursts_HR_df_sleep[\"Limbs\"] != {\"RL\", \"T\"}) & (bursts_HR_df_sleep[\"Limbs\"] != {\"LW\", \"T\"}) & (bursts_HR_df_sleep[\"Limbs\"] != {\"RW\", \"T\"}), \"Category\"] = \"Mixed\"\n",
    "bursts_HR_df_sleep.loc[bursts_HR_df_sleep[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "bursts_HR_df_sleep.loc[(bursts_HR_df_sleep[\"Limbs\"] == {\"LL\", \"LW\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"RL\", \"RW\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"LL\", \"LW\", \"T\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"RL\", \"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_HR_df_sleep.loc[(bursts_HR_df_sleep[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_HR_df_sleep.loc[(bursts_HR_df_sleep[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"LW\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"RW\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"LL\"}) | (bursts_HR_df_sleep[\"Limbs\"] == {\"RL\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_HR_df_sleep.loc[bursts_HR_df_sleep[\"Limbs\"] == {\"T\"}, \"Laterality\"] = \"None\"\n",
    "\n",
    "bursts_HR_df_wake = bursts_HR[bursts_HR[\"SIB\"] == 0].reset_index(drop=True)\n",
    "bursts_HR_df_wake[\"Duration\"] = bursts_HR_df_wake[\"End\"] - bursts_HR_df_wake[\"Start\"]\n",
    "bursts_HR_df_wake[\"Duration\"] = bursts_HR_df_wake[\"Duration\"].apply(lambda x: x.total_seconds())\n",
    "bursts_HR_df_wake[\"n_limbs\"] = bursts_HR_df_wake[\"Limbs\"].apply(lambda x: len(x))\n",
    "bursts_HR_df_wake[\"Category\"] = \"placeholder\"\n",
    "bursts_HR_df_wake[\"Laterality\"] = \"Bilateral\"\n",
    "bursts_HR_df_wake.loc[bursts_HR_df_wake[\"n_limbs\"] == 5, \"Category\"] = \"Full Body\"\n",
    "bursts_HR_df_wake.loc[(bursts_HR_df_wake[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"LL\", \"RL\", \"T\"}), \"Category\"] = \"Lower Body\"\n",
    "bursts_HR_df_wake.loc[(bursts_HR_df_wake[\"Limbs\"] == {\"LW\", \"RW\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"RW\", \"T\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"LW\", \"RW\", \"T\"}), \"Category\"] = \"Upper Body\"\n",
    "bursts_HR_df_wake.loc[(bursts_HR_df_wake[\"n_limbs\"] >= 2) & (bursts_HR_df_wake[\"n_limbs\"] != 5) & (bursts_HR_df_wake[\"Limbs\"] != {\"LL\", \"RL\"}) & (bursts_HR_df_wake[\"Limbs\"] != {\"LL\", \"RL\", \"T\"}) & (bursts_HR_df_wake[\"Limbs\"] != {\"LW\", \"RW\"}) & (bursts_HR_df_wake[\"Limbs\"] != {\"LW\", \"RW\", \"T\"}) & (bursts_HR_df_wake[\"Limbs\"] != {\"LL\", \"T\"}) & (bursts_HR_df_wake[\"Limbs\"] != {\"RL\", \"T\"}) & (bursts_HR_df_wake[\"Limbs\"] != {\"LW\", \"T\"}) & (bursts_HR_df_wake[\"Limbs\"] != {\"RW\", \"T\"}), \"Category\"] = \"Mixed\"\n",
    "bursts_HR_df_wake.loc[bursts_HR_df_wake[\"n_limbs\"] == 1, \"Category\"] = \"Focal\"\n",
    "bursts_HR_df_wake.loc[(bursts_HR_df_wake[\"Limbs\"] == {\"LL\", \"LW\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"RL\", \"RW\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"LL\", \"LW\", \"T\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"RL\", \"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_HR_df_wake.loc[(bursts_HR_df_wake[\"Limbs\"] == {\"LL\", \"T\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"LW\", \"T\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"RL\", \"T\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"RW\", \"T\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_HR_df_wake.loc[(bursts_HR_df_wake[\"Limbs\"] == {\"LL\", \"RL\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"LW\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"RW\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"LL\"}) | (bursts_HR_df_wake[\"Limbs\"] == {\"RL\"}), \"Laterality\"] = \"Unilateral\"\n",
    "bursts_HR_df_wake.loc[bursts_HR_df_wake[\"Limbs\"] == {\"T\"}, \"Laterality\"] = \"None\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_response_sleep_lower = bursts_HR_df_sleep.groupby([\"sub_ID\",\"Category\"])[\"HR_response_normalized\"].mean().unstack()[\"Lower Body\"]\n",
    "HR_response_sleep_lower_sem = HR_response_sleep_lower.dropna().to_numpy().std() / np.sqrt(HR_response_sleep_lower.dropna().shape[0])\n",
    "\n",
    "HR_response_sleep_upper = bursts_HR_df_sleep.groupby([\"sub_ID\",\"Category\"])[\"HR_response_normalized\"].mean().unstack()[\"Upper Body\"]\n",
    "HR_response_sleep_upper_sem = HR_response_sleep_upper.dropna().to_numpy().std() / np.sqrt(HR_response_sleep_upper.dropna().shape[0])\n",
    "\n",
    "HR_response_sleep_mixed = bursts_HR_df_sleep.groupby([\"sub_ID\",\"Category\"])[\"HR_response_normalized\"].mean().unstack()[\"Mixed\"]\n",
    "HR_response_sleep_mixed_sem = HR_response_sleep_mixed.dropna().to_numpy().std() / np.sqrt(HR_response_sleep_mixed.dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(21, 6), sharey=True)\n",
    "\n",
    "t = np.arange(-19, 50, 1)\n",
    "f.subplots_adjust(wspace=0.05)\n",
    "\n",
    "ax1.errorbar(t, HR_response_sleep_lower.mean(), yerr = HR_response_sleep_lower_sem, fmt = '-o', color = \"k\", capsize=3, elinewidth=1.5, label = \"Lower Body\")\n",
    "ax2.errorbar(t, HR_response_sleep_upper.mean(), yerr = HR_response_sleep_upper_sem, fmt = '-o', color = \"k\", capsize=3, elinewidth=1.5, label = \"Upper Body\")\n",
    "ax3.errorbar(t, HR_response_sleep_mixed.mean(), yerr = HR_response_sleep_mixed_sem, fmt = '-o', color = \"k\", capsize=3, elinewidth=1.5, label = \"Mixed\")\n",
    "\n",
    "ax1.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax2.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax3.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "\n",
    "ax1.set_xlim(-11, 28)\n",
    "ax2.set_xlim(-11, 28)\n",
    "ax3.set_xlim(-11, 28)\n",
    "\n",
    "ax1.set_title(\"Lower Body Movement\", fontsize = 19)\n",
    "ax2.set_title(\"Upper Body Movement\", fontsize = 19)\n",
    "ax3.set_title(\"Mixed Movement\", fontsize = 19)\n",
    "\n",
    "ax1.set_xlabel('Time (seconds)', fontsize = 19)\n",
    "ax2.set_xlabel('Time (seconds)', fontsize = 19)\n",
    "ax3.set_xlabel('Time (seconds)', fontsize = 19)\n",
    "\n",
    "ax1.set_ylabel('HR change', fontsize = 21)\n",
    "ax1.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "\n",
    "ax1.xaxis.set_tick_params(labelsize=19)\n",
    "ax1.yaxis.set_tick_params(labelsize=19)\n",
    "ax2.xaxis.set_tick_params(labelsize=19)\n",
    "ax3.xaxis.set_tick_params(labelsize=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/HR/HR_response_sleep_lower_upper_mixed.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "HR_response_sleep_focal = bursts_HR_df_sleep.groupby([\"sub_ID\",\"Category\"])[\"HR_response_normalized\"].mean().unstack()[\"Focal\"]\n",
    "HR_response_sleep_focal_sem = HR_response_sleep_focal.dropna().to_numpy().std() / np.sqrt(HR_response_sleep_focal.dropna().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Focal Movement')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f, ax= plt.subplots(1, 1, figsize=(12, 5))\n",
    "\n",
    "t = np.arange(-19, 50, 1)\n",
    "\n",
    "ax.errorbar(t+1, HR_response_sleep_focal.mean(), yerr = HR_response_sleep_focal_sem, fmt = '-o', color = \"k\", capsize=3, elinewidth=1.5, label = \"Focal\")\n",
    "\n",
    "ax.axvline(x=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "ax.axhline(y=0, color='grey', linestyle='--', linewidth=1.2)\n",
    "\n",
    "ax.set_xlim(-15+1, 18+1)\n",
    "\n",
    "plt.xlabel('Time (seconds)', fontsize = 19)\n",
    "plt.ylabel('HR change', fontsize = 21)\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(decimals=0))\n",
    "ax.xaxis.set_tick_params(labelsize=19)\n",
    "ax.yaxis.set_tick_params(labelsize=19)\n",
    "\n",
    "plt.yticks(fontsize=16)\n",
    "plt.title(\"Focal Movement\", fontsize = 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitadiBologna/Marcello/sleep-movement-hr/figures/HR/HR_response_sleep_focal.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
