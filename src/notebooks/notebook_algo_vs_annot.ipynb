{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib qt\n",
    "mpl.rcParams['lines.linewidth'] = 0.91\n",
    "plt.style.use('seaborn-v0_8-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary_SPT = {    \n",
    "    \"158\": [pd.Timestamp('2024-02-28 23:00:00'), pd.Timestamp('2024-02-29 07:15:00')], # 158 OK\n",
    "    \"633\": [pd.Timestamp('2024-03-07 00:05:00'), pd.Timestamp('2024-03-07 06:36:00')], # 633 OK\n",
    "    \"906\": [pd.Timestamp('2024-03-07 00:30:00'), pd.Timestamp('2024-03-07 07:30:00')], # 906 OK\n",
    "    \"958\": [pd.Timestamp('2024-03-13 22:00:00'), pd.Timestamp('2024-03-14 06:00:00')], # 958 OK\n",
    "    \"127\": [pd.Timestamp('2024-03-13 23:15:00'), pd.Timestamp('2024-03-14 06:50:00')], # 127 OK\n",
    "    \"098\": [pd.Timestamp('2024-03-16 02:01:00'), pd.Timestamp('2024-03-16 09:50:00')], # 098 OK\n",
    "    \"547\": [pd.Timestamp('2024-03-16 01:04:00'), pd.Timestamp('2024-03-16 07:40:00')], # 547 OK\n",
    "    \"815\": [pd.Timestamp('2024-03-20 23:00:00'), pd.Timestamp('2024-03-21 07:30:00')], # 815 OK\n",
    "    \"914\": [pd.Timestamp('2024-03-20 21:50:00'), pd.Timestamp('2024-03-21 05:50:00')], # 914 OK\n",
    "    \"971\": [pd.Timestamp('2024-03-20 23:50:00'), pd.Timestamp('2024-03-21 07:50:00')], # 971 OK\n",
    "    \"279\": [pd.Timestamp('2024-03-28 00:10:00'), pd.Timestamp('2024-03-28 07:27:00')], # 279 OK\n",
    "    \"965\": [pd.Timestamp('2024-03-28 01:25:00'), pd.Timestamp('2024-03-28 09:20:00')], # 965 OK\n",
    "}\n",
    "\n",
    "comb_location = {\n",
    "    \"158\": [\"la\", \"trunk\", \"rw\"],\n",
    "    \"633\": [\"trunk\", \"ra\", \"lw\"],\n",
    "    \"906\": [\"rw\", \"la\", \"trunk\"],\n",
    "    \"958\": [\"ra\", \"trunk\", \"lw\"],\n",
    "    \"127\": [\"la\", \"trunk\", \"rw\"],\n",
    "    \"098\": [\"trunk\", \"lw\", \"ra\"],\n",
    "    \"547\": [\"la\", \"lw\", \"trunk\"],\n",
    "    \"815\": [\"trunk\", \"ra\", \"lw\"],\n",
    "    \"914\": [\"ra\", \"trunk\", \"lw\"],\n",
    "    \"971\": [\"la\", \"trunk\", \"rw\"],\n",
    "    \"279\": [\"trunk\", \"la\", \"rw\"],\n",
    "    \"965\": [\"rw\", \"trunk\", \"la\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confronto con l'algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_marcello = \"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitaÌ€diBologna/General - LG-MIAR (rehab)/SCORING_bursts\"\n",
    "\n",
    "with open(f\"{path_marcello}/final_database/wrist_5_40_2.5.pkl\", \"rb\") as f:\n",
    "    wrist = pickle.load(f)\n",
    "with open(f\"{path_marcello}/final_database/ankle_5_40_2.5.pkl\", \"rb\") as f:\n",
    "    ankle = pickle.load(f)\n",
    "with open(f\"{path_marcello}/final_database/trunk_5_40_2.5.pkl\", \"rb\") as f:\n",
    "    trunk = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate sensitivity, specificity, PPV, F1\n",
    "\n",
    "subjects = [\"158\", \"098\", \"633\", \"906\", \"279\", \"547\", \"971\", \"958\", \"815\", \"127\", \"914\", \"965\"]\n",
    "\n",
    "wrist_results = {}\n",
    "ankle_results = {}\n",
    "trunk_results = {}\n",
    "\n",
    "alphas = np.arange(5,41,2.5)\n",
    "\n",
    "for alpha in alphas:\n",
    "    wrist_results[alpha] = {\"acc\": [], \"sens\": [], \"spec\": [], \"ppv\": [], \"f1\": []}\n",
    "    ankle_results[alpha] = {\"acc\": [], \"sens\": [], \"spec\": [], \"ppv\": [], \"f1\": []}\n",
    "    trunk_results[alpha] = {\"acc\": [], \"sens\": [], \"spec\": [], \"ppv\": [], \"f1\": []}\n",
    "\n",
    "for alpha in alphas:\n",
    "    for sub in subjects:\n",
    "        TP_wrist = wrist[sub][alpha][\"TP\"]\n",
    "        FP_wrist = wrist[sub][alpha][\"FP\"]\n",
    "        FN_wrist = wrist[sub][alpha][\"FN\"]\n",
    "        TP_ankle = ankle[sub][alpha][\"TP\"]\n",
    "        FP_ankle = ankle[sub][alpha][\"FP\"]\n",
    "        FN_ankle = ankle[sub][alpha][\"FN\"]\n",
    "        TP_trunk = trunk[sub][alpha][\"TP\"]\n",
    "        FP_trunk = trunk[sub][alpha][\"FP\"]\n",
    "        FN_trunk = trunk[sub][alpha][\"FN\"]\n",
    "\n",
    "        acc_wrist = (TP_wrist + FN_wrist) / (TP_wrist + FP_wrist + FN_wrist)\n",
    "        sens_wrist = TP_wrist / (TP_wrist + FN_wrist)\n",
    "        spec_wrist = TP_wrist / (TP_wrist + FP_wrist)\n",
    "        ppv_wrist = TP_wrist / (TP_wrist + FP_wrist)\n",
    "        f1_wrist = 2 * (ppv_wrist * sens_wrist) / (ppv_wrist + sens_wrist)\n",
    "\n",
    "        acc_ankle = (TP_ankle + FN_ankle) / (TP_ankle + FP_ankle + FN_ankle)\n",
    "        sens_ankle = TP_ankle / (TP_ankle + FN_ankle)\n",
    "        spec_ankle = TP_ankle / (TP_ankle + FP_ankle)\n",
    "        ppv_ankle = TP_ankle / (TP_ankle + FP_ankle)\n",
    "        f1_ankle = 2 * (ppv_ankle * sens_ankle) / (ppv_ankle + sens_ankle)\n",
    "\n",
    "        acc_trunk = (TP_trunk + FN_trunk) / (TP_trunk + FP_trunk + FN_trunk)\n",
    "        sens_trunk = TP_trunk / (TP_trunk + FN_trunk)\n",
    "        spec_trunk = TP_trunk / (TP_trunk + FP_trunk)\n",
    "        ppv_trunk = TP_trunk / (TP_trunk + FP_trunk)\n",
    "        f1_trunk = 2 * (ppv_trunk * sens_trunk) / (ppv_trunk + sens_trunk)\n",
    "\n",
    "        wrist_results[alpha][\"acc\"].append(acc_wrist)\n",
    "        wrist_results[alpha][\"sens\"].append(sens_wrist)\n",
    "        wrist_results[alpha][\"spec\"].append(spec_wrist)\n",
    "        wrist_results[alpha][\"ppv\"].append(ppv_wrist)\n",
    "        wrist_results[alpha][\"f1\"].append(f1_wrist)\n",
    "\n",
    "        ankle_results[alpha][\"acc\"].append(acc_ankle)\n",
    "        ankle_results[alpha][\"sens\"].append(sens_ankle)\n",
    "        ankle_results[alpha][\"spec\"].append(spec_ankle)\n",
    "        ankle_results[alpha][\"ppv\"].append(ppv_ankle)\n",
    "        ankle_results[alpha][\"f1\"].append(f1_ankle)\n",
    "\n",
    "        trunk_results[alpha][\"acc\"].append(acc_trunk)\n",
    "        trunk_results[alpha][\"sens\"].append(sens_trunk)\n",
    "        trunk_results[alpha][\"spec\"].append(spec_trunk)\n",
    "        trunk_results[alpha][\"ppv\"].append(ppv_trunk)\n",
    "        trunk_results[alpha][\"f1\"].append(f1_trunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"ggplot\")\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results (f1)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(19, 5))\n",
    "for alpha in alphas:\n",
    "    ax[0].boxplot(wrist_results[alpha][\"f1\"], positions = [alpha], widths = 1.2, showmeans = True, patch_artist = False)\n",
    "    ax[1].boxplot(ankle_results[alpha][\"f1\"], positions = [alpha], widths = 1.2, showmeans = True, patch_artist = False)\n",
    "    ax[2].boxplot(trunk_results[alpha][\"f1\"], positions = [alpha], widths = 1.2, showmeans = True, patch_artist = False)\n",
    "for i in range(3):\n",
    "    ax[i].set_xticks([alpha for alpha in alphas[::2]])\n",
    "    ax[i].set_xticklabels([str(alpha) for alpha in alphas[::2]])\n",
    "    ax[i].set_xlabel(\"Threshold (mg)\")\n",
    "ax[0].set_title(\"Wrist\")\n",
    "ax[1].set_title(\"Ankle\")\n",
    "ax[2].set_title(\"Trunk\")\n",
    "plt.suptitle(\"F1 score\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_marcello + \"/final_database/figures/f1_score.png\", dpi = 300, bbox_inches = \"tight\")\n",
    "\n",
    "# plot results (senstivity)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(19, 5))\n",
    "for alpha in alphas:\n",
    "    ax[0].boxplot(wrist_results[alpha][\"sens\"], positions = [alpha], widths = 1.2, showmeans = True, patch_artist = False)\n",
    "    ax[1].boxplot(ankle_results[alpha][\"sens\"], positions = [alpha], widths = 1.2, showmeans = True, patch_artist = False)\n",
    "    ax[2].boxplot(trunk_results[alpha][\"sens\"], positions = [alpha], widths = 1.2, showmeans = True, patch_artist = False)\n",
    "for i in range(3):\n",
    "    ax[i].set_xticks([alpha for alpha in alphas[::2]])\n",
    "    ax[i].set_xticklabels([str(alpha) for alpha in alphas[::2]])\n",
    "    ax[i].set_xlabel(\"Threshold (mg)\")\n",
    "ax[0].set_title(\"Wrist\")\n",
    "ax[1].set_title(\"Ankle\")\n",
    "ax[2].set_title(\"Trunk\")\n",
    "plt.suptitle(\"Sensitivity\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(path_marcello + \"/final_database/figures/sensitivity.png\", dpi = 300, bbox_inches = \"tight\")\n",
    "\n",
    "# plot results (specificity)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(19, 5))\n",
    "for alpha in alphas:\n",
    "    ax[0].boxplot(wrist_results[alpha][\"spec\"], positions = [alpha], widths = 1.2, showmeans = True, patch_artist = False)\n",
    "    ax[1].boxplot(ankle_results[alpha][\"spec\"], positions = [alpha], widths = 1.2, showmeans = True, patch_artist = False)\n",
    "    ax[2].boxplot(trunk_results[alpha][\"spec\"], positions = [alpha], widths = 1.2, showmeans = True, patch_artist = False)\n",
    "for i in range(3):\n",
    "    ax[i].set_xticks([alpha for alpha in alphas[::2]])\n",
    "    ax[i].set_xticklabels([str(alpha) for alpha in alphas[::2]])\n",
    "    ax[i].set_xlabel(\"Threshold (mg)\")\n",
    "\n",
    "ax[0].set_title(\"Wrist\")\n",
    "ax[1].set_title(\"Ankle\")\n",
    "ax[2].set_title(\"Trunk\")\n",
    "\n",
    "plt.suptitle(\"Precision\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(path_marcello + \"/final_database/figures/precision.png\", dpi = 300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90.58082910391124,\n",
       " 3.0818482636946984,\n",
       " 93.48262576795184,\n",
       " 6.727717894402637,\n",
       " 88.81935275273631,\n",
       " 7.84669695913838)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(wrist_results[20][\"f1\"])*100, np.std(wrist_results[20][\"f1\"])*100, np.mean(wrist_results[20][\"sens\"])*100, np.std(wrist_results[20][\"sens\"])*100, np.mean(wrist_results[20][\"spec\"])*100, np.std(wrist_results[20][\"spec\"])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93.65845382414116,\n",
       " 6.683084598630604,\n",
       " 94.66274881497915,\n",
       " 7.183698432911247,\n",
       " 93.16591856203871,\n",
       " 8.654082508892845)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ankle_results[15][\"f1\"])*100, np.std(ankle_results[15][\"f1\"])*100, np.mean(ankle_results[15][\"sens\"])*100, np.std(ankle_results[15][\"sens\"])*100, np.mean(ankle_results[15][\"spec\"])*100, np.std(ankle_results[15][\"spec\"])*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94.40889112982632,\n",
       " 4.5255544249623565,\n",
       " 94.56866184300262,\n",
       " 5.928426645027572,\n",
       " 95.10005899563274,\n",
       " 8.397945489664641)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(trunk_results[15][\"f1\"])*100, np.std(trunk_results[15][\"f1\"])*100, np.mean(trunk_results[15][\"sens\"])*100, np.std(trunk_results[15][\"sens\"])*100, np.mean(trunk_results[15][\"spec\"])*100, np.std(trunk_results[15][\"spec\"])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hl_envelopes_idx(s, dmin=1, dmax=1, split=False, plot = True):\n",
    "    \"\"\"\n",
    "    Compute high and low envelopes of a signal s\n",
    "    Parameters\n",
    "    ----------\n",
    "    s: 1d-array, data signal from which to extract high and low envelopes\n",
    "    dmin, dmax: int, optional, size of chunks, use this if the size of the input signal is too big\n",
    "    split: bool, optional, if True, split the signal in half along its mean, might help to generate the envelope in some cases\n",
    "    resample: bool, optional, if True, resample the signal to the original size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lmin,lmax : high/low envelope idx of input signal s\n",
    "    \"\"\"\n",
    "\n",
    "    # locals min      \n",
    "    lmin = (np.diff(np.sign(np.diff(s))) > 0).nonzero()[0] + 1 \n",
    "    # locals max\n",
    "    lmax = (np.diff(np.sign(np.diff(s))) < 0).nonzero()[0] + 1 \n",
    "    \n",
    "    if split:\n",
    "        # s_mid is zero if s centered around x-axis or more generally mean of signal\n",
    "        s_mid = np.mean(s) \n",
    "        # pre-sorting of locals min based on relative position with respect to s_mid \n",
    "        lmin = lmin[s[lmin]<s_mid]\n",
    "        # pre-sorting of local max based on relative position with respect to s_mid \n",
    "        lmax = lmax[s[lmax]>s_mid]\n",
    "\n",
    "    # global min of dmin-chunks of locals min \n",
    "    lmin = lmin[[i+np.argmin(s[lmin[i:i+dmin]]) for i in range(0,len(lmin),dmin)]]\n",
    "    # global max of dmax-chunks of locals max \n",
    "    lmax = lmax[[i+np.argmax(s[lmax[i:i+dmax]]) for i in range(0,len(lmax),dmax)]]\n",
    "    \n",
    "    return lmin,lmax\n",
    "\n",
    "def detect_bursts(acc, resample_envelope = False, plot = False, alfa = 15):\n",
    "    \"\"\"\n",
    "    Detect bursts in acceleration signal\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    acc : pd.Series\n",
    "        # Signal magnitude of raw acceleration \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bursts : pd.Series\n",
    "        pd.DataFrame with burst start times, end times, and duration\n",
    "    \"\"\"\n",
    "\n",
    "    if envelope:\n",
    "        lmin, lmax = hl_envelopes_idx(acc.values, dmin=10, dmax=10)\n",
    "        # adjust shapes\n",
    "        if len(lmin) > len(lmax):\n",
    "            lmin = lmin[:-1]\n",
    "        if len(lmax) > len(lmin):\n",
    "            lmax = lmax[1:]\n",
    "        upper_envelope = acc.values[lmax]\n",
    "        lower_envelope = acc.values[lmin]\n",
    "        # resample the envelopes to the original size\n",
    "        if resample_envelope:\n",
    "            upper_envelope_res = np.interp(np.arange(len(acc)), lmax, upper_envelope)\n",
    "            lower_envelope_res = np.interp(np.arange(len(acc)), lmin, lower_envelope)\n",
    "            env_diff = pd.Series(upper_envelope_res - lower_envelope_res, index = acc.index)\n",
    "        else:\n",
    "            env_diff = pd.Series(upper_envelope - lower_envelope, index = acc.index[lmax])\n",
    "        print(len(env_diff))\n",
    "        th = np.percentile(env_diff.values, 10) * alfa\n",
    "    else:\n",
    "        std_acc = acc.resample(\"1 s\").std()\n",
    "        std_acc.index.round(\"1 s\")\n",
    "        th = np.percentile(std_acc, 10) * alfa\n",
    "        env_diff = std_acc\n",
    "        \n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(acc.values, color = 'k')\n",
    "        if resample_envelope:\n",
    "            plt.plot(lower_envelope_res, '-o')\n",
    "            plt.plot(upper_envelope_res, '-o')\n",
    "        else:\n",
    "            plt.plot(lmin, acc.values[lmin], '-o')\n",
    "            plt.plot(lmax, acc.values[lmax], '-o')\n",
    "        plt.subplot(2,1,2, sharex = plt.subplot(2,1,1))\n",
    "        plt.plot(env_diff.values, color = 'b')\n",
    "        plt.axhline(th, color = 'r')\n",
    "\n",
    "    bursts1 = (env_diff > th).astype(int)\n",
    "    start_burst = bursts1.where(bursts1.diff()==1).dropna()\n",
    "    end_burst = bursts1.where(bursts1.diff()==-1).dropna()\n",
    "    if bursts1.iloc[0] == 1:\n",
    "            start_burst = pd.concat([pd.Series(0, index = [bursts1.index[0]]), start_burst])\n",
    "    if bursts1.iloc[-1] == 1:\n",
    "        end_burst = pd.concat([end_burst, pd.Series(0, index = [bursts1.index[-1]])])\n",
    "    bursts_df = pd.DataFrame({\"duration\": end_burst.index - start_burst.index}, index = start_burst.index)\n",
    "\n",
    "    start = bursts_df.index\n",
    "    end = pd.to_datetime((bursts_df.index + bursts_df[\"duration\"]).values)\n",
    "\n",
    "    end = end.to_series().reset_index(drop = True)\n",
    "    start = start.to_series().reset_index(drop = True)\n",
    "\n",
    "    duration_between_bursts = (start.iloc[1:].values - end.iloc[:-1].values)\n",
    "\n",
    "    # If two bursts are too close to each other (5s), consider them as one burst\n",
    "    for i in range(len(start)-1):\n",
    "        if duration_between_bursts[i] < pd.Timedelta(\"5 s\"):\n",
    "            end[i] = np.nan\n",
    "            start[i+1] = np.nan\n",
    "    end.dropna(inplace = True)\n",
    "    start.dropna(inplace = True)\n",
    "\n",
    "    # extract amplitude of the bursts\n",
    "    bursts = pd.DataFrame({\"Start\": start.reset_index(drop = True), \"End\": end.reset_index(drop = True)})\n",
    "    burst_amplitude1 = []\n",
    "    burst_amplitude2 = []\n",
    "    for i in range(len(bursts)):\n",
    "        # peak-to-peak amplitude of bp acceleration\n",
    "        burst_amplitude1.append(acc.loc[bursts[\"Start\"].iloc[i]:bursts[\"End\"].iloc[i]].max() - acc.loc[bursts[\"Start\"].iloc[i]:bursts[\"End\"].iloc[i]].min())\n",
    "        # AUC of env_diff\n",
    "        burst_amplitude2.append(np.trapz(env_diff.loc[bursts[\"Start\"].iloc[i]:bursts[\"End\"].iloc[i]]))\n",
    "    bursts[\"duration\"] = bursts[\"End\"] - bursts[\"Start\"]\n",
    "    bursts[\"peak-to-peak\"] = burst_amplitude1\n",
    "    bursts[\"AUC\"] = burst_amplitude2\n",
    "    return bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n",
      "18200\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[29], line 46\u001b[0m\n",
      "\u001b[1;32m     36\u001b[0m bursts \u001b[38;5;241m=\u001b[39m detect_bursts(current_acc_1, resample_envelope \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, plot \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, alfa \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m)\n",
      "\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# # plot annot1 as axvspans\u001b[39;00m\n",
      "\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# plt.figure(figsize=(20, 12))\u001b[39;00m\n",
      "\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# plt.plot(current_acc_1)\u001b[39;00m\n",
      "\u001b[0;32m   (...)\u001b[0m\n",
      "\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# for i, row in bursts.iterrows():\u001b[39;00m\n",
      "\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#     plt.axvspan(row[\"start\"], row[\"end\"], alpha=0.5, color='red')\u001b[39;00m\n",
      "\u001b[0;32m---> 46\u001b[0m agreement, disagreement \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannot_marcello2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbursts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mcompare_annotations\u001b[0;34m(annot1, annot2)\u001b[0m\n",
      "\u001b[1;32m      6\u001b[0m overlap_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, row_marcello \u001b[38;5;129;01min\u001b[39;00m annot2\u001b[38;5;241m.\u001b[39miterrows():\n",
      "\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_overlap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow_paola\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_paola\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_marcello\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_marcello\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEnd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n",
      "\u001b[1;32m      9\u001b[0m         agreement_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m     10\u001b[0m         overlap_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\n",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m, in \u001b[0;36mis_overlap\u001b[0;34m(start1, end1, start2, end2)\u001b[0m\n",
      "\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_overlap\u001b[39m(start1, end1, start2, end2):\n",
      "\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mstart1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend2\u001b[49m) \u001b[38;5;129;01mand\u001b[39;00m (start2 \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end1)\n",
      "\n",
      "\u001b[0;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "subjects = [\"158\"]\n",
    "\n",
    "for i, sub in enumerate(subjects):\n",
    "    locations = comb_location[sub]\n",
    "    print(sub)\n",
    "\n",
    "    save_path = \"/Users/marcellosicbaldi/Library/CloudStorage/OneDrive-AlmaMaterStudiorumUniversitaÌ€diBologna/General - LG-MIAR (rehab)/SCORING_bursts\"\n",
    "\n",
    "    acc_norm_raw = pd.read_pickle(save_path+ \"/\" + sub + \"/\" + locations[1] + \"/\" + locations[1] + \".pkl\")\n",
    "    acc_norm_raw1 = pd.Series(nk.signal_filter(acc_norm_raw.values, sampling_rate = 50, lowcut=0.1, highcut=5, method='butterworth', order=8), index = acc_norm_raw.index)\n",
    "    acc_norm_raw2 = pd.Series(nk.signal_filter(acc_norm_raw1.values, sampling_rate = 100, lowcut=0.1, highcut=10, method='butterworth', order=8), index = acc_norm_raw1.index)\n",
    "    start_sleep, end_sleep = diary_SPT[sub]\n",
    "\n",
    "    # Split the data according to the sleep midpoint\n",
    "    sleep_midPoint = start_sleep + (end_sleep - start_sleep) / 2\n",
    "\n",
    "    # First location\n",
    "    # loc1_df_1 = acc_norm_raw.loc[sleep_midPoint - pd.Timedelta(hours = 1):sleep_midPoint]\n",
    "    # loc1_df_2 = acc_norm_raw.loc[sleep_midPoint:sleep_midPoint + pd.Timedelta(hours = 1)]\n",
    "\n",
    "    # # Second location\n",
    "    loc1_df_1 = acc_norm_raw.loc[sleep_midPoint - pd.Timedelta(hours = 2):sleep_midPoint - pd.Timedelta(hours = 1)]\n",
    "    loc1_df_2 = acc_norm_raw.loc[sleep_midPoint + pd.Timedelta(hours = 1):sleep_midPoint + pd.Timedelta(hours = 2)]\n",
    "\n",
    "    # # Third location\n",
    "    # loc1_df_1 = acc_norm_raw.loc[sleep_midPoint - pd.Timedelta(hours = 3):sleep_midPoint - pd.Timedelta(hours = 2)]\n",
    "    # loc1_df_2 = acc_norm_raw.loc[sleep_midPoint + pd.Timedelta(hours = 2):sleep_midPoint + pd.Timedelta(hours = 3)]\n",
    "\n",
    "    # concatenate the two dataframes\n",
    "    current_acc_1 = pd.concat([loc1_df_1, loc1_df_2])\n",
    "\n",
    "    annot_marcello1 = pd.read_csv(f\"{path_marcello}/{sub}/{locations[0]}/bursts_ANNOT.csv\")\n",
    "    annot_marcello2 = pd.read_csv(f\"{path_marcello}/{sub}/{locations[1]}/bursts_ANNOT.csv\")\n",
    "    annot_marcello3 = pd.read_csv(f\"{path_marcello}/{sub}/{locations[2]}/bursts_ANNOT.csv\")\n",
    "\n",
    "    bursts = detect_bursts(current_acc_1, resample_envelope = False, plot = False, alfa = 6)\n",
    "\n",
    "    # # plot annot1 as axvspans\n",
    "    # plt.figure(figsize=(20, 12))\n",
    "    # plt.plot(current_acc_1)\n",
    "    # for i, row in annot_marcello2.iterrows():\n",
    "    #     plt.axvspan(pd.to_datetime(row[\"Start\"]), pd.to_datetime(row[\"End\"]), alpha=0.5, color='blue')\n",
    "    # for i, row in bursts.iterrows():\n",
    "    #     plt.axvspan(row[\"start\"], row[\"end\"], alpha=0.5, color='red')\n",
    "\n",
    "    agreement, disagreement = compare_annotations(annot_marcello2, bursts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>peak-to-peak</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-02-29 01:15:54.014869928</td>\n",
       "      <td>2024-02-29 01:15:54.444869995</td>\n",
       "      <td>0 days 00:00:00.430000067</td>\n",
       "      <td>0.028314</td>\n",
       "      <td>0.025932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-02-29 01:18:00.644870043</td>\n",
       "      <td>2024-02-29 01:18:09.494869947</td>\n",
       "      <td>0 days 00:00:08.849999904</td>\n",
       "      <td>0.129128</td>\n",
       "      <td>0.396791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-02-29 01:18:15.114870071</td>\n",
       "      <td>2024-02-29 01:18:16.464869976</td>\n",
       "      <td>0 days 00:00:01.349999905</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.090850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-02-29 01:18:24.174870014</td>\n",
       "      <td>2024-02-29 01:18:37.784869909</td>\n",
       "      <td>0 days 00:00:13.609999895</td>\n",
       "      <td>0.181678</td>\n",
       "      <td>0.973120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-02-29 01:21:48.164870024</td>\n",
       "      <td>2024-02-29 01:21:48.814870119</td>\n",
       "      <td>0 days 00:00:00.650000095</td>\n",
       "      <td>0.027165</td>\n",
       "      <td>0.025596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-02-29 01:24:32.034869909</td>\n",
       "      <td>2024-02-29 01:24:36.734869957</td>\n",
       "      <td>0 days 00:00:04.700000048</td>\n",
       "      <td>0.087386</td>\n",
       "      <td>0.439976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-02-29 01:29:52.954869986</td>\n",
       "      <td>2024-02-29 01:29:54.684870005</td>\n",
       "      <td>0 days 00:00:01.730000019</td>\n",
       "      <td>0.055484</td>\n",
       "      <td>0.063021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-02-29 01:30:12.324870110</td>\n",
       "      <td>2024-02-29 01:30:36.414870024</td>\n",
       "      <td>0 days 00:00:24.089999914</td>\n",
       "      <td>0.875546</td>\n",
       "      <td>3.982242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-02-29 01:32:16.654870033</td>\n",
       "      <td>2024-02-29 01:32:19.424870014</td>\n",
       "      <td>0 days 00:00:02.769999981</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.169452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-02-29 01:40:29.964869976</td>\n",
       "      <td>2024-02-29 01:40:30.724869967</td>\n",
       "      <td>0 days 00:00:00.759999991</td>\n",
       "      <td>0.033871</td>\n",
       "      <td>0.020757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-02-29 01:49:12.574870110</td>\n",
       "      <td>2024-02-29 01:49:12.994869947</td>\n",
       "      <td>0 days 00:00:00.419999837</td>\n",
       "      <td>0.022907</td>\n",
       "      <td>0.022290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-02-29 01:53:59.234869957</td>\n",
       "      <td>2024-02-29 01:54:09.204869986</td>\n",
       "      <td>0 days 00:00:09.970000029</td>\n",
       "      <td>0.253935</td>\n",
       "      <td>1.303709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-02-29 01:57:00.604870081</td>\n",
       "      <td>2024-02-29 01:57:03.404870033</td>\n",
       "      <td>0 days 00:00:02.799999952</td>\n",
       "      <td>0.056764</td>\n",
       "      <td>0.174033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-02-29 04:15:52.004869938</td>\n",
       "      <td>2024-02-29 04:16:24.644870043</td>\n",
       "      <td>0 days 00:00:32.640000105</td>\n",
       "      <td>0.944378</td>\n",
       "      <td>5.179144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-02-29 04:34:34.554869890</td>\n",
       "      <td>2024-02-29 04:34:40.674870014</td>\n",
       "      <td>0 days 00:00:06.120000124</td>\n",
       "      <td>0.053731</td>\n",
       "      <td>0.245320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-02-29 04:37:38.684870005</td>\n",
       "      <td>2024-02-29 04:37:38.924870014</td>\n",
       "      <td>0 days 00:00:00.240000009</td>\n",
       "      <td>0.027614</td>\n",
       "      <td>0.021429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-02-29 04:42:55.874870062</td>\n",
       "      <td>2024-02-29 04:43:01.004869938</td>\n",
       "      <td>0 days 00:00:05.129999876</td>\n",
       "      <td>0.045011</td>\n",
       "      <td>0.237601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-02-29 04:44:50.234869957</td>\n",
       "      <td>2024-02-29 04:44:52.014869928</td>\n",
       "      <td>0 days 00:00:01.779999971</td>\n",
       "      <td>0.027324</td>\n",
       "      <td>0.054151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024-02-29 04:46:58.144870043</td>\n",
       "      <td>2024-02-29 04:47:07.424870014</td>\n",
       "      <td>0 days 00:00:09.279999971</td>\n",
       "      <td>0.221844</td>\n",
       "      <td>1.149574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024-02-29 04:49:08.544869900</td>\n",
       "      <td>2024-02-29 04:49:10.114870071</td>\n",
       "      <td>0 days 00:00:01.570000171</td>\n",
       "      <td>0.037415</td>\n",
       "      <td>0.095524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2024-02-29 04:50:12.444869995</td>\n",
       "      <td>2024-02-29 04:50:12.864870071</td>\n",
       "      <td>0 days 00:00:00.420000076</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.019861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2024-02-29 04:55:38.754869938</td>\n",
       "      <td>2024-02-29 04:55:40.824870110</td>\n",
       "      <td>0 days 00:00:02.070000172</td>\n",
       "      <td>0.042685</td>\n",
       "      <td>0.088669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2024-02-29 04:56:45.764869928</td>\n",
       "      <td>2024-02-29 04:56:51.614870071</td>\n",
       "      <td>0 days 00:00:05.850000143</td>\n",
       "      <td>0.074323</td>\n",
       "      <td>0.376129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2024-02-29 05:05:41.504869938</td>\n",
       "      <td>2024-02-29 05:05:50.004869938</td>\n",
       "      <td>0 days 00:00:08.500000</td>\n",
       "      <td>0.850238</td>\n",
       "      <td>2.743261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           start                           end  \\\n",
       "0  2024-02-29 01:15:54.014869928 2024-02-29 01:15:54.444869995   \n",
       "1  2024-02-29 01:18:00.644870043 2024-02-29 01:18:09.494869947   \n",
       "2  2024-02-29 01:18:15.114870071 2024-02-29 01:18:16.464869976   \n",
       "3  2024-02-29 01:18:24.174870014 2024-02-29 01:18:37.784869909   \n",
       "4  2024-02-29 01:21:48.164870024 2024-02-29 01:21:48.814870119   \n",
       "5  2024-02-29 01:24:32.034869909 2024-02-29 01:24:36.734869957   \n",
       "6  2024-02-29 01:29:52.954869986 2024-02-29 01:29:54.684870005   \n",
       "7  2024-02-29 01:30:12.324870110 2024-02-29 01:30:36.414870024   \n",
       "8  2024-02-29 01:32:16.654870033 2024-02-29 01:32:19.424870014   \n",
       "9  2024-02-29 01:40:29.964869976 2024-02-29 01:40:30.724869967   \n",
       "10 2024-02-29 01:49:12.574870110 2024-02-29 01:49:12.994869947   \n",
       "11 2024-02-29 01:53:59.234869957 2024-02-29 01:54:09.204869986   \n",
       "12 2024-02-29 01:57:00.604870081 2024-02-29 01:57:03.404870033   \n",
       "13 2024-02-29 04:15:52.004869938 2024-02-29 04:16:24.644870043   \n",
       "14 2024-02-29 04:34:34.554869890 2024-02-29 04:34:40.674870014   \n",
       "15 2024-02-29 04:37:38.684870005 2024-02-29 04:37:38.924870014   \n",
       "16 2024-02-29 04:42:55.874870062 2024-02-29 04:43:01.004869938   \n",
       "17 2024-02-29 04:44:50.234869957 2024-02-29 04:44:52.014869928   \n",
       "18 2024-02-29 04:46:58.144870043 2024-02-29 04:47:07.424870014   \n",
       "19 2024-02-29 04:49:08.544869900 2024-02-29 04:49:10.114870071   \n",
       "20 2024-02-29 04:50:12.444869995 2024-02-29 04:50:12.864870071   \n",
       "21 2024-02-29 04:55:38.754869938 2024-02-29 04:55:40.824870110   \n",
       "22 2024-02-29 04:56:45.764869928 2024-02-29 04:56:51.614870071   \n",
       "23 2024-02-29 05:05:41.504869938 2024-02-29 05:05:50.004869938   \n",
       "\n",
       "                    duration  peak-to-peak       AUC  \n",
       "0  0 days 00:00:00.430000067      0.028314  0.025932  \n",
       "1  0 days 00:00:08.849999904      0.129128  0.396791  \n",
       "2  0 days 00:00:01.349999905      0.063694  0.090850  \n",
       "3  0 days 00:00:13.609999895      0.181678  0.973120  \n",
       "4  0 days 00:00:00.650000095      0.027165  0.025596  \n",
       "5  0 days 00:00:04.700000048      0.087386  0.439976  \n",
       "6  0 days 00:00:01.730000019      0.055484  0.063021  \n",
       "7  0 days 00:00:24.089999914      0.875546  3.982242  \n",
       "8  0 days 00:00:02.769999981      0.047771  0.169452  \n",
       "9  0 days 00:00:00.759999991      0.033871  0.020757  \n",
       "10 0 days 00:00:00.419999837      0.022907  0.022290  \n",
       "11 0 days 00:00:09.970000029      0.253935  1.303709  \n",
       "12 0 days 00:00:02.799999952      0.056764  0.174033  \n",
       "13 0 days 00:00:32.640000105      0.944378  5.179144  \n",
       "14 0 days 00:00:06.120000124      0.053731  0.245320  \n",
       "15 0 days 00:00:00.240000009      0.027614  0.021429  \n",
       "16 0 days 00:00:05.129999876      0.045011  0.237601  \n",
       "17 0 days 00:00:01.779999971      0.027324  0.054151  \n",
       "18 0 days 00:00:09.279999971      0.221844  1.149574  \n",
       "19 0 days 00:00:01.570000171      0.037415  0.095524  \n",
       "20 0 days 00:00:00.420000076      0.028583  0.019861  \n",
       "21 0 days 00:00:02.070000172      0.042685  0.088669  \n",
       "22 0 days 00:00:05.850000143      0.074323  0.376129  \n",
       "23    0 days 00:00:08.500000      0.850238  2.743261  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bursts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98107acf70>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(acc_norm_raw)\n",
    "plt.plot(acc_norm_raw1)\n",
    "plt.plot(acc_norm_raw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary_SPT = {    \n",
    "    \"158\": [pd.Timestamp('2024-02-28 23:00:00'), pd.Timestamp('2024-02-29 07:15:00')], # 158 OK\n",
    "    \"633\": [pd.Timestamp('2024-03-07 00:05:00'), pd.Timestamp('2024-03-07 06:36:00')], # 633 OK\n",
    "    \"906\": [pd.Timestamp('2024-03-07 00:30:00'), pd.Timestamp('2024-03-07 07:30:00')], # 906 OK\n",
    "    \"958\": [pd.Timestamp('2024-03-13 22:00:00'), pd.Timestamp('2024-03-14 06:00:00')], # 958 OK\n",
    "    \"127\": [pd.Timestamp('2024-03-13 23:15:00'), pd.Timestamp('2024-03-14 06:50:00')], # 127 OK\n",
    "    \"098\": [pd.Timestamp('2024-03-16 02:01:00'), pd.Timestamp('2024-03-16 09:50:00')], # 098 OK\n",
    "    \"547\": [pd.Timestamp('2024-03-16 01:04:00'), pd.Timestamp('2024-03-16 07:40:00')], # 547 OK\n",
    "    \"815\": [pd.Timestamp('2024-03-20 23:00:00'), pd.Timestamp('2024-03-21 06:25:00')], # 815 OK\n",
    "    \"914\": [pd.Timestamp('2024-03-20 21:50:00'), pd.Timestamp('2024-03-21 05:50:00')], # 914 OK\n",
    "    \"971\": [pd.Timestamp('2024-03-20 23:50:00'), pd.Timestamp('2024-03-21 07:50:00')], # 971 OK\n",
    "    \"279\": [pd.Timestamp('2024-03-28 00:10:00'), pd.Timestamp('2024-03-28 07:27:00')], # 279 OK\n",
    "    \"965\": [pd.Timestamp('2024-03-28 01:25:00'), pd.Timestamp('2024-03-28 09:20:00')], # 965 OK\n",
    "}\n",
    "\n",
    "diary_TIB = {\n",
    "    \"158\": [pd.Timestamp('2024-02-28 22:15:00'), pd.Timestamp('2024-02-29 07:45:00')], # 158 OK\n",
    "    \"633\": [pd.Timestamp('2024-03-06 23:39:00'), pd.Timestamp('2024-03-07 08:00:00')], # 633 OK \n",
    "    \"906\": [pd.Timestamp('2024-03-07 00:15:00'), pd.Timestamp('2024-03-07 07:35:00')], # 906 OK\n",
    "    \"958\": [pd.Timestamp('2024-03-13 21:30:00'), pd.Timestamp('2024-03-14 06:30:00')], # 958 OK\n",
    "    \"127\": [pd.Timestamp('2024-03-13 22:00:00'), pd.Timestamp('2024-03-14 07:10:00')], # 127 OK \n",
    "    \"098\": [pd.Timestamp('2024-03-16 01:49:00'), pd.Timestamp('2024-03-16 09:52:00')], # 098 OK \n",
    "    \"547\": [pd.Timestamp('2024-03-16 00:26:00'), pd.Timestamp('2024-03-16 08:20:00')], # 547 OK \n",
    "    \"815\": [pd.Timestamp('2024-03-20 22:00:00'), pd.Timestamp('2024-03-21 07:30:00')], # 815 OK \n",
    "    \"914\": [pd.Timestamp('2024-03-20 21:30:00'), pd.Timestamp('2024-03-21 06:20:00')], # 914 OK \n",
    "    \"971\": [pd.Timestamp('2024-03-20 23:30:00'), pd.Timestamp('2024-03-21 08:08:00')], # 971 OK \n",
    "    \"279\": [pd.Timestamp('2024-03-28 00:04:00'), pd.Timestamp('2024-03-28 07:41:00')], # 279 OK\n",
    "    \"965\": [pd.Timestamp('2024-03-28 01:22:00'), pd.Timestamp('2024-03-28 09:22:00')], # 965 OK\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annot_paola2['Start'] = pd.to_datetime(annot_paola2['Start'])\n",
    "annot_paola2['End'] = pd.to_datetime(annot_paola2['End'])\n",
    "bursts['Start'] = pd.to_datetime(bursts['start'])\n",
    "bursts['End'] = pd.to_datetime(bursts['end'])\n",
    "\n",
    "# Function to check if two intervals overlap\n",
    "def is_overlap(start1, end1, start2, end2):\n",
    "    return (start1 <= end2) and (start2 <= end1)\n",
    "\n",
    "# Initialize counters for agreement and disagreement\n",
    "agreement_count = 0\n",
    "disagreement_count = 0\n",
    "\n",
    "# Check each burst in algo data against all bursts in marcello rater's data\n",
    "for i, row_algo in bursts.iterrows():\n",
    "    overlap_found = False\n",
    "    for j, row_other in annot_paola2.iterrows():\n",
    "        if is_overlap(row_algo['Start'], row_algo['End'], row_other['Start'].tz_localize(None), row_other['End'].tz_localize(None)):\n",
    "            agreement_count += 1\n",
    "            overlap_found = True\n",
    "            break\n",
    "    if not overlap_found:\n",
    "        disagreement_count += 1\n",
    "\n",
    "# Check each burst in the marcello rater's data against all bursts in algo data\n",
    "for j, row_other in annot_paola2.iterrows():\n",
    "    overlap_found = False\n",
    "    for i, row_algo in bursts.iterrows():\n",
    "        if is_overlap(row_algo['Start'], row_algo['End'], row_other['Start'].tz_localize(None), row_other['End'].tz_localize(None)):\n",
    "            overlap_found = True\n",
    "            break\n",
    "    if not overlap_found:\n",
    "        disagreement_count += 1\n",
    "\n",
    "\n",
    "agreement_count, disagreement_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot annot1 as axvspans\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(current_acc_1)\n",
    "for i, row in annot_paola2.iterrows():\n",
    "    ax.axvspan(pd.to_datetime(row[\"Start\"].tz_localize(None)), pd.to_datetime(row[\"End\"].tz_localize(None)), alpha=0.5, color='red')\n",
    "for i, row in bursts.iterrows():\n",
    "    ax.axvspan(pd.to_datetime(row[\"Start\"]), pd.to_datetime(row[\"End\"]), alpha=0.5, color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2024-03-07 00:29:03.959481001'),\n",
       " Timestamp('2024-03-07 03:09:37.218347+0000', tz='UTC'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "row_algo[\"Start\"], row_other['Start']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
